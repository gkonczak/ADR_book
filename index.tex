% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrreprt}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother
% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\@ifpackageloaded{fontawesome5}{}{\usepackage{fontawesome5}}
\definecolor{quarto-callout-color}{HTML}{909090}
\definecolor{quarto-callout-note-color}{HTML}{0758E5}
\definecolor{quarto-callout-important-color}{HTML}{CC1914}
\definecolor{quarto-callout-warning-color}{HTML}{EB9113}
\definecolor{quarto-callout-tip-color}{HTML}{00A047}
\definecolor{quarto-callout-caution-color}{HTML}{FC5300}
\definecolor{quarto-callout-color-frame}{HTML}{acacac}
\definecolor{quarto-callout-note-color-frame}{HTML}{4582ec}
\definecolor{quarto-callout-important-color-frame}{HTML}{d9534f}
\definecolor{quarto-callout-warning-color-frame}{HTML}{f0ad4e}
\definecolor{quarto-callout-tip-color-frame}{HTML}{02b875}
\definecolor{quarto-callout-caution-color-frame}{HTML}{fd7e14}
\makeatother
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Rysunek}
\else
  \newcommand\figurename{Rysunek}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Tabela}
\else
  \newcommand\tablename{Tabela}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\captionsetup{labelsep=period}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\newcounter{quartocallouttipno}
\newcommand{\quartocallouttip}[1]{\refstepcounter{quartocallouttipno}\label{#1}}

\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Wprowadzenie do rachunku prawdopodobieństwa},
  pdfauthor={Grzegorz Kończak, Małgorzata Złotoś},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\title{Wprowadzenie do rachunku prawdopodobieństwa}
\author{Grzegorz Kończak, Małgorzata Złotoś}
\date{2024-12-27}

\begin{document}
\maketitle

\renewcommand*\contentsname{Spis treści}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}
\listoffigures
\listoftables

\bookmarksetup{startatroot}

\chapter*{Tylko notatki}\label{tylko-notatki}
\addcontentsline{toc}{chapter}{Tylko notatki}

\markboth{Tylko notatki}{Tylko notatki}

To do wyrzucenia

To jest książka o rachunku prawdopodobieństwa

Good (\citeproc{ref-good1959}{1959}) I.J. Good Aczel str. 65

Por. Krysicki (\citeproc{ref-krysicki2003}{2003}) a także Hellwig
(\citeproc{ref-hellwig1995}{1995})

Bernstein et al. (\citeproc{ref-bernstein1997}{1997})

Good (\citeproc{ref-good1959}{1959})

(\citeproc{ref-jux119drzejczak2020}{\textbf{jędrzejczak2020?}})

Jędrzejczak \& Pekasiewicz (\citeproc{ref-jedrzejczak2020}{2020})

To Trzpiot \& Kończak (\citeproc{ref-trzpiot2008}{2008}) zadania

Szymańska (\citeproc{ref-szymanska2017}{2017})

Trzpiot (\citeproc{ref-trzpiot2011}{2008})

Kucharski (\citeproc{ref-kucharski2013}{2013})

Piasecki \& Tomasik (\citeproc{ref-piasecki2013}{2013})

Małecka (\citeproc{ref-malecka2016}{2016})

Ulman \& Ćwiek (\citeproc{ref-ulman2021}{2021})

(\citeproc{ref-konczak2020b}{\textbf{konczak2020b?}})

Ganczarek-Gamrot (\citeproc{ref-ganczarek-gamrot2013}{2013})

Także Kończak (\citeproc{ref-konczak2016}{2016})

Por. Jakubowski \& Sztencel (\citeproc{ref-jakubowski2004}{2004})

Bertsekas \& Tsitsiklis (\citeproc{ref-bertsekas2008}{2008})

Billingsley (\citeproc{ref-billingsley1995}{1995})

Capiński \& Zastawniak (\citeproc{ref-capinski2001}{2001})

Kinney (\citeproc{ref-kinney2015}{2015})

Covington (\citeproc{ref-covington2020}{2020})

Suhov \& Kelbert (\citeproc{ref-suhov2005}{2005})

Feller (\citeproc{ref-feller1971}{1971})

Thas (\citeproc{ref-thas2010}{2010})

Definicja jest następująca (\citeproc{ref-trzpiot2002}{Trzpiot \&
Kończak, 2002}):

Zeliaś et al. (\citeproc{ref-zelias2002}{2002})

Steinhaus \& Kobyliński (\citeproc{ref-steinhaus2010}{2010})

Plucińska \& Pluciński (\citeproc{ref-plucinska1983}{1983})

Krzyśko (\citeproc{ref-krzysko2000}{2000})

Simons (\citeproc{ref-simons2017}{2017})

Bernstein (\citeproc{ref-bernstein1998}{1998})

Kończak (\citeproc{ref-konczak2014}{2014})

Sobczyk (\citeproc{ref-sobczyk2001}{2001})

Kowgier (\citeproc{ref-kowgier2011}{2011})

Feller (\citeproc{ref-feller1971}{1971})

Rao (\citeproc{ref-rao1997}{1997})

Wywiał (\citeproc{ref-wywial2004}{2004})

Jasiulewicz \& Kordecki (\citeproc{ref-jasiulewicz2010}{2010})

Bratijczuk \& Chydziński (\citeproc{ref-bratijczuk2000}{2000})

Wieczorkowski \& Zieliński (\citeproc{ref-wieczorkowski1997}{1997})

Czaplicki (\citeproc{ref-czaplicki2011}{2011})

Wawrzynek (\citeproc{ref-wawrzynek2007}{2007})

Snopkowski (\citeproc{ref-snopkowski2007}{2007})

Plucińska \& Pluciński (\citeproc{ref-plucinska2006}{2006})

Kończak (\citeproc{ref-konczak2012}{2012})

Aczel (\citeproc{ref-aczel2000}{2000})

Iwasiewicz \& Paszek (\citeproc{ref-iwasiewicz2000}{2000})

Kończak (\citeproc{ref-konczak2000}{2000})

Przykłady call-out

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Informacje}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-note-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-note-color-frame, colback=white]

Wprowadzenie ważnych pojęć.

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład numer}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

Tu treść przykładu

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={Rozwiązanie}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={Stop}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Zdarzenie elementarne - callout-note}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-note-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-note-color-frame, colback=white]

Zdarzenie elementarne, to niepodzielny wynik doświadczenia losowego.

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Zdarzenie elementarne - callout-tip}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

Zdarzenie elementarne, to niepodzielny wynik doświadczenia losowego.

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-caution-color}{\faFire}\hspace{0.5em}{Zdarzenie elementarne - callout-caution}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-caution-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-caution-color-frame, colback=white]

Zdarzenie elementarne, to niepodzielny wynik doświadczenia losowego.

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{Zdarzenie elementarne - callout-important}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-important-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-important-color-frame, colback=white]

Zdarzenie elementarne, to niepodzielny wynik doświadczenia losowego.

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-warning-color}{\faExclamationTriangle}\hspace{0.5em}{Zdarzenie elementarne - callout-warning}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-warning-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-warning-color-frame, colback=white]

Zdarzenie elementarne, to niepodzielny wynik doświadczenia losowego.

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-warning-color}{\faExclamationTriangle}\hspace{0.5em}{Zdarzenie elementarne - collapse=``false''}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-warning-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-warning-color-frame, colback=white]

Zdarzenie elementarne, to niepodzielny wynik doświadczenia losowego.

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-warning-color}{\faExclamationTriangle}\hspace{0.5em}{Zdarzenie elementarne collapse=``true'' apperance=``simple''}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-warning-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-warning-color-frame, colback=white]

Zdarzenie elementarne, to niepodzielny wynik doświadczenia losowego.

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-warning-color}{\faExclamationTriangle}\hspace{0.5em}{Zdarzenie elementarne - ``warning'' collapse=``true''
apperance=``minimal''}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-warning-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-warning-color-frame, colback=white]

Zdarzenie elementarne, to niepodzielny wynik doświadczenia losowego.

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-warning-color}{\faExclamationTriangle}\hspace{0.5em}{Definicja}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-warning-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-warning-color-frame, colback=white]

\section*{Zdarzenie elementarne - callout-warning collapse=``false''
title=``Definicja''}\label{zdarzenie-elementarne---callout-warning-collapsefalse-titledefinicja}
\addcontentsline{toc}{section}{Zdarzenie elementarne - callout-warning
collapse=``false'' title=``Definicja''}

\markright{Zdarzenie elementarne - callout-warning collapse=``false''
title=``Definicja''}

Zdarzenie elementarne, to niepodzielny wynik doświadczenia losowego.

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-warning-color}{\faExclamationTriangle}\hspace{0.5em}{Zdarzenie elementarne - apperance=``simple''}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-warning-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-warning-color-frame, colback=white]

Zdarzenie elementarne, to niepodzielny wynik doświadczenia losowego.

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-warning-color}{\faExclamationTriangle}\hspace{0.5em}{Zdarzenie elementarne - apperance=``minimal''}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-warning-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-warning-color-frame, colback=white]

Zdarzenie elementarne, to niepodzielny wynik doświadczenia losowego.

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={Zdarzenie elementarne - icon=``false''}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-warning-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-warning-color-frame, colback=white]

Zdarzenie elementarne, to niepodzielny wynik doświadczenia losowego.

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Tip \ref*{tip-example1}. Cross-Referencing a Tip - \#tip-example1 .callout-tip}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\quartocallouttip{tip-example1} 

Add an ID starting with \texttt{\#tip-} to reference a tip.

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Tip \ref*{tip-example2}. Cross-Referencing a Tip-2}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\quartocallouttip{tip-example2} 

Add an ID starting with \texttt{\#tip-example1} to reference a tip.

\end{tcolorbox}

To próba odwołania do Tip~\ref{tip-example2}

\pandocbounded{\includegraphics[keepaspectratio]{pic/zadania.png}}

\pandocbounded{\includegraphics[keepaspectratio]{pic/problem.png}}

\pandocbounded{\includegraphics[keepaspectratio]{pic/tn.png}}

\pandocbounded{\includegraphics[keepaspectratio]{pic/testowe.png}}

\bookmarksetup{startatroot}

\chapter*{Wprowadzenie}\label{wprowadzenie}
\addcontentsline{toc}{chapter}{Wprowadzenie}

\markboth{Wprowadzenie}{Wprowadzenie}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={P.S. Laplace ``Theorie analytique des probabilities'' (za: Rao 1997, s.
83)
\href{https://mathshistory.st-andrews.ac.uk/Biographies/Laplace/quotations/}{Laplace}}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-note-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-note-color-frame, colback=white]

Godne uwagi jest to, że nauka, która zaczęłą się od rozważania gier
losowych, powinna stać się najważniejszą dziedziną ludzkiej wiedzy.

\end{tcolorbox}

Amir Aczel (\citeproc{ref-aczel2000}{2000}, XIV) podkreśla, że
umiejętność formułowania precyzyjnych prognoz dotyczących przebiegu
przyszłych zdarzeń i związana z tym możliwość dokonywania wyboru
pomiędzy różnymi alernatywami jest najistotniejszym aspektem życia
współczesnych społeczeństw. To przewidywanie nie byłoby możliwe bez
wielkiego postępu w zakresie teorii prawdopodobieństwa w ostatnim
stuleciu.

Chociaż przyjmuje się, że początki rozważań nad pojęciem
prawdopodobieństwa miały miejsce w XVII wieku, to jednak znacznie
wcześniej ludzie podejmowali codzienne decyzje w warunkach niepewności,
w jakiejś mierze nieświadomie oceniając szanse realizacji różnych
zdarzeń. Znaczenie tej nauki podkreśla statystyk Irving John Good
(\citeproc{ref-good1959}{Good, 1959}), który sformułował myśl, że
``\emph{teoria prawdopodobieństwa jest znacznie starsza niż rodzaj
ludzki}'' (za Aczel (\citeproc{ref-aczel2000}{2000, p. 65})). Ocena
niepewności (prawdopodobieństwa) łączy w sobie ideę uczenia się na
podstawie doświadczenia oraz ideę rozumowania indukcyjnego. Większość
aktualnych zastosowań teorii prawdopodobieństwa nie ma nic wspólnego
bezpośrednio z grami losowymi, to jednak gry losowe są najlepszymi
przykładami ilustrującymi pojęcie prawdopodobieństwa oraz sposoby jego
obliczania (Aczel (\citeproc{ref-aczel2000}{2000, p. 66})).

W książce przedstawiono podstawy rachunku prawdopodobieństwa z
przeznaczeniem dla wykorzystania na kierunkach I stopnia lub II stopnia
przez studentów kierunków ilościowych.

W pierwszym rozdziale w sposób zwięzły przedstawiono wybrane fakty z
rozwoju metod rachunku prawdopodobieństwa. Poczynając od najdawniejszych
czasów, kiedy kwestię losowości wiązano z bóstwami, poprzez pierwsze
próby sformalizowania tych zagadnień, zwykle związane z grami
hazardowymi, aż do wskazania kluczowych osiągnięć rozwoju tej teorii i
najważniejszych naukowców.

W rozdziale drugim omówiono zagadnienia kombinatoryki. W szczególności
uwzględniono kombinacje, wariacje bez powtórzeń i z powtórzeniami oraz
permutacje. Przedstawiono charakterystykę tych pojęć oraz zamieszczono
przykłady wykorzystania podanych wzorów.

W kolejnym rozdziale scharakteryzowano podstawowe zagadnienia niezbędne
do wprowadzenia pojęcia prawdopodobieństwa jak: doświadczenie losowe,
zdarzenie losowe, zdarzenie elementarne i przestrzeń zdarzeń
elementarnych. W dalszej części rozdziału przedstawiono wybrane
definicje prawdopodobieństwa, w tym definicje klasyczną oraz
aksjomatyczną.

W rozdziale czwartym przedstawiono pojęcie zmiennej losowej.
Scharakteryzowano podstawowe własności zmiennych losowych skokowych i
ciągłych. Zaprezentowano pojęcia rozkładu prawdopodobieństwa, gęstości i
dystrybuanty, wartości oczekiwanej oraz wariancji zmiennej losowej.

W rozdziale piątym zaprezentowano wybrane rozkłady zmiennych losowych
skokowych. Uwzględniono zmienne losowe o rozkładach dwupunktowym,
dwumianowym oraz Poissona. Dla omawianych rozkładów przedstawiono ich
najważniejsze charakterystyki.

W rozdziale szóstym zaprezentowano wybrane rozkłady zmiennych losowych
ciągłych. Uwzględniono m.in. zmienne losowe o rozkładach jednostajnym,
trójkatnym, normalnym, \(t\) Studenta oraz chi-kwadrat. Dla tych
rozkładów przedstawiono ich najważniejsze charakterystyki.

W rozdziale siódmym przedstawiono charakterystykę wybranych rozkładów
wielowymiarowych skokowych i ciągłych. Szczególną uwagę zwrócono na
rozkłady dwuwymiarowe, a w szczególności na dwuwymiarowy rozkład
normalny.

W rozdziale ósmym przedstawiono wybrane zagadnienia teoretyczne.
Omówiono funkcje zmiennych losowych, funkcje tworzące momenty zmiennej
losowej oraz funkcje charakterystyczne, a także wybrane twierdzenia
graniczne.

W rozdziałach od 2-7 zamieszczono przykłady z rozwiązaniami a także
zadania do sdamodzielnego rozwiązania i pytania różnego typu pozwalające
Czytelnikowi zweryfikować swoją wiedzę.

Dla uzupełnienia informacji można polecić książki:

\begin{itemize}
\item
  teoria Hellwig (\citeproc{ref-hellwig1998}{1998}), Aczel
  (\citeproc{ref-aczel2000}{2000}), Bratijczuk \& Chydziński
  (\citeproc{ref-bratijczuk2000}{2000}), Krzyśko
  (\citeproc{ref-krzysko2000}{2000}), Jakubowski \& Sztencel
  (\citeproc{ref-jakubowski2004}{2004}), Snopkowski
  (\citeproc{ref-snopkowski2007}{2007}), Kończak
  (\citeproc{ref-konczak2012}{2012})
\item
  zadania Plucińska \& Pluciński (\citeproc{ref-plucinska1983}{1983}),
  Jasiulewicz \& Kordecki (\citeproc{ref-jasiulewicz2010}{2010}) ,
  Krysicki (\citeproc{ref-krysicki2003}{2003}), Trzpiot \& Kończak
  (\citeproc{ref-trzpiot2008}{2008})
\item
  z zakresu popularnonaukowego: Rao (\citeproc{ref-rao1997}{1997}),
  Bernstein et al. (\citeproc{ref-bernstein1997}{1997}), Steinhaus \&
  Kobyliński (\citeproc{ref-steinhaus2010}{2010}),
\end{itemize}

We wszystkich rozdziałach podano także dane o wartościowych źródłach
internetowych informacji z danej tematyki.

W książce przyjęto pewne oznaczenia wybranych fragmentów, a schemat tych
oznaczeń zamieszczono ponizej.

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Określenia pojęć, objaśnienia lub definicje}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-note-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-note-color-frame, colback=white]

To jest określenie pojęcia (definicja???) lub objaśnienie

\end{tcolorbox}

Przykłady (treść przykładu i rozwiązanie)

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład numer}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

Tu jest treść przykładu

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={Rozwiązanie}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

Tu jest rozwiązanie przykładu.

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={***}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

To jest informacja o końcu przykładu.

Twierdzenia i wnioski

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{Twierdzenia i wnioski}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-important-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-important-color-frame, colback=white]

To jest twierdzenie lub wniosek

\end{tcolorbox}

Dla zadań i pytań zamieszczonych na zakończenie rozdziałów 2-7 przyjęto
następujace oznaczenia.

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={Zadania}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-warning-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-warning-color-frame, colback=white]

Tu zamieszczono zadania do materiału z rozdziału

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={Pytania problemowe}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

Tu zamieszczono pytania problemowe do materiału z rozdziału

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={Prawda czy fałsz?}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-caution-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-caution-color-frame, colback=white]

Tu zamieszczono pytania typu ``Tak / Nie'' do materiału z rozdziału

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={Pytania testowe}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-important-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-important-color-frame, colback=white]

Tu zamieszczono pytania testowe z jedną poprawną odpowiedzią do
materiału z rozdziału

\end{tcolorbox}

\bookmarksetup{startatroot}

\chapter{Rys historyczny}\label{rys-historyczny}

Mitologia grecka dla wyjaśnienia początku wszechrzeczy odwołuje się do
gier losowych, a więc w jakiejś mierze do zagadnień związanych z
prawdopodobieństwem. Trzej bracia rzucali kośćmi o władzę nad
wszechświatem: Zeus wygrał niebo, Posejdon otrzymał morza, a przegrany
Hades zstapił do piekieł jako władca podziemnego świata
(\citeproc{ref-bernstein1997}{Bernstein et al., 1997, p. {[}5{]}}).

Już w starożytności ludzie pasjonowali się grami losowymi. Gry takie
były popularne w różnych kulturach. W starożytnym Egipcie, Grecji i
Rzymie znane były gry w kości a także inne gry hazardowe. Malowidła w
egipskich grobowcach, datujące się na 3500 rok przed naszą erą,
przedstawiają partie gry w kości (\citeproc{ref-bernstein1997}{Bernstein
et al., 1997, p. {[}2{]}}). Najstarsze ślady gier w kości znaleziono w
wielu miejscach na świecie m.in. Iranie, archipelagu szkockim i Indiach
\href{https://muduko.com/historia-gry-w-kosci-od-astragali-po-roll-write/}{Muduko}.

W British Museum znajdują się wykorzystywane do gier żetony i tablica
sumeryjska, datowane na ok. 4 tys. lat p.n.e. Z tamtych czasów pochodzi
też gra hazardowa w astragale. Były to kamyki mające 4 strony i każdą z
odpowiednią ilością oczek. Wykorzystywano je nie tylko do gier, ale i do
wróżb, a nawet do podejmowania decyzji
(\href{https://pg.edu.pl/files/cnm/2021-03/2009_10_KN.pdf}{Nowicka
2009}).

W Egipcie nałogowi gracze byli karani obowiązkowymi pracami, ale
jednocześnie sami faraonowie nie mieli oporów przed rozgrywaniem partii,
a niekiedy wykorzystywali do tego celu sfałszowane kostki
(\citeproc{ref-bernstein1997}{Bernstein et al., 1997, p. {[}2{]}}).
Sceny uwidaczniające grających młodzieńców zostały ujęte również na
starożytnych greckich wazach.

W Azji ze starożytnych form wróżbiarstwa rozwinęły się gry karciane. Gry
takie w Europie zyskały znaczną popularność dopiero po wynalezieniu
druku. Uczestnicy gier próbowali przewidzieć wyniki na podstawie
intuicji i obserwacji, ale nie było wówczas formalnych narzędzi
matematycznych do analizy tych zjawisk.

Proste określenia prawdopodobieństwa próbowano formułować jeszcze przed
naszą erą. Arystoteles (około 300 p.n.e.) powiedział, że ``prawdopodobne
jest to, co zwykle się zdarza'', a odnosząc się do rzutów kośćmi
wyróżniał ``rzut łatwiejszy'' i ``rzut trudniejszy''. W starożytnym
Rzymie najlepszy rzut określano mianem ``venus'', a najogorszy był
``rzutem psa''
(\href{https://imperiumromanum.pl/spoleczenstwo/rozrywka-w-starozytnym-rzymie/hazard-antycznych-rzymian/}{Imperium
Romanum}). Cyceron (ok. 60 r. p.n.e.) opisał prawdopodobieństwo jako
``przewodnik życia'' (\citeproc{ref-good1959}{Good, 1959, p.
{[}443{]}}).

Żołnierze Poncjusza Piłata rzucali losy o szatę Jezusa Chrystusa podczas
Jego męki na krzyżu. ``Nie rozdzierajmy jej, ale rzućmy o nią losy, do
kogo ma należeć'' (\emph{Biblia Tysiąclecia}
(\citeproc{ref-biblia2002}{2002, p. 1723}), J 19.23), a z kolei w
Ewangelii Łukasza jest napisane „Potem rozdzielili między siebie Jego
szaty, rzucając losy'' (\emph{Biblia Tysiąclecia}
(\citeproc{ref-biblia2002}{2002, p. 1680}) Łk. 23.34).

W tym czasie cesarz rzymski Klaudiusz (10 p.n.e. - 54) miał specjalnie
dostosowany w powozie stół do gry w kości aby móc grać podczas podróży.
Napisał nawet książkę na temat zasad gry w kości
\href{https://imperiumromanum.pl/spoleczenstwo/rozrywka-w-starozytnym-rzymie/hazard-antycznych-rzymian/}{Klaudiusz}.

Nieco ponad 100 lat później rzymski cesarz Marek Aureliusz (121-180) tak
pasjonował się grami hazardowymi, że zawsze w podróżach towarzyszył mu
krupier. Również setki lat później poważne osobistosci świata
politycznego były zafascynowane grami losowymi. Tak tez było np. w
przypadku Jerzego Waszyngtona (1732-1799), gdzie gry hazardowe często
były uprawiane w jego namiocie podczas rewolucji amerykańskiej
(\citeproc{ref-bernstein1997}{Bernstein et al., 1997, p. {[}2{]}}).

Hinduska epopeja \emph{Mahabharata} napisana przed 400 r. zawiera
historię króla Rtuparny , który przekazuje swoją wiedzę człowiekowi
imieniem Nala, który jest opanowany namiętnością do gry w kości.
Rtuparna jest opisywany jako człowiek zdolny oszacować liczbę liści na
drzewie na podstawie znajomosci liczby liści na przypadkowo wybranej
gałęzi (\citeproc{ref-aczel2000}{Aczel, 2000, p. {[}65{]}}). Dopiero 16
wieków później zostanie sformalizowana teoria wnioskowania
statystycznego o charakterystykach populacji na podstawie prób.

Pewną wiedzę o prawdopodobieństwie wykazywali też rabini działający w
okresie, który nastąpił po zniszczeniu drugiej świątyni jerozolimskiej
(rok 587). W Talmudzie stosowane jest rozumowanie o charakterze
probabilistycznym przy rozważaniu kwestii związanych z dietetyką,
podatkami, ustaleniem ojcostwa oraz cudzołóstwem
(\citeproc{ref-aczel2000}{Aczel, 2000, p. {[}66{]}}).

Za panowania Henryka II (1154-1189) w Mennicy Królewskiej w Londynie
ustanowiono tradycję ceremonii ``Trial of the Pyx''. Słowo ``Pyx'' w
staroagielskim oznacza ``skrzynię'' lub ``puszkę''
(\citeproc{ref-aczel2000}{Aczel, 2000, p. {[}670{]}}). Ceremonia miała
charakter religijny i była związana z oceną jakości złotych monet
wybijanych w mennicy królewskiej. Każdego dnia spośród wykonanych w
mennicy monet wybierano losowo jedną (próbkowanie) ze złota (niekiedy
były to srebrne monety) i wrzucano ją do skrzyni. Co trzy lub cztery
lata skrzynia była otwierana, liczono monety i wyznaczano ich łączną
wagę. Otrzymaną wagę porównywano z ustalonym wzorcem po uwzglednieniu
liczby monet i pewnego zakresu tolerancji. Cała ceremonia pozwalała
królowi sprawować kontrolę nad wykorzystaniem królewskiego złota. Jeśli
monety były zbyt ciężkie, to świadczyło to o marnowaniu złota z
królewskiego skarbca. Jeśli monety były zbyt lekkie, to waluta traciła
na wartości, a ktoś z obsługi mógł czerpać zyski z zaoszczędzonego
złota. Jeśli test zakończył sie pomyślnie, to wydawano ucztę. W
przciwnym przypadku mistrza mennicy mogło czekać więzienie, a nawet
śmierć. Przez wiele lat mistrzem mennicy był wybitny naukowiec Izaak
Newton (1699-1727). W tym czasie jeden z testów nie zakończył się
pomyślnie, ale nie były to już czasy, w których stosowano tak srogie
kary jak we wczesniejszych wiekach (\citeproc{ref-aczel2000}{Aczel,
2000, p. {[}670{]}}). Ceremonia ``Trial of the Pyx'' jest imponujacym
przykładem zastosowania metod probabilistycznych i statystyki na setki
lat przed formalnym opracowaniem zasad rachunku prawdopodobieństwa. W
latach 20. XX wieku Walter A. Shewhart wprowadził karty kontrolne do
monitorowania jakości procesów produkcyjnych
(\citeproc{ref-iwasiewicz2000}{Iwasiewicz \& Paszek, 2000};
\citeproc{ref-konczak2000}{Kończak, 2000}), których idea jest podobna do
opisywanego rozwiązania.

Dopiero w XVII wieku, kiedy hazard stał się popularny w Europie, zaczęto
systematycznie badać i opisywać prawdopodobieństwo, co zapoczątkowało
rozwój tej dziedziny matematyki. To niezwykłe, że gry hazardowe stały za
początkiem nauki, która z czasem stała się kluczowa w rozwoju wielu
dyscyplin naukowych.

W 1499 roku franciszkanin Tomasz Murner zajął się związkiem kart z
matematyką. Wykorzystując karty opracował prawa logiki. Galileusz
(1564--1642) napisał traktat ``\emph{Rozważania nad grą w kości}''.
Jednak pierwszym dojrzałym od strony matematycznej dziełem dotyczącym
gry w kosci jest praca ``\emph{O rachubach gry w kosci}'' CH. Huygensa
(1629--1695) pochodząca z 1657 roku. Pokazującym specyficzne pojęcia i
metody tej nowej gałęzi matematyki.
(\href{https://pg.edu.pl/files/cnm/2021-03/2009_10_KN.pdf}{Nowicka
2009}).

Faktyczny przełom w podejściu do określenia pojęcia prawdopodobieństwa
nastąpił w drugiej połowie XVII wieku, a jego inicjatorem był francuski
szlachcic i hazardzista, Antoine Gombaud (1607-1684), znany jako
Chevalier de Méré. Był on z zamiłowania matematykiem, ale również
namiętnym hazardzistą (\citeproc{ref-bernstein1997}{Bernstein et al.,
1997}{[}XV{]}). Posiadał niezwykłą intuicję do właściwego obstawiania
wyników w grach losowych. Obstawiał często właściwie wyniki, które jego
przciwnicy uważali za czysto losowe z równymi prawdopodobieństwami
wystąpienia. De Mere wielokrotnie obstawiał, że w czterech rzutach
sześcienną kostką do gry wypadnie przynajmniej jedna ``6''. Przez
ówczesnych graczy takie zdarzenie było traktowane jako jednakowo
prawdopodobne ze zdarzeniem przeciwnym. Jednak w rzeczywistości
prawdopodobieństwo takiego zdarzenia wynosi około 0,5177, a więc jest
nieco większe od 0,5 (\citeproc{ref-konczak2012}{Kończak, 2012}). Przy
dużej liczbie gier, de Méré nieco częściej wygrywał niż przegrywał i w
długiej perspektywie pomnażał swój kapitał. De Méré stosował także inną
strategię, która polegała na obstawianiu, że w serii 24 rzutów dwiemia
sześciennymi kostkami zdarzy się wystapienie dwóch ``6''. Rozumowanie
było następujące: obstawienie wyrzucenia ``6'' w czterech rzutach kostką
było korzystne, to jeżeli dołoży się dodatkową kostkę (6 dodatkowych
wariantów, czyli 6 razy 4 to 24) to przy 24 rzutach dwiema kostkami
korzystne będzie obstawienie wystąpienia dwóch ``6''. Jednak stosując
niedostępny wówczas aparat obliczeniowy można łatwo wykazać, że
prawdopodobieństwo wystąpienia przynajmniej raz dwóch ``6'' w 24 rzutach
dwiema kostkami wynosi około 0,4914, a więc nieco mniej niż 0,5.
Wielokrotnie obstawiając taki wariant de Méré poniósł znaczne straty
finansowe. Wątpliwości związane z opisanym zdarzeniem skłoniły go do
zwrócenia się z zapytaniem listownie do Błażeja Pascala (1623 -- 1662).
Innym zagadnieniem, które de Méré poruszył w korespondencji z Pascalem,
był problem podziału wygranej w niedokończonej grze w kości. Wcześniej
to zagadnienie rozważał już Luca Paccioli (1445-1517), matematyk i
franciszkanin uważany za ojca rachunkowosci
(\citeproc{ref-bernstein1997}{Bernstein et al., 1997, pp.
{[}29--31{]}}). Te pytania zapoczątkowały korespondencję między Pascalem
a Pierre'em de Fermat (1601-1661), podczas której obaj matematycy
analizowali różne problemy związane z grami losowymi. Ich wymiana listów
doprowadziła do powstania podstawowych zasad teorii prawdopodobieństwa.
Pascal i Fermat byli pierwszymi, którzy sformułowali zasady
kombinatoryki i zaczęli badać zdarzenia losowe w sposób systematyczny,
co dało początek nowej dziedzinie matematyki. Pascal i Fermat nigdy się
nie spotkali, ale dzięki intensywnej wymianie listów, opracowali metody
obliczania prawdopodobieństwa, które stały się fundamentem dla dalszych
badań w tej dziedzinie.

Tak powoli rodziły się podstawy rachuneku prawdopodobieństwa w znanej
nam formie. Dla dalszego rozwoju w kolejnych dziesięcioleciach niezbędne
było społeczne zaakceptowanie idei, że przyszłość nie jest całkowicie
zdeterminowana i że można ją przewidywać za pomocą liczb. To pokazuje,
że rachunek prawdopodobieństwa nie tylko rozwinął matematykę, ale także
wpłynął na sposób postrzegania świata
(\citeproc{ref-bernstein1997}{Bernstein et al., 1997}{[}s. XVII ???{]}).

W 1703 roku Gottfried von Leibniz (1646 - 1716) w liście do
szwajcarskiego matematyka Jakuba Bernoulliego (1654 - 1705) napisał, że
``\emph{przyroda ustanawia prawidłowości zdarzeń, lecz stosują się one
tylko do większości przypadków}''
(\citeproc{ref-bernstein1997}{Bernstein et al., 1997}{[}s. XVII{]}). To
wskazanie specyfiki losowości zainspirowało Bernolliego do poszukiwań, a
efektem rozważań była m.in. pierwsza książka o zagadnieniach rachunku
prawdopodobieństwa pt.~``Ars Conjectandi'' (``Sztuka przewidywania''). W
swojej pracy opublikowanej pośmiertnie w 1713 roku w Bazylei Bernoulli
wykazał, że przy dużej liczbie prób, średnia wyników zbliża się do
pewnej ustalonej wartości. Twierdzenie udowodnione przez Bernoulliego
nosi nazwę prawa wielkich liczb Bernoulliego
(\citeproc{ref-kaluszka1999}{Kałuszka, 1999}). To odkrycie miało ogromne
znaczenie dla teorii prawdopodobieństwa i statystyki, ponieważ
umożliwiło bardziej precyzyjne przewidywanie wyników w długim okresie
czasu. Bernoulli położył również podwaliny pod rozwój teorii
prawdopodobieństwa jako nauki matematycznej, a jego prace były
kontynuowane przez innych badaczy w XVIII i XIX wieku. Jego badania
kontynuowali inni matematycy, w tym Abraham de Moivre (1667-1754), który
wprowadził pojęcie rozkładu normalnego oraz Karol Gauss (1777-1855),
który zajmował się teorią błędów. Prawo wielkich liczb zostało
wzmocnione między innymi przez rosyjskiego matematyka Pafnutija
Czebyszewa (1821-1894), a także jego uczniów Aandrieja Markowa
(1856-1922) i Aleksandra Lapunowa (1857-1918).

Niespełna sto lat od czasu, gdy Pascal i Fermat podjęli wspólne badania
nad obliczaniem prawdopodobieństw pastor Thomas Bayes (ok. 1702 - 1761)
wskazał na możliwość podejmowania decyzji wykorzystując metodę łączenia
nowych i wcześniejszych informacji
(\citeproc{ref-bernstein1997}{Bernstein et al., 1997}{[}XVII{]}).
Obecnie wzór Bayes'a znajduje szerokie zastosowania w ekonomii,
finansach, medycynie, kryminalistyce, naukach przyrodniczych i wielu
innych dziedzinach.

W 1812 roku P.S. Laplace (1749-1827) sformułował tzw. klasyczną
definicję prawdopodobieństwa zdarzenia losowego, jako miarę sznsy
wystąpienia tego zdarzenia (\citeproc{ref-czaplicki2011}{Czaplicki,
2011}). Prawdopodobieństwo zdarzenia określił on jako stosunek liczby
zdarzeń sprzyjajacych pojawieniu się tego zdarzenia do ogólnej liczby
zdarzeń jednakowo możliwych. Definicja ta ma jednak wiele wad. Można ją
stosować tylko, gdy rozpatrywane zbiory zdarzeń są skończone. Poważną
wadą formalną jest fakt, iż jest to definicja tautologiczna, ponieważ
przy formułowaniu pojęcia prawdopodobieństwa odwołuje się do określenia
jednakowo prawdopodobnych zdarzeń.

O ile pierwsza książka z rachunku prawdopodobieństwa została wydana w
roku 1713, to pierwsza książka o tej tematyce w Polsce ukazała się w
roku 1790, a więc krótko przed całkowitą utratą niepodległości. Autorem
książki ``\emph{Rachunek zdarzeń i przypadków losu}'' był Jan Śniadecki
(1756-1830).
\href{https://pl.wikipedia.org/wiki/Jan_\%C5\%9Aniadecki}{Jan
śniadecki}.

S.D. Poisson (1781-1840)

daty (Kowgier (\citeproc{ref-kowgier2011}{2011}))

W XIX wieku rachunek prawdopodobieństwa znalazł szereg zastosowań w
ekonomii, medycynie, genetyce i w wielu innych dyscyplinach nauki.
Jednak cały czas nie była to sformalizowana matematycznie teoria. W 1900
roku David Hilbert (1862-1943) postawił problem zmatematyzowania teorii
prawdopodobieństwa (\citeproc{ref-kaluszka1999}{Kałuszka, 1999, p.
{[}122{]}}). Chciał, aby teoria prawdopodobieństwa wywodziła się, tak
jak geometria, z układu pojęć pierwotnych i aksjomatów.

W XX wieku Andriej Kołmogorow (1903-1987) doprowadził do ważnego
przełomu w teorii prawdopodobieństwa wprowadzając aksjomatyczny system,
który ujednolicił i sformalizował tę dziedzinę. Kołmogorow zdefiniował
prawdopodobieństwo jako miarę przypisaną zdarzeniom losowym, spełniającą
określone aksjomaty. Wprowadzony w 1933 roku w pracy „Podstawowe pojęcia
teorii prawdopodobieństwa'' aksjomatyczny model jest podstawą
współczesnych badań i praktyki w zakresie analizy ryzyka, teorii gier
oraz statystyki. Jego podejście umożliwiło rozwój nowoczesnej teorii
prawdopodobieństwa i jej zastosowanie w różnych dziedzinach nauki,
takich jak fizyka, ekonomia, biologia i informatyka. Dzięki wprowadzeniu
definicji aksjomatycznej rachunek prawdopodobieństwa stał się integralną
częścią matematyki i narzędziem niezbędnym w analizie zjawisk losowych.

\bookmarksetup{startatroot}

\chapter{Elementy kombinatoryki}\label{elementy-kombinatoryki}

Kombinatoryka to dział matematyki, którego przedmiotem jest obliczanie
liczby zbiorów, w jakie można łączyć, w określony sposób, przedmioty
należące do danego zbioru skończonego
(\citeproc{ref-bratijczuk2000}{Bratijczuk \& Chydziński, 2000, p.
{[}23{]}}).

W tym rozdziale zostaną omówione kombinacje, wariacje bez powtórzeń,
wariacje z powtórzeniami oraz permutacje. W przedstawionych w niniejszym
rozdziale wzorach wykorzystywany będzie symbol (!) silni. Silnia jest
obliczana następujaco:

\begin{equation}\phantomsection\label{eq-silnia}{n! = 1 \cdot 2 \ldots \cdot n, \text{dla } n \ge 1}\end{equation}
Dodatkowo określa się, że

\[0! = 1\]

Zagadnienia omawiane w tym rozdziale są szeroko opisane w literaturze.
Czytelnik może poszerzyć swą wiedzę odwołując sie do np. Kowgier
(\citeproc{ref-kowgier2011}{2011, pp. 18--24}), Bratijczuk \& Chydziński
(\citeproc{ref-bratijczuk2000}{2000, pp. 23--35}), Kałuszka
(\citeproc{ref-kaluszka1999}{1999, pp. 20--31}), Hellwig
(\citeproc{ref-hellwig1998}{1998, pp. 9--18}). Po przedstawieniu
teoretycznym oraz przytoczeniu odpowiednich wzorów podane zostaną
przykłady oraz zestawy zadań i pytań.

Uzupełnienia:
\href{https://www.matemaks.pl/kombinatoryka.html}{Kombinatoryka}

\href{https://www.edukator.pl/resources/page/kombinatoryka-i-rachunek-prawdopodobienstwa/11041}{Kombinatoryk\_lic}

\href{https://www.math.edu.pl/kombinatoryka}{Kombinatoryka}

\section{Kombinacje}\label{kombinacje}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Kombinacje}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-note-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-note-color-frame, colback=white]

\(k\)-Elementową kombinacją zbioru \(n\)-elementowego \(A\) nazywa się
każdy \(k \ (k \le n)\) elementowy podzbiór zbioru \(A\).

\end{tcolorbox}

Liczba kombinacji podaje na ile sposobów można wybrać \(k\) elementów
spośród \(n\) elementów. Liczbę takich kombinacji oznacza się symbolem
\(C_n^k\) i wyraża się ona następującym wzorem:

\begin{equation}\phantomsection\label{eq-komb}{C_n^k = \binom{n}{k} = \frac{n!}{k!(n-k)!}}\end{equation}

\subsubsection*{Trójkąt Pascala}\label{truxf3jkux105t-pascala}
\addcontentsline{toc}{subsubsection}{Trójkąt Pascala}

Liczbę kombinacji dla różnych wartości \(k\) i \(n\) można zwizualizować
wykorzystując trójkąt Pascala. Jest to uporządkowany zbiór liczb w
formie trójkąta (zob rys.~\ref{fig-tr_Pascal}) . Na samej górze trójkąta
znajduje się liczba 1. To jest pierwszy wiersz trójkąta Pascala. Każdy
wiersz zaczyna się i kończy liczbą 1. Każda liczba w wierszu, która nie
jest na brzegu (pierwsza lub ostatnia w wierszu), jest sumą dwóch liczb
bezpośrednio nad nią z poprzedniego wiersza.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{r02_files/figure-pdf/fig-tr_Pascal-1.pdf}}

}

\caption{\label{fig-tr_Pascal}Trójkąt Pascala}

\end{figure}%

Na rys.~\ref{fig-tr_Pascal} przedstawiono pierwsze 6 wierszy trójkąta
Pascala, są to wiersze od \(n = 0\) do \(n = 5\). W wierszu
przedostatnim są umieszczone liczby: \(1, 4, 6, 4 \text { i } 1\).
Odpowiadają one kolejno następującym kombinacjom:
\(\binom{4}{0}, \binom{4}{1}, \binom{4}{2}, \binom{4}{3}, \binom{4}{4}\).
W szczególności trzecia liczba w przedostatnim wierszu, czyli 6,
odpowiada liczbie kombinacji \(\binom{4}{2}\).

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 2.1}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

Na ile sposobów można wybrać spośród 5 osób delegację trzyosobową?

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={Rozwiązanie}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

Liczba elementów zbioru wynosi \(n=5\). Liczba wybieranych osób wynosi
\(k=3\). Wobec tego liczba możliwości wyznaczana jest następująco:

\[ C_5^3=\binom{5} {3}=\frac{5!}{3!(5-3)!}=\frac{4 \cdot 5}{2}=10\]

Delegację 3 osobową spośród 5 osób można wybrać na 10 sposobów.

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 2.2}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 2.3}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 2.4}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\section{Wariacje z powtórzeniami}\label{wariacje-z-powtuxf3rzeniami}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Wariacje z powtórzeniami}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-note-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-note-color-frame, colback=white]

\(k\)-Elementową wariacją z powtórzeniami \(n\)-elementowego zbioru
\(A\) nazywa się każdy ciąg o długości \(k\) złożony z elementów zbioru
\(A\) z możliwością wystąpienia powtórzeń elementów.

\end{tcolorbox}

Liczbę \(k\)-elementowych wariacji z powtórzeniami zbioru
\(n\)-elementowego oznacza się symbolem \(V_n^k\) i wyznacza się na
podstawie wzoru:

\begin{equation}\phantomsection\label{eq-war_powt}{V_n^k = n^k}\end{equation}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 2.5}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 2.6}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 2.7}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 2.8}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\section{Wariacje bez powtórzeń}\label{wariacje-bez-powtuxf3rzeux144}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Wariacje bez powtórzeń}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-note-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-note-color-frame, colback=white]

\(k\)-Elementową wariacją bez powtórzeń \(n\)-elementowego zbioru \(A\)
nazywa się każdy ciąg o długości \(k\) złożony z elementów zbioru \(A\),
gdzie nie występują powtórzenia elementów.

\end{tcolorbox}

Liczbę \(k\)-elementowych wariacji bez powtórzeń zbioru \(n\)
elementowego oznacza się symbolen \(\bar{V}_n^k\). Liczbę takich
wariacji wyznacza się na podstawie następującego wzoru:

\begin{equation}\phantomsection\label{eq-war_bezpowt}{\bar{V}_n^k = \frac{n!}{(n-k)!} }\end{equation}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 2.9}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 2.10}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 2.11}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 2.12}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\section{Permutacje}\label{permutacje}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Permutacje}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-note-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-note-color-frame, colback=white]

\(n\)-Elenentową permutacją zbioru \(A\) o liczbie elementów \(n\)
nazywa się każdy ciąg elementów tego zbioru o długosci \(n\) bez
powtarzania się elementów.

\end{tcolorbox}

Permutacja zbioru to ustawienie wszystkich \(n\) elementów w ciąg o
długosci \(n\) bez powtórzeń. Liczbę permutacji zbioru \(n\)
elementowego oznacza się symbolem \(P_n\) i oblicza następująco:

\begin{equation}\phantomsection\label{eq-permut}{P_n = n!}\end{equation}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 2.13}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 2.14}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 2.15}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 2.16}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\section{Zadania i pytania}\label{zadania-i-pytania}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={Zadania}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-warning-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-warning-color-frame, colback=white]

\end{tcolorbox}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
\item
\item
\item
\item
\end{enumerate}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={Pytania problemowe}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
\item
\item
\item
\item
\end{enumerate}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={Prawda czy fałsz?}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-caution-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-caution-color-frame, colback=white]

\end{tcolorbox}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
\item
\item
\item
\item
\end{enumerate}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={Pytania testowe}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-important-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-important-color-frame, colback=white]

\end{tcolorbox}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
\item
\item
\item
\item
\end{enumerate}

\bookmarksetup{startatroot}

\chapter{Zdarzenia losowe i
prawdopodobieństwo}\label{zdarzenia-losowe-i-prawdopodobieux144stwo}

We wszystkich teoriach naukowych istnieją pojęcia pierwotne, których się
nie definiuje. W arytmetyce jest to np. liczba, w teorii mnogości jest
to zbiór, a w geometrii punkt, prosta czy płaszczyzna
(\citeproc{ref-bratijczuk2000}{Bratijczuk \& Chydziński, 2000}).

Pojęciami pierwotnymi, a więc niedefiniowanymi, w teorii rachunku
prawdopodobieństwa są zdarzenie elementarne \(\omega\) oraz przestrzeń
zdarzeń elementarnych \(\Omega\) (\citeproc{ref-krysicki2003}{Krysicki,
2003, p. {[}7{]}}) związane z doświadczeniem losowym \(D\). Pomimo braku
formalnej definicji można te zagadnienia opisać i podać szereg
przykładów przestrzeni zdarzeń elementarnych dla różnych doświadczeń
losowych.

\href{https://www.math.edu.pl/zdarzenia-losowe}{Zdarzenie losowe}

\href{https://www.edukator.pl/resources/page/rachunekprawdopodobiestwa/778}{Podfstawy}

\href{https://www.matemaks.pl/rachunek-prawdopodobienstwa.html}{Podstawowe
pojęcia}

\href{https://szaloneliczby.pl/prawdopodobienstwo/}{Klasyczne}

\section{Podstawowe pojęcia}\label{podstawowe-pojux119cia}

Przed określeniem prawdopodobieństwa niezbędne jest wprowadzenie
następujących pojęć (por. Kowgier (\citeproc{ref-kowgier2011}{2011}),
Krysicki (\citeproc{ref-krysicki2003}{2003}),Bratijczuk \& Chydziński
(\citeproc{ref-bratijczuk2000}{2000})):

\begin{itemize}
\item
  doświadczenie losowe,
\item
  zdarzenie losowe,
\item
  zdarzenie elementarne,
\item
  przestrzeń zdarzeń elementarnych.
\end{itemize}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Doświadczenie losowe}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-note-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-note-color-frame, colback=white]

Doświadczenie losowe, to pewien eksperyment, którego wyniku nie można
jednoznacznie przewidzieć.

\end{tcolorbox}

Doswiadczenie (eksperyment) określane jest jako losowe, jesli przy
kolejnych jego powtórzeniach w identycznych warunkach można otrzymywać
różne wyniki. Przykładami doświadczeń losowych są:

\begin{itemize}
\item
  Jednokrotny rzut monetą.
\item
  Jednokrotny rzut sześcienną kostką do gry.
\item
  Trzykrotny rzut sześcienną kostką do gry.
\item
  Losowanie kuli z urny, w której jest 5 kul białych i 3 czarne.
\item
  Cena zamknięcia akcji spółki \(X\) podczas ustalonej sesji giełdowej.
\end{itemize}

\textbf{Przykład}. Jednokrotny rzut monetą.

W jednym rzucie symetryczną monetą możliwe są dwa rezultaty, które
zwykle oznaczane są symbolami ``O'' (orzeł) i ``R'' (reszka).

\textbf{Przykład}. Jednokrotny rzut sześcienną kostką do gry.

Przy rzucie sześcienną kostką do gry możlwych jest 6 następujących
wyników: \(1, 2, 3, 4, 5, 6\).

\textbf{Przykład}. Trzykrotny rzut monetą.

Przy trzykrotnym rzucie monetą liczba wszystkich możliwych rezultatów
wynosi 8 (\(\bar{V_2^3}=2^3=8\)). Symbolicznie wszystkie możliwe wyniki
takiego doświadczenia można zapisać następująco:

(O,O,O), (O,O,R), (O,R,O), (O,R,R), (R,O,O), (R,O,R), (R,R,O), (R,R,R).

Realizacja doświadczenia losowego prowadzi do uzyskania jakiegoś wyniku.
Może to być np. liczba oczek uzyskana w rzucie kostką, kolor wylosowanej
z urny kuli lub cena zamknięcia akcji danej spółki podczas ustalonej
sesji giełdowej. Wynik doświadczenia losowego, to zdarzenie losowe, a do
oznaczenia zdarzeń losowych zwykle używa się dużych liter:
\(A, B, C ...\).

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Zdarzenie losowe}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-note-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-note-color-frame, colback=white]

Zdarzenie losowe to wynik doświadczenia losowego.

\end{tcolorbox}

Doświadczenie losowe zwykle jest opisywane słownie np. ``otrzymano
parzystą liczbę oczek w rzucie kostką'', ale często można to zdarzenie
opisać w sposdób nieco bardziej sformalizowany, np. wymieniając
zdarzenia elementerne wchodzące w skład danego zdarzenia losowego.

Niech doświadczenie losowe polega na dwukrotnym rzucie sześcienną kostką
do gry. Przykładami zdarzeń losowych w takim doświadczeniu są:

\(A\) - suma wyrzuconych oczek jest większa od 9.

\(A=\{{(6,6), (6,5), (6,4), (5,6), (5,5), (4,6)\}}\)

\(B\) - na pierwszej kostce otrzymano 6 oczek.

\(B = {(6,1), (6,2), (6,3), (6,4), (6,5), (6,6)}\)

\(C\) - na obu kostach otrzymano 6 oczek.

\(C = {(6,6)}\)

W powyższych przykładach poza słownym opisem doświadczenia losowego
przedstawiono także zapis formalny.

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Zdarzenie elementarne}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-note-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-note-color-frame, colback=white]

Zdarzenie elementarne, to niepodzielny wynik doświadczenia losowego.

\end{tcolorbox}

Zdarzenia elementarne zwykle oznaczane są przez \(\omega\).

Niech doświadczenie losowe polega na dwukrotnym rzucie sześcienną kostką
do gry. Przykładami zdarzeń elementarnych w takim doświadczeniu są:

\(C= \{{(6,6)}\}\)

\(D= \{{(4,3)}\}\)

\(E\) - suma wyrzuconych oczek wynosi 2

\(E = \{{(1,1)}\}\)

Zdarzenie losowe:

\(F\)- suma oczek wynosi 3 - nie jest zdarzeniem elementanym, ponieważ

\(F = \{{(1,2),(2,1)}\}\)

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Przestrzeń zdarzeń elementarnych}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-note-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-note-color-frame, colback=white]

Zbiór wszystkich zdarzeń elementranych określa sie mianem przestrzeni
zdarzeń elementarnych i oznacza zwykle symbolem \(\Omega\).

\end{tcolorbox}

W doświadczeniu polegającym na jednokrotnym rzucie sześcienną kostką do
gry, przestrzeń zdarzeń elementarnych jest następująca:

\[\Omega=\{{1,2,3,4,5,6\}}\] Liczba wszystkich zdarzeń elementarnych
nazywana jest mocą zbioru \(\Omega\). W omawianym przypadku
jednokrotnego rzutu szescienną kostką do gry jest to:

\[ |\Omega| = 6\]

Do oznaczenia mocy zbioru stosuje się niekiedy następujące oznaczenie:

\[ \overline {\overline \Omega} = 6.\]

Jeśli doświadczenie losowe polega na trzykrotnym rzucie symetryczną
monetą, to przestrzeń zdarzeń elementarnych jest następująca:

\[\Omega=\{{ (O,O,O), (O,O,R), (O,R,O), (O,R,R), (R,O,O), (R,O,R), (R,R,O), (R,R,R)    \}}\]

Liczba zdarzeń elementarnych w tym przypadku wynosi:

\[ |\Omega| = 2^3 = 8.\]

\section{Rachunek zdarzeń losowych}\label{rachunek-zdarzeux144-losowych}

Z powyższych określeń wynika, że zdarzenia losowe są zbiorami. Możliwe
jest wykonywanie na nich działań jak w rachunku zbiorów. Przed
określeniem takich działań przedstawiona zostanie stosowna terminologia
dotycząca zdarzeń losowych:

\(\Omega\) - zdarzenie losowe pewne

\(\emptyset\) - zdarzenie losowe niemożliwe

\(A \cup B\) - suma zdarzeń losowych \(A\) i \(B\)

\(A \cap B\) - iloczyn (koniunkcja, przekrój) zdarzeń losowych \(A\) i
\(B\)

\(A \setminus B\) - róznica zdarzeń losowych \(A\) i \(B\)

\(A'=\Omega \setminus A\) - zdarzenie losowe przeciwne do zdarzenia
\(A\), dopełnienie zdarzenia \(A\)

\(A \Rightarrow B \text{ lub }  A \subseteq B\) - zajście zdarzenia
losowego \(A\) pociąga za sobą zajście zdarzenia \(B\).

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Zdarzenie losowe A}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-note-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-note-color-frame, colback=white]

Wynik doświadczenia losowego to zdarzenie losowe. Jest to podzbiór
przestrzeni zdarzeń elementarnych, składający się wyłącznie ze zdarzeń
elementarnych sprzyjajacych danemu zdarzeniu losowemu \(A\).

\end{tcolorbox}

W jednokrotnym rzucie kostką przestrzeń zdarzeń elementarnych jest
określona następujaco:

\[\Omega = \{{1,2,3,4,5,6}\}.\]

Jeżeli rozpatrywane jest zdarzenie losowe \(A\) odpowiadające wyrzuceniu
parzystej liczby oczek, to zdarzenie losowe \(A\) składa się z trzech
zdarzeń elementarnych. Zdarzenie losowe \(A\) można zapisać następująco:

\[A=\{{2,4,6}\}.\]

Na rys.~\ref{fig-zdA} symbolicznie przedstawiono zdarzenie \(A\).
Zaznaczony obszar, to zbiór wszystkich zdarzeń elementarnych
sprzyjających zdarzeniu \(A\).

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{r03_files/figure-pdf/fig-zdA-1.pdf}}

}

\caption{\label{fig-zdA}Zdarzenie A}

\end{figure}%

\subsection{Działania na zdarzeniach
losowych}\label{dziaux142ania-na-zdarzeniach-losowych}

W rachunku zdarzeń można dokonywać różnych działań, jak np. obliczanie
sumy, iloczynu czy różnicy zdarzeń losowych. Możliwe jest także
wyznaczanie zdarzenia prezciwnego (dopełnienia) do danego zdarzenia.
Poniżej scharakteryzowano takie operacje i przedstawiono je graficznie.

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Suma zdarzeń \(A\) i \(B\)}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-note-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-note-color-frame, colback=white]

Sumą zdarzeń \(A\) i \(B\) jest zbiór składajacy się ze zdarzeń
elementarnych należących do zdarzenia losowego \(A\) lub do \(B\).

\end{tcolorbox}

Na rys.~\ref{fig-suma} przedstawiono w formie graficznej sumę zdarzeń
\(A\) i \(B\).

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{r03_files/figure-pdf/fig-suma-1.pdf}}

}

\caption{\label{fig-suma}Suma zdarzeń losowych}

\end{figure}%

Do zdarzenia będącego sumą tych zdarzeń należą wszystkie zdarzenia
elementarne sprzyjające zdarzeniu \(A\) lub \(B\).

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Iloczyn zdarzeń \(A\) i \(B\)}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-note-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-note-color-frame, colback=white]

Iloczynem (albo koniunkcją, przekrojem) zdarzeń \(A\) i \(B\) jest zbiór
składający się ze zdarzeń elementarnych należących jednocześnie do
zdarzenia losowego \(A\) i do \(B\).

\end{tcolorbox}

Na rys.~\ref{fig-iloczyn} przedstawiono w formie graficznej iloczyn
zdarzeń \(A\) i \(B\)

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{r03_files/figure-pdf/fig-iloczyn-1.pdf}}

}

\caption{\label{fig-iloczyn}Iloczyn (koniunkcja, przekrój) zdarzeń
losowych}

\end{figure}%

Do iloczynu zdarzeń \(A\) i \(B\) należą te zdarzenia elementarne, które
sprzyjają jednocześnie zdarzeniu \(A\) i \(B\).

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Różnica zdarzeń A i B}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-note-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-note-color-frame, colback=white]

Różnicą dwóch zdarzeń \(A\) i \(B\) jest zbiór składajacy się ze
zdarzeń, które należą do zdarzenia losowego \(A\) i jednoczesnie nie
należą do \(B\).

\end{tcolorbox}

Na rys.~\ref{fig-roznica} przedstawiono w formie graficznej różnicę
zdarzeń \(A\) i \(B\)

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{r03_files/figure-pdf/fig-roznica-1.pdf}}

}

\caption{\label{fig-roznica}Różnica zdarzeń losowych}

\end{figure}%

Różnica zdarzeń losowych \(A\) i \(B\), to zbiór zdarzeń elementarnych
sprzyjających zdarzeniu \(A\) i nie należących do zdarzenia \(B\).

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Zdarzenie przeciwne (dopełnienie) do zdarzenia A}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-note-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-note-color-frame, colback=white]

Zdarzenie przeciwne do zdarzenia \(A\), to zdarzenie \(A'\), w skład
którego wchodzą wszystkie zdarzenia elementarne nie należące do
zdarzenia \(A\).

\end{tcolorbox}

Zdarzenie przeciwne do zdarzenia A składa się ze zdarzeń elementarnych,
które nie należą do A. Zdarzenie przeciwne do zdarzenia A oznaczane jest
jako \(A'\) lub \(\overline A\) .

Na rys.~\ref{fig-dop} przedstawiono schematycznie dopełnienie zdarzenia
\(A\).

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{r03_files/figure-pdf/fig-dop-1.pdf}}

}

\caption{\label{fig-dop}Zdarzenie A i zdarzenie A' do niego przeciwne}

\end{figure}%

Oczywiście spełnione są następujące warunki

\[ A \cup A' = \Omega\] \[  (A')' = A\] \[  \Omega' = \emptyset\]
\[   \emptyset' =   \Omega \]

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Zdarzenia wykluczajace się (lub rozłączne)}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-note-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-note-color-frame, colback=white]

Zdarzenia wykluczające się to zdarzenia losowe, których koniunkcja jest
zbiorem pustym.

\end{tcolorbox}

Przedstawione symbolicznie na rys.~\ref{fig-roz} zdarzenia \(A\) i \(B\)
sa zdarzeniami rozłączymi. Koniunkcja (iloczyn) tych zdarzeń jest
zbiorem pustym.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{r03_files/figure-pdf/fig-roz-1.pdf}}

}

\caption{\label{fig-roz}Suma zdarzeń losowych}

\end{figure}%

Zdarzenia losowe \(A\) i \(B\) określane są jako zdarzenia wykluczające
się, jeśli spełniony jest następujący warunek:

\[ P(A \cap B) = \emptyset\]

Poniżej przedstawiono najważniejsze własności działań na zdarzeniach
losowych (por. Krysicki (\citeproc{ref-krysicki2003}{2003, p. 10})).

\[ A \cup B = B \cup A \]

\[ A \cap B = B \cap A \]

\[ A \cup (B \cup C) = (A \cup B) \cup C \]

\[ A \cap (B \cap C) = (A \cap B) \cap C \]

\[ A \cap (B \cup C) = (A \cap B) \cup (A \cap C) \]

\[ A \cup (B \cap C) = (A \cup B) \cap (A \cup C) \]
\[(A \cup B)' = A' \cap B'\] \[(A \cap B)' = A' \cup B'\]

\subsection{Sigma ciało zdarzeń}\label{sigma-ciaux142o-zdarzeux144}

Dla określenia pojęcia prawdopodobieństwa niezbędne jest wproawdzenie
pojęcia \(\sigma\)-ciała (sigma ciało) zdarzeń. Niepustą klasę zdarzeń
\(\mathcal{F}\) utworzonych z pewnej przestrzeni \(\Omega\) nazywa się
\(\sigma\)-ciałem jeśli spełnia ona następujace warunki (por. Hellwig
(\citeproc{ref-hellwig1998}{1998, p. 28}), Wywiał
(\citeproc{ref-wywial2004}{2004, p. 16}))

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(\emptyset \in \mathcal{F}\)
\item
  \(A \in \mathcal{F} \Rightarrow A' \in \mathcal{F}\)
\item
  \(A_1, A_2, \ldots \in \mathcal{F} \Rightarrow \bigcup_{i=1}^{\infty} A_i \in \mathcal{F}\)
\end{enumerate}

Z pierwszych dwóch warunków wynika bezpośrednio, że dla dowolnego
\(\sigma\)-ciała \(\mathcal{F}\)

\[ \Omega \in \mathcal{F}.\] Wprowadzenie pojęcia \(\sigma\)-ciała
zdarzeń pozwala na określenie prawdopodobieństwa. Wybór odpowiedniego
\(\sigma\)-ciała pozwala dostosować model probabilistyczny do specyfiki
rozważanego problemu. \(\sigma\)-ciało zdarzeń jest kluczowym elementem
formalnej definicji przestrzeni probabilistycznej, umożliwiającym spójne
podejście do modelowania zjawisk losowych.

\section{Przykłady - rachunek
zdarzeń}\label{przykux142ady---rachunek-zdarzeux144}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 3.1}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 3.2}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 3.3}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 3.4}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 3.5}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 3.6}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

XXXXXXXXXXXXXXXXX

\section{Wybrane określenia i definicje
prawdopodobieństwa}\label{wybrane-okreux15blenia-i-definicje-prawdopodobieux144stwa}

W ostatnich stuleciach podejmowano różne próby dla określenia pojęcia
prawdopodobieństwa. Charakteryzując pojęcie prawdopodobieństwa Aczel
(\citeproc{ref-aczel2000}{2000, p. 65}) określa je jako ilościową miarę
niepewności. Wskazuje, że jest to liczba, która wyraża siłę przekonania
o tym, że zajdzie niepewne zdarzenie. Poniżej przedstawiono wybrane
definicje prawdopodobieństwa. Wraz z przykładami ich zastosowań.

\subsection{Definicja klasyczna}\label{definicja-klasyczna}

Niech \(n\) będzie liczbą wszystkich zdarzeń losowych elementarnych
jednakowo prawdopodobnych, a \(k\) liczbą takich zdarzeń sprzyjajacych
zdarzeniu \(A\). Prawdopodobieństwa zdarzenia \(A\) to iloraz liczby
zdarzeń elementarnych sprzyjających zdarzeniu \(A\) do liczby wszystkich
zdarzeń elementarnych jednakowo prawdopodobnych.

\begin{equation}\phantomsection\label{eq-pr_klas}{ P(A) = \frac{k}{n}}\end{equation}

Wzór ten można zapisać odwołując się do liczby elentów zbioru \(A\)
wprowadzając oznaczenie: \[ |A|=k\] gdzie symbol \(|A|\) oznacza moc
zbioru \(A\), co dla zbiorów skończonych odpowiada liczbie elementów
tego zbioru. Wówczas wzór \ref{eq-pr_klas} może być zapisany następująco

\[ P(A) = \frac{|A|}{|\Omega|}.\]

Dla wyznaczenia prawdopodobieństwa uzyskania parzystej liczby oczek w
rzucie sześcienną kostką do gry należy określić przestrzeń zdarzeń
elementarnych \(\Omega\) oraz zbiór \(A\) i ich liczbę elementów. W
omawianym przypadku zdarzenia można zapisać następująco:

\(\Omega = \{{1,2,3,4,5,6}\}\)

\(A=\{{2,4,6}\}\)

Na podstawie definicji klasycznej otrzymuje się:

\[ P(A) = \frac{|A|}{|\Omega|}=\frac{3}{6}=\frac{1}{2}\] Wynik jest
zgodny z oczekiwaniami. Prawdopodobieństwo uzyskania parzystej liczby
oczek w jednokrotnym rzucie sześcienną kostką do gry wynosi
\(\frac{1}{2}\).

Przedstawiona definicja (klasyczna), mimo że prosta i intuicyjna,
charakteryzuje się jednak bardzo poważną wadą, Definiując pojęcie
``prawdopodobieństwa'' wykorzystano określenie ``jednakowo
prawdopodobne''. To definicja przez tautologię. Nie jest dopuszczalne
definiowanie pojęć z wykorzystaniem pojęcia definiowanego. Podana
definicja nie spełnia formalnych wymogów matematycznych, dlatego zostaną
przedstawione inne stosowane definicje prawdopodobieństwa.

\subsection{Definicja statystyczna}\label{definicja-statystyczna}

Jeżeli \(n\) jest liczbą przeprowadzonych doświadczeń, a \(m\) liczbą
wyników tych doświadczeń, które sprzyjają zdarzeniu \(A\) (np.
wyrzucenie parzystej liczby oczek w rzucie sześcienną kostką do gry), to
prawdopodobieństwo zajścia zdarzenia \(A\) można wyrazić następujaco:

\begin{equation}\phantomsection\label{eq-pr_stat}{ P(A) \approx \frac{m}{n}}\end{equation}

Definicja statystyczna nie podaje dokładnej wartości prawdopodobieństwa
zdarzenia \(A\), a jedynie jego przybliżoną wartość. Dla dobrego
przybliżenia niezbędne jest, aby liczba wykonanych doświadczeń \(n\)
była znaczna.

Francuski przyrodnik Georges-Louis Leclerc de Buffon (1707 - 1788)
rzucał monetą 4040 i otrzymał 2048 razy orła. Na tej podstawie uzyskał
przybliżoną wartość prawdopodobieństwa wyrzucenia orła
(\citeproc{ref-lange1970}{Lange \& Banasiński, 1970, p. {[}21{]}}):

\[ P(A) \approx \frac{2048}{4040}=0,50693\]

Angielski statystyk Karol Pearson (1857 - 1936) rzucał monetą 24000 razy
uzyskując 12012 razy orła. Na tej podstawie uzyskał ocenę
prawdopodobieństwa wyrzucenia orła w pojedynczym rzucie monetą:

\[ P(A) \approx \frac{12012}{24000}=0,5005\] Obaj wybitni naukowcy
uzyskali zbliżone wyniki i bliskie wartosci 0,5. Jednak zastosowanie
deficji statystycznej nie prozwadzi do uzyskania dokładnej wartości
szukanego prawdopodobieństwa, a jedynie jego przybliżonej wartości.

\subsection{Definicja geometryczna}\label{definicja-geometryczna}

Idea definicji geometrycznej prawdopodobieństwa zostanie przedstawiona
na przykładzie wyznaczania prawdopodobieństwa spotkania się dwóch osób.

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 3.7. Spotkanie dwóch osób}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

Jaś i Małgosia umówili się na spotkanie w kawiarence. Ustalili, że oboje
przyjdą niezależnie pomiędzy godziną 17:00 a 18:00. Przyjęli jednak, że
każde z nich będzie czekało na drugą osobę dokładnie 20 minut. Obliczyć
prawdopodobieństwo, że Jaś i Małgosia spotkają się ustalonego dnia w
kawiarence.

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={Rozwiązanie}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

W rozważanym przypadku nie można jednoznacznie stwierdzić, czy Jaś i
Małgosia w ustalonym dniu spotkają się w kawiarence.

Oto przykłady czasu przyjścia do kawiarenki, gdy osoby się spotkają:

\begin{itemize}
\tightlist
\item
  Jaś 17:10, Małgosia 17:25
\item
  Jaś 17:30, Małgosia 17:32
\item
  Jaś 17:55, Małgosia 17:40
\end{itemize}

Przykłady czasu przyjścia do kawiarenki, gdy osoby się nie spotkają:

\begin{itemize}
\tightlist
\item
  Jaś 17:10, Małgosia 17:45
\item
  Jaś 17:30, Małgosia 17:55
\item
  Jaś 17:55, Małgosia 17:15
\end{itemize}

Widoczne jest, że opisane doświadczenie jest zdarzeniem losowym,
ponieważ wyniku tego doświadczenia nie można jednoznacznie przewidzieć.
Zasadne jest wobec tego pytanie o prawdopodobieństwo zdarzenia, że Jaś i
Małgosia spotkają się ustalonego dnia w kawiarence. Niech \(A\) oznacza
zdarzenie losowe, że ustalonego dnia Jaś i Małgosia spotkają się w
kawiarence.

Nietrudno zauważyć, że nie można bezpośrednio określić skończonego
zbioru zdarzeń elementarnych jednakowo prawdopodobnych. Nie jest więc
możliwe, do obliczenia szukanego prawdopodobieństwa, zastosowanie
definicji klasycznej.

Trudno także zastosować definicję statystyczną. Dla uzyskania, wyłącznie
przybliżonej wartości prawdopodobieństwa, należałoby planować codzienne
spotkania przez kilka lat i za każdym razem rejestrować, czy osoby się
spotkały, czy nie. Ostatecznie nie uzyskanoby wartości szukanego
prawdopodobieństwa, a jedynie jego przybliżoną wartość.

Z pomocą w takim przypadku przychodzi definicja geometryczna
prawdopodobieństwa. Niech \(x\) oznacza czas przybycia do kawiarenki
Jasia, a \(y\) czas przyjścia Małgosi. Przyjmując, że czas zostanie
zapisany w godzinach licząc od 17:00 zarówno \(x\) jak i \(y\) mogą
przyjmować wartości od 0 do 1.

Warunek spotkania (realizacja zdarzenia \(A\)) można zapisać
następująco:

\[ |x-y| \le \frac{1}{3}\] gdzie \(x, y \in [0,1]\).

Warunek ten można zapisać równoważnie w postaci układu dwóch
nierówności:

\[
\begin{cases} 
x-y \le \frac{1}{3} \\
y-x \le \frac{1}{3}
\end{cases}
\] gdzie \(x, y \in [0,1]\).

Na rys.~\ref{fig-jm} przedstawiono graficznie rozwiązanie rozważanego
warunku.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{r03_files/figure-pdf/fig-jm-1.pdf}}

}

\caption{\label{fig-jm}Obszar zdarzenia A}

\end{figure}%

Prawdopodobieństwo zdarzenia \(A\) można określić jako stosunek pola
zaznaczonego obszaru, do pola całego obszaru (przestrzeń zdarzeń
elementarnych). W omawianym przypadku może to być zapisane następująco:

\begin{equation}\phantomsection\label{eq-pr_geom}{P(A) = \frac{\mu(A)}{\mu({\Omega})}}\end{equation}

gdzie \(\mu(.)\) oznacza miarę zbioru, a w omawianym przypadku będzie to
pole zbioru.

Pole całego obszaru to pole kwadratu o boku 1, a więc pole to wynosi 1.
Pole obszaru \(A\) wygodnie obliczyć jako różnicę pomiędzy polem całego
zaznaczonego na rys.~\ref{fig-jm} kwadratu, a sumą dwóch pól trójkątów.
Odwołując się do wzoru \ref{eq-pr_geom} szukane prawdopodobieństwo
wynosi:

\[P(A) = \frac{1-2\cdot\frac{1}{2}\frac{2}{3}\frac{2}{3}}{1}=\frac{5}{9}\]

W tym przypadku pole zaznaczonego obszaru wynosi \(\frac{5}{9}\). Łatwo
można dostrzec, że zmieniając nieco warunki zadania, np. czas
oczekiwania na drugą osobę na 15 lub 35 minut, uzyska się inny rezultat,
ale definicja geometryczna będzie we wszystkich takich przypadkach
skuteczna.

\subsection{Definicja aksjomatyczna}\label{definicja-aksjomatyczna}

Żadna z powyżej przedstawionych definicji prawdopodobieństwa nie może
być podstawą pozwalającą zbudować wolną od sprzeczności konstrukcję
naukową (Hellwig (\citeproc{ref-hellwig1998}{1998, p. 48})). O wadach
definicji klasycznej wspomniano powyżej. Pozostałe przedstawione
definicje także nie spełniają formalnych wymogów matematycznych.
Rozwiązaniem jest przedstawiona przez Andrieja Kołmogorowa w roku 1933
definicja aksjomatyczna.

Niech \(\Omega\) będzie przestrzenią zdarzeń elementarnych doświadczenia
losowego \(D\), a \(\mathcal{F}\) \(\sigma\)-ciałem określonym na
przestrzeni zdarzeń elementarnych \(\Omega\). Prawdopodobieństwem
nazwywamy funkcję \(P\) przyporzadkowującą każdemu zdarzeniu losowemu
\(A \in \mathcal{F}\) liczbę \(P(A)\) zgodnie z następującymi warunkami
(por. Kowgier (\citeproc{ref-kowgier2011}{2011, p. 25}), Wywiał
(\citeproc{ref-wywial2004}{2004, p. 17}), Kordecki
(\citeproc{ref-kordecki2003}{2003, p. 13})):

\(1. \  P(A) \ge 0 \text{, dla każdego zdarzenia } A \in \mathcal{F} \\\),

\(2. \  P(\Omega) = 1 \\\)

\(3. \ P(A_1 \cup A_2 \cup \ldots \cup A_n \ldots )=P(A_1)+P(A_2)+\ldots+P(A_n) + \ldots\)
dla dowolnych parami rozłącznych zdarzeń
\(A_1, A_2, \ldots, A_n, \ldots \text{ ze zbioru } \mathcal{F}\).

Trzy powyższe punkty, to tzw. aksjomaty w omawianej definicji
prawdopodobieństwa.

\section{Prawdopodobieństwo - wybrane
zagadnienia}\label{prawdopodobieux144stwo---wybrane-zagadnienia}

Teoria prawdopodobieństwa stanowi istotne zagadnienie w matematyce,
ułatwiające badanie i modelowanie zjawisk losowych. Dużą rolę odgrywają
takie pojęcia jak prawdopodobieństwo warunkowe, prawdopodobieństwo
bezwzględne, zdarzenia niezależne i twierdzenie Bayesa.
Prawdopodobieństwo warunkowe umożliwia ocenę prawdopodobieństwa
wystąpienia zdarzenia, przy założeniu, że wystąpiło inne zdarzenie.
Zdarzenia niezależne definiuje się jako te zdarzenia, których realizacja
nie wpływa na prawdopodobieństwo wystąpienia innych zdarzeń. Wzór Bayesa
natomiast stanowi potężne narzędzie, które umożliwia aktualizację
prawdopodobieństw w świetle nowych informacji. Opanowanie tych pojęć
jest niezbędne dla biegłego zastosowania teorii prawdopodobieństwa w
różnych dziedzinach, od statystyki i analizy danych po podejmowanie
decyzji w obliczu niepewności.

\subsection{Prawdopodobieństwo
warunkowe}\label{prawdopodobieux144stwo-warunkowe}

Niech \(A\) i \(B\) będą dowolnymi zdarzeniami losowymi.
Prawdopodobieństwo zdarzenia \(A\) obliczane przy założeniu, że zaszło
zdarzenie \(B\) nazywamy prawdopodobieństwem warunkowym zdarzenia \(A\)
pod warunkiem \(B\) i oznaczane jest symbolem \(P(A/B)\)

\begin{equation}\phantomsection\label{eq-pr_war}{ (A/B)= \frac{P(A \cap B)}{P(B)}}\end{equation}

dla \(A, B \in \ \mathcal{F}, \ P(B) > 0.\)

\subsection{Prawdopodobieństwo
całkowite}\label{prawdopodobieux144stwo-caux142kowite}

Prawdopodobieństwo całkowite pozwala na obliczenie prawdopodobieństwa
zdarzenia, które może zajść na kilka różnych sposobów. Jest to
szczególnie użyteczne w przypadkach, gdy zdarzenie może być wynikiem
kilku różnych, wzajemnie wykluczających się zdarzeń. Umożliwia ono
dekompozycję złożonych problemów probabilistycznych na prostsze części,
które można łatwiej analizować i sumować.

Uwzględniając dwa zbiory można to zapisać następująco: Jeżeli
\(B_1 \cup B_2 = \Omega\), to:

\begin{equation}\phantomsection\label{eq-pr_cal}{ P(A)= P(A/B_1)P(B_1)+P(A/B_2)P(B_2)}\end{equation}

Wzór \ref{eq-pr_cal} można uogólnić na \(n\) składników i przyjmuje on
wówczas postać:

Jeżeli \(B_1 \cup B_2 \cup \ldots \cup B_n =\Omega\), to

\begin{equation}\phantomsection\label{eq-pr_cal_n}{ P(A)= P(A/B_1)P(B_1)+P(A/B_2)P(B_2)+ \ldots + P(A/B_n)P(B_n).}\end{equation}

\subsection{Niezależność zdarzeń
losowych}\label{niezaleux17cnoux15bux107-zdarzeux144-losowych}

Niezależność zdarzeń oznacza, że wystąpienie jednego zdarzenia nie
wpływa na prawdopodobieństwo wystąpienia drugiego zdarzenia. Jest to
kluczowe założenie w wielu modelach probabilistycznych i statystycznych,
ułatwiające analizę i obliczenia. Zdarzenia \(A\) i \(B\) są niezależne,
jeśli

\begin{equation}\phantomsection\label{eq-niez}{P(A \cap B)= P(A)P(B)}\end{equation}

Łatwo zauważyć, że dla dowolnego zdarzenia \(A\) zdarzenia
\(A \text{ i } \Omega\) są niezależne:

\[P(\Omega \cap A) = P(A) = 1 \cdot P(A) = P(\Omega) P(A)\]

Jeżeli \(P(A) = 0\), to dla dowolnego zdarzenia \(B\), zdarzenia \(A\) i
\(B\) są niezależne. Wystarczy zauważyć, że
\(P(A \cap B) \le P(A) = 0\), to \(P(A \cap B)=0\) i wówczas
otrzymujemy:

\[P(A \cap B)=0 \cdot P(B) = P(A) P(B).\]

W bardziej złożonym przypadku, gdy rozpatrywanych jest \(n>2\) zdarzeń
\(A_1,A_2,\ldots,A_n\) warunek niezależności (dokładniej: wzajemnej
niezależności lub zespołowej niezależnosci) zadany wzorem \ref{eq-niez}
oznacza, że prawdopodobieństwołącznego zajścia \(m (m \le n)\) zdarzeń
spośród nich jest równe iloczynowi prawdopodobieństw tych zdarzeń, czyli
(\citeproc{ref-krysicki2003}{Krysicki, 2003, p. {[}23{]}}):

\begin{equation}\phantomsection\label{eq-niez_n}{ P(A_{i_1} \cap A_{i_2} \cap \ldots \cap A_{i_m} ) = P(A_{i_1}) P(A_{i_2}) \ldots P(A_{i_m}) }\end{equation}

dla każdego \(m \le n\) i każdego m-wyrazowego rosnącego ciągu
\(i_1, i_2, \ldots, i_m\) liczba naturalnych
\(1 \le i_1, i_2, \ldots, i_m \le n\).

Spełnienie warunku
\(P(A_1 \cap A_2 \cap \ldots \cap A_n) = P(A_1) P(A_2) \ldots P(A_n)\)
nie oznacza, że wszystkie zdarzenia \(A_1, A_2, \ldots, A_n\) są parami
niezależne (por. np. Krzyśko (\citeproc{ref-krzysko2000}{2000, p. 87}))

\subsection{Wzór Bayesa}\label{wzuxf3r-bayesa}

Jeżeli zdarzenia \(B_1, B_2, \ldots, B_n\) są zdarzeniami parami
rozłącznymi, czyli \(B_i \cap B_j = \emptyset \text{ dla } i \neq j\) o
dodatnich prawdopodobieństwach, czyli
\(P(B_i) > 0 \text{ dla } i =1, 2, \ldots, n\) oraz
\(B_1 \cup B_2 \cup \ldots \cup B_n=\Omega\), to

\begin{equation}\phantomsection\label{eq-pr_bayes}{ P(B_i/A)= \frac{P(B_i)P(A / B_i)}{P(A)}}\end{equation}

Wzór Bayes'a (\ref{eq-pr_bayes}) informuje w jai sposób zaktualizować
przekonania o prawdopodobieństwie zdarzenia na podstawie dodatkowych
informacji. Wzór wyraża relację między prawdopodobieństwem warunkowym a
prawdopodobieństwem brzegowym i prawdopodobieństwem a priori.

\subsection{Podstawowe własności
prawdopodobieństwa}\label{podstawowe-wux142asnoux15bci-prawdopodobieux144stwa}

Poniżej przedstawiono wybrane najważniejsze własności prawdopodobieństwa
(\citeproc{ref-krysicki2003}{Krysicki, 2003}).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Prawdopodobieństwo zdarzenia niemożliwego (oznaczenie \(\emptyset\))
\end{enumerate}

\[ P(\emptyset) = 0 \text{,}\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Jeżeli zdarzenie \(A\) pociąga zdarzenie \(B\) (\(A \Rightarrow B\)),
  to
\end{enumerate}

\[ P(A) \le P(B) \]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Prawdopodobieństwo dowolnego zdarzenia \(A\) jest nie większe od 1.
\end{enumerate}

\[ P(A) \le 1 \text{, dla dowolnego zdarzenia} A.\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Jeżeli zdarzenie \(A\) pociąga zdarzenie
  \(B, \text{ (co zapisujemy} \  A \Rightarrow B)\), to
\end{enumerate}

\[ P(B \setminus A) = P(B) - P(A) \]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Jeżeli zdarzenia \(A_1, A_2, \ldots A_n\) są parami rozłączne, to
\end{enumerate}

\[P(A_1 \cup A_2 \cup \ldots \cup A_n)=P(A_1)+P(A_2)+\ldots+P(A_n)\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Prawdopodobieństwo zdarzenia przeciwnego \(A'\) do zdarzenia \(A\)
  wynosi:
\end{enumerate}

\[ P(A') = 1 - P(A) \]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  Prawdopodobieństwo sumy dowolnych zdarzeń \(A\) i \(B\) wynosi:
\end{enumerate}

\[ P(A \cup B) = P(A) + P(B) - P(a \cap B)\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{7}
\tightlist
\item
  Prawdopodobieństwo iloczynu dowolnych zdarzeń \(A\) i \(B\) wynosi:
\end{enumerate}

\[ P(A \cap B) = P(A) + P(B) - P(a \cup B)\]

\section{Przykłady -
prawdopodobieństwo}\label{przykux142ady---prawdopodobieux144stwo}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 3.7}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 3.8}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 3.9}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 3.10}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 3.11}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 3.12}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\section{Zadania i pytania}\label{zadania-i-pytania-1}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={Zadania}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-warning-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-warning-color-frame, colback=white]

\end{tcolorbox}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
\item
\item
\item
\item
\end{enumerate}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={Pytania problemowe}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
\item
\item
\item
\item
\end{enumerate}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={Prawda czy fałsz?}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-caution-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-caution-color-frame, colback=white]

\end{tcolorbox}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
\item
\item
\item
\item
\end{enumerate}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={Pytania testowe}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-important-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-important-color-frame, colback=white]

\end{tcolorbox}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
\item
\item
\item
\item
\end{enumerate}

\bookmarksetup{startatroot}

\chapter{Zmienna losowa - podstawowe
określenia}\label{zmienna-losowa---podstawowe-okreux15blenia}

\href{https://www.edukator.pl/resources/page/zmienna-losowa/790}{Zmienna
losowa}

\href{https://theta.edu.pl/wp-content/uploads/2014/02/W2EP-1.pdf}{Zmienna
losowa}

\href{https://home.agh.edu.pl/~zak/downloads/Stat-3.pdf}{Zmienna losowa}

\href{https://www.math.uni.wroc.pl/~mbogdan/Podstawy/Wyklady/wyklad_3.pdf}{Zmienna
losowa}

Niech \(\mathcal{F}\) będzie \(\sigma\)-ciałem przestrzeni \(\Omega\) i
niech \(X\) będzie funkcją określoną na \(\Omega\) o wartościach w
zbiorze liczb rzeczywistych.

\[ X: \Omega \to \mathbb{R}\]

Definicja (\citeproc{ref-krzysko2000}{Krzyśko, 2000}):

Funkcja \(X\) jest zmienną losową, jeżeli dla każdej liczby
\(c \in \mathbb{R}\)

\[ \{{ \omega: X(\omega)<c \}} =X^{-1}(-\infty; \ c)  \in \mathcal{F} \]
gdzie \(X^{-1}\) jest operacją przeciwobrazu zbioru poprzez funkcję
\(X\).

Często w literaturze podawane jest opisowe określenie pojęcia zmiennej
losowej. Aczel (\citeproc{ref-aczel2000}{2000, p. 111}) podaje, że
``\emph{zmienną losową jest zmienna, która przyjmuje różne wartości
liczbowe, wyznaczone przez los}'', a Dobiesław Bobrowski (1980):
``\emph{zmienną losową jest zmienna, która w wyniku doświadczenia
przyjąć może jedną z wartości z pewnego zbioru liczb rzeczywistych i to
z określonym prawdopodobieństwem}'' (za Snopkowski
(\citeproc{ref-snopkowski2007}{2007, p. 13})) .

Zmienne losowe oznaczane są dużymi literami \(X, Y, Z, ...\), poza
nielicznymi wyjątkami gdzie zwyczajowo stosuje się specyficzne
oznaczenia np. \(t\), \(\chi^2\) lub \(\xi\).

W badaniach naukowych zmienne losowe są wykorzystywane do modelowania i
analizy zjawisk, które mają element niepewności. Rozkłady zmiennych
losowych znajdują szerokie zastosowania w różnych zagadnieniach w
ekonomii i finansach jak np.:

\begin{itemize}
\item
  w ocenie ryzyka rynkowego i zarzadzaniu ryzykiem
  (\citeproc{ref-bernstein1997}{Bernstein et al., 1997};
  \citeproc{ref-malecka2016}{Małecka, 2016};
  \citeproc{ref-trzpiot2011}{Trzpiot, 2008},
  \citeproc{ref-trzpiot2008b}{2011});
\item
  w analizach rynku ubezpieczeń (\citeproc{ref-szymanska2017}{Szymańska,
  2017});
\item
  w analizach rozkładów wynagrodzeń (\citeproc{ref-cwiek2018}{Ćwiek et
  al., 2018}; \citeproc{ref-jedrzejczak2020}{Jędrzejczak \& Pekasiewicz,
  2020});
\item
  w analizach szeregów czasowych i prognozowaniu
  (\citeproc{ref-kucharski2013}{Kucharski, 2013});
\item
  w analizach giełdowych (\citeproc{ref-piasecki2013}{Piasecki \&
  Tomasik, 2013});
\item
  w analizach symulacyjnych (\citeproc{ref-konczak2012}{Kończak, 2012},
  \citeproc{ref-konczak2020}{2020};
  \citeproc{ref-snopkowski2007}{Snopkowski, 2007});
\item
  w ekonomicznych badaniach porównawczych
  (\citeproc{ref-ganczarek-gamrot2013}{Ganczarek-Gamrot, 2013};
  \citeproc{ref-polko-zajac2021}{Polko-Zając, 2021}).
\end{itemize}

Wyróżnia się dwa rodzaje zmiennych losowych:

\begin{itemize}
\item
  zmienna losowa skokowa,
\item
  zmienna losowa ciągła.
\end{itemize}

\section{Zmienna losowa skokowa}\label{zmienna-losowa-skokowa}

Zmienna losowa skokowa (dyskretna), to taka zmienna losowa, która może
przyjmować skończenie lub przeliczalnie wiele wartości
(\citeproc{ref-aczel2000}{Aczel, 2000, p. {[}111{]}}). Regułę, według
której jednostkowa masa prawdopodobieństwa rozkłada się na poszczególne
wartości zmiennej losowej nazywa się funkcją rozkładu
prawdopodobieństwa.

Rozkład prawdopodobieństwa zmiennej losowej dyskretnej \(X\) może być
dany w następującej postaci:

\begin{equation}\phantomsection\label{eq-rp_sk}{ P(X=x_i)= p_i \  \text{dla} \  i = 1, 2, \ldots, k}\end{equation}

gdzie \(p_i > 0\)

\(\sum_{i=1}^n p_i = 1 \ lub \  \sum_{i=1}^{\infty} p_i = 1\).

Jest to funkcja przyporządkowująca wartości prawdopodobieństwa
poszczególnym wartościom \(x_i\) zmiennej losowej \(X\). Funkcja ta może
być podana w postaci wzoru analitycznego, poprzez wymienienie wszystkich
par \((x_i, p_i)\) a także w formie graficznej.

Kolejną ważną charakterystyką zmiennej losowej jest dystrybuanta. Jest
to funkcja \(F(x): \mathbb{R} \to [0, 1]\) zadana następującym wzorem:

\begin{equation}\phantomsection\label{eq-dys_sk}{ F(x) = P(X <x) \text{ dla } x \in \mathbb{R}.}\end{equation}

Dla zmiennej losowej skokowej wzór \ref{eq-dys_sk} może być równoważnie
zapisany w postaci:

\[F(x) = \sum_{i: \ x_i<x}p_i\]

Dystrybuanta \(F(x)\) zawsze spełnia następujące warunki:

\[0 \le F(x) \le 1\] \[F(x) \ \text{jest funkcją niemalejącą}\]
\[F(x) \ \text{jest funkcją lewostronnie ciągłą}\]
\[\lim_{x \to -\infty} F(x) = 0 \text{ oraz } \lim_{x \to \infty}F(x) = 1\]
\[\lim_{x \to -\infty} F(x) = 0\]

W charakterystyce zmiennych losowych wykorzystywane są parametry jak
wartość oczekiwana oraz wariancja. Wartość oczekiwana zmiennej losowej
\(EX\) obliczana jest następująco:

\begin{equation}\phantomsection\label{eq-wo_sk}{EX = \sum_{i}{x_ip_i}}\end{equation}
Wariancja zmiennej losowej \(D^2X\) zadana jest wzorem:

\begin{equation}\phantomsection\label{eq-war_sk}{D^2X = E(X-EX)^2 = EX^2-(EX)^2}\end{equation}

gdzie:

\[ EX^2 = \sum_{i}{x_i^2p_i}\]

Po obliczeniu \(D^2X\) wyznacza się odchylenie standardowe tej zmiennej
losowej. Odchylenie standardowe zmiennej losowej \(X\), to pierwiastek
kwadratowy z wariancji zmiennej losowej, czyli:

\begin{equation}\phantomsection\label{eq-sd_sk}{ DX=\sqrt{D^2X}}\end{equation}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 4.1. Jednokrotny rzut sześcienną kostką do gry}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

Rozważmy jednokrotny rzut sześcienną kostką do gry. Niech \(X\) oznacza
liczbę wyrzuconych oczek. Wyznaczyć rozkład prawdopodobieństwa i
dystrybuantę zmiennej losowej \(X\). Obliczyć wartość oczekiwaną i
wariancję tej zmiennej losowej.

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={Rozwiązanie}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

Zmienna losowa \(X\) może przyjmować następujące wartości:
\(1, 2, 3, 4, 5 \text{ oraz } 6\). Wszystkie te wartości są przyjmowane
z jednakowymi prawdopodobieństwami \(p=\frac{1}{6}\).

Dla tak określej zmiennej funkcja rozkładu prawdopodobieństwa ma
następującą postać:

\[P(X=x) = \begin{cases} 
\frac{1}{6} & \text{dla } x = 1 \\
\frac{1}{6} & \text{dla } x = 2 \\
\frac{1}{6} & \text{dla } x = 3 \\
\frac{1}{6} & \text{dla } x = 4 \\
\frac{1}{6} & \text{dla } x = 5 \\
\frac{1}{6} & \text{dla } x = 6
\end{cases}
\]

Zwykle rozkład zmiennej losowej skokowej wygodnie jest przedstawiać w
formie tabeli (por. tabela~\ref{tbl-kostka})

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1429}}
  >{\centering\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1429}}
  >{\centering\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1429}}
  >{\centering\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1429}}
  >{\centering\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1429}}
  >{\centering\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1429}}
  >{\centering\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1429}}@{}}
\caption{Rozkład prawdopodobieństwa liczby oczek w jednokrotnym rzucie
sześcienną kostką do gry}\label{tbl-kostka}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
\(x_i\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
1
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
2
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
3
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
4
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
5
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
6
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
\(x_i\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
1
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
2
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
3
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
4
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
5
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
6
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(p_i\) & \(\frac{1}{6}\) & \(\frac{1}{6}\) & \(\frac{1}{6}\) &
\(\frac{1}{6}\) & \(\frac{1}{6}\) & \(\frac{1}{6}\) \\
\end{longtable}

Na rys.~\ref{fig-kostka_rp} przedstawiono funkcję rozkładu
prawdopodobieństwa liczby wyrzuconych oczek w jednokrotnym rzucie
sześcienną kostką do gry.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{r04_files/figure-pdf/fig-kostka_rp-1.pdf}}

}

\caption{\label{fig-kostka_rp}Rozkład prawdopodobieństwa liczby
otrzymanych oczek w jednokrotnym rzucie sześcienną kostką do gry}

\end{figure}%

Dla tak określej zmiennej dystrybuanta \(F(x)\) (por. \ref{eq-dys_sk})
ma następującą postać:

\[F(x) = \begin{cases} 
0 & \text{dla } x \le 1 \\
\frac{1}{6} & \text{dla } 1< x  \le2 \\
\frac{2}{6} & \text{dla } 2< x  \le3 \\
\frac{3}{6} & \text{dla } 3< x  \le4 \\
\frac{4}{6} & \text{dla } 4< x  \le5 \\
\frac{5}{6} & \text{dla } 5< x  \le6 \\
1 & \text{dla } x >6 \\
\end{cases}
\]

Na rys.~\ref{fig-kostka_dys} pokazano dystrybuantę \(F(x)\) zmiennej
losowej \(X\).

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{r04_files/figure-pdf/fig-kostka_dys-1.pdf}}

}

\caption{\label{fig-kostka_dys}Dystrybuanta zmiennej losowej}

\end{figure}%

Zgodnie ze wzorem \ref{eq-wo_sk} wartość oczekiwana w jednokrotnym
rzucie kostką wynosi:

\[EX=1 \cdot \frac{1}{6}+1 \cdot \frac{2}{6}+ \ldots +6 \cdot \frac{1}{6} = 3,5\]

Rezultat ten należy tak rozumieć, że gdyby wielokrotnie (setki, tysiace
razy) rzucać sześcienną kostką do gry, to przeciętna wartość wyrzuconej
liczby oczek będzie bliska 3,5.

Do wyznaczenia wariancji na podstawie wzoru \ref{eq-war_sk} niezbędne
jest obliczenie \(EX^2\)

\[EX^2=1 \cdot \frac{1}{6}+1 \cdot \frac{4}{6}+ \ldots +6 \cdot \frac{36}{6} = \frac{91}{6}\]
Wobec tego wariancja zmiennej losowej \(X\) wynosi:

\[ D^2X=\frac{91}{6}-(3,5)^2 \approx 2,92\]

Odchylenie standardowe \(DX\) wynosi:

\[DX=\sqrt{2,92}=1,71\]

Przy wielokrotnym rzucaniu sześcienną kostką do gry liczba wyrzuconych
oczek odchyla się przeciętnie od wartości oczekiwanej o około 1,71.

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={Stop}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\section{Zmienna losowa ciągła}\label{zmienna-losowa-ciux105gux142a}

Zmienna losowa ciągła, to taka zmienna losowa, która może przyjmować
dowolne wartości z pewnego przedziału. Możliwe wartości takiej zmiennej
tworzą zbiór nieprzeliczalny (\citeproc{ref-aczel2000}{Aczel, 2000, p.
{[}111{]}}). O ile dla zmiennej losowej skokowej podawana była funkcja
rozkładu prawdopodobieństwa, to dla zmiennej losowej ciagłej jej
odpowiednikiem jest funkcja gęstości.

Funkcja gęstości \(f(x)\) spełnia następujące warunki:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(f(x) \ge 0 \text{, dla } x \in \mathbb{R}\)
\item
  \(\int_{-\infty}^{\infty}f(x)dx= 1\)
\end{enumerate}

Dystrybuanta zmiennej losowej to funkcja:

\begin{equation}\phantomsection\label{eq-dys_og}{ F(x) = P(X <x) \text{ dla } x \in \mathbb{R}.}\end{equation}

Dla zmiennej losowej ciągłej dystrybuanta zadana \ref{eq-dys_og} może
być zapisana w postaci:

\begin{equation}\phantomsection\label{eq-dys_cg}{F(x) = P(X <x) = \int_{-\infty}^x f(t)dt}\end{equation}

Prawdopodobieństwo, że zmienna losowa ciągła przyjmie wartość z
przedziału {[}a, b{]} można obliczyć w oparciu o funkcję gęstości
następująco:

\begin{equation}\phantomsection\label{eq-pr_gest}{ P(a<X<b)= \int_a^b f(x)dx}\end{equation}

To samo prawdopodobieństwo można obliczyć wykorzystując wartosci
dystrybuanty zmiennej losowej \(X\):

\begin{equation}\phantomsection\label{eq-pr_dys}{ P(a<X<b)= F(b) - F(a)}\end{equation}

Podobnie jak dla zmiennej losowej skokowej, tak również w
charakterystyce zmiennych losowych ciągłych wykorzystywane są parametry
jak wartość oczekiwana oraz wariancja. Wartość oczekiwana zmiennej
losowej \(EX\) obliczana jest następująco:

\begin{equation}\phantomsection\label{eq-wo_cg}{ EX = \int_{-\infty}^{\infty} x f(x)dx}\end{equation}

Wariancja zmiennej losowej \(D^2X\) zadana jest wzorem:

\begin{equation}\phantomsection\label{eq-war_cg}{ D^2X = E(X-EX)^2 = EX^2-(EX)^2 }\end{equation}

gdzie:

\[ EX^2 = \int_{-\infty}^{\infty} x^2 f(x)dx\]

Po obliczeniu \(D^2X\) wyznacza się odvhylenie standardowe tej zmiennej
losowej. Odchylenie standardowe zmiennej losowej X, to pierwiastek
kwadratowy z wariancji zmiennej losowej, czyli:

\begin{equation}\phantomsection\label{eq-sd_cg}{ DX=\sqrt{D^2X}}\end{equation}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 4.2. Czas oczekiwania na autobus}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

Na pewnym przystanku autobus odjeżdża dokładnie co 10 minut. Niech \(X\)
oznacza czas oczekiwania na odjazd autobusu losowego podróżnego. Podać
gęstość zmiennej losowej \(X\), jej dystrybuantę oraz wyznaczyć wartość
oczekiwaną i wariancję tej zmiennej losowej.

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={Rozwiązanie}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

Zmienna losowa \(X\) może przyjmować wartości od 0 do 10.

Gęstość zmiennej losowej \(X\) ma następującą postać:

\begin{equation}\phantomsection\label{eq-gest_aut}{
f(x) = \begin{cases} 
0 & \text{dla } x < 0 \\
\frac{1}{10} & \text{dla } 0 \le x \le 10 \\
0 & \text{dla } x > 10
\end{cases}
}\end{equation}

Wykres funkcji gęstości zmiennej losowej \(X\) przedstawia
rys.~\ref{fig-autobus}

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{r04_files/figure-pdf/fig-autobus-1.pdf}}

}

\caption{\label{fig-autobus}Gęstość rozkładu normalnego standardowego}

\end{figure}%

Na rys.~\ref{fig-aut_prob} przedstawiono funkcję gęstości jak na
rys.~\ref{fig-autobus}, ale dodatkowo zaznaczono obszar pod funkcją
gęstości w zakresie \(x \in (2, 6)\). Pole to odpowiada
prawdopodobieństwu realizacji zdarzenia polegającego na tym, że losowo
wybrany pasażer będzie oczekiwał na autobus od 2 do 6 minut. W omawianym
przypadku prawdopodobieństwo to wynosi 0,4.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{r04_files/figure-pdf/fig-aut_prob-1.pdf}}

}

\caption{\label{fig-aut_prob}Gęstość rozkładu normalnego standardowego z
zaznaczeniem prawdopodobieństwa realizacji w zakresie 2 do 6}

\end{figure}%

Dystrybuanta zmiennej losowej \(X\) jest zadana wzorem:

\[F(x) = P(X < x),\] a wyznaczenie tej funkcji zostanie zrealizowane w
trzech etapach:

\(\text{a) }  x \in (-\infty, 0)\)

\[ F(x) = P(X<x) = \int_{-\infty}^{x} f(t) \, dt = \int_{-\infty}^{x} 0 \, dt = 0\]

\(\text{b) } x \in [ 0, 10]\)

\[ F(x) = P(X<x) = \int_{-\infty}^{0} f(t) \, dt +\int_{0}^{x} f(t) \, dt=\]

\[= \int_{-\infty}^{0} 0 \, dt +\int_{0}^{x} \frac{1}{10} \, dt  = 0 + \left[ \frac{1}{10}t \right]_0^{x}  = 0+ \frac{1}{10}x=  \frac{1}{10}x\]

\(\text{c) } x \in ( 10, \infty)\)

\[ F(x) = P(X<x) = \int_{-\infty}^{0} f(t) \, dt +\int_{0}^{10} f(t) \, dt +\int_{10}^{x} f(t) \, dt=\]

\[= \int_{-\infty}^{0} 0 \, dt +\int_{0}^{10} \frac{1}{10} \, dt +\int_{10}^{x} 0 \, dt = 0 + \left[ \frac{1}{10}t \right]_0^{10}  + 0 = 0+1+0=1 \]

Wobec powyższych wyników dystrybuantę można zapisać następująco:

\[
F(x) = \begin{cases} 
0 & \text{dla } x < 0 \\
\frac{1}{10}x & \text{dla } 0 \le x \le 10 \\
1 & \text{dla } x > 10
\end{cases}
\]

Na rys.~\ref{fig-aut_dys} przedstawiono dystrybuantę zmiennej losowej
\(X\). Jest to funkcja niemalejąca, a granice w \(-\infty\) i \(\infty\)
wynoszą odpiednio 0 i 1.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{r04_files/figure-pdf/fig-aut_dys-1.pdf}}

}

\caption{\label{fig-aut_dys}Dystrybuanta zmiennej losowej X}

\end{figure}%

Korzystając ze wzoru \ref{eq-pr_dys} można wyznaczyć prawdopodobieństwo
oczekiwania na autobus pomiędzy 2 min. oraz 6 min (por.
rys.~\ref{fig-aut_prob}). Wartości dystrybuanty w tych punktach są
następujące:

\[F(2)=\frac{2}{10} \]

\[F(2)=\frac{6}{10} \]

Wobec tego na podstawie (\ref{eq-pr_dys}) otrzymujemy:

\[ P(2<X<6) = F(6) - F(2) = \frac{6}{10}-\frac{2}{10}=\frac{4}{10}\]

Odpowiednie wartości dystrybuanty przedstawiono na
rys.~\ref{fig-aut_dys2}

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{r04_files/figure-pdf/fig-aut_dys2-1.pdf}}

}

\caption{\label{fig-aut_dys2}Dystrybuanta zmiennej losowej X}

\end{figure}%

Do obliczenia wartości oczekiwanej zmiennej losowej X wykorzystanie wzór
\ref{eq-wo_cg}

\[ EX = \int_{-\infty}^{\infty} xf(x)dx = \int_{-\infty}^{0} xf(x)dx+ \int_{0}^{10} xf(x)dx+ \int_{10}^{\infty} xf(x)dx= \]
\[ = \int_{-\infty}^{0} x0dx+ \int_{0}^{10} x\frac{1}{10}dx+ \int_{10}^{\infty} x0dx= 0 + \frac{1}{10}\int_{0}^{10} xdx + 0 = \]

\[ =  \frac{1}{10} \left[ \frac{x^2}{2} \right]_0^{10}= \frac{1}{10}\left( \frac{10^2}{2}-0^2 \right)=5 \]

Otrzymany wynik informuje nas, że gdyby na przystanek przychodziło
bardzo wielu pasażerów, to ich przeciętny czas oczekiwania na autobus
wynosiłby około 5 minut.

Do obliczenia wariancji niezbędne jest wyznaczenie wartości \(EX^2\):

\[ EX^2 = \int_{-\infty}^{\infty} x^2f(x)dx = \int_{-\infty}^{0} x^2f(x)dx+ \int_{0}^{10} x^2f(x)dx+ \int_{10}^{\infty} x^2f(x)dx= \]
\[ = \int_{-\infty}^{0} x^20dx+ \int_{0}^{10} x^2\frac{1}{10}dx+ \int_{10}^{\infty} x^20dx= 0 + \frac{1}{10}\int_{0}^{10} x^2dx + 0 = \]

\[\frac{1}{10} \left[ \frac{x^3}{3} \right]_0^{10} = \frac{1}{10} \left( \frac{10^3}{3} - \frac{0^3}{3} \right) = \frac{1}{10} \cdot \frac{1000}{3} = \frac{1000}{30} = \frac{100}{3}
\]

Wobec tego wariancja zmiennej losowej \(X\) wynosi

\[D^2X=\frac{1000}{3}-5^2\approx{8,33}\]

Odchylenie standardowe zmiennej losowej \(X\) wynosi

\[DX = \sqrt{8,33} = 2,9\]

Otrzymana wielkość informuje nas, że gdyby wielu pasażerów przychodziło
na przystanek autobusowy, to ich czas oczekiwania na odjazd autobusu
odchylałby się przecietnie od wartości opczekiwanej o około 2,9 minuty.

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={***}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\section{Własności wartości oczekiwanej i
wariancji}\label{wux142asnoux15bci-wartoux15bci-oczekiwanej-i-wariancji}

Wprowadzone parametry wartość oczekiwana i wariancja zmiennej losowej
charalkteryzują się pewnymi własnościami. Poniżej wskazano najważniejsze
własności tych parametrów.

\begin{itemize}
\tightlist
\item
  Wartość oczekiwana - najważniejsze własności
\end{itemize}

Wartość oczekiwana stałej, jest równa tej stałej wartości.

\(Ec = c\)

Gdyby na każdej ściance sześciennej kostki do gry były np. dwa oczka, a
zmienna losowa \(X\) przyjmowała wartość równą liczbie wyrzuconych
oczek, to wartość oczekiwana takiej zmiennej losowej (stałej) wynosiłaby
2.

\(E(cX) = cEX\)

\(E(X+c) = EX +c\)

\(E(X+Y) = EX + EY\)

\(N \le EX \le M\), jeśli \(N \le X \le M\)

\(E(X\cdot Y)=EX \cdot EY\), dla X, Y niezależnych.

\begin{itemize}
\tightlist
\item
  Wariancja - najważniejsze własności
\end{itemize}

\(D^2c = 0\)

\(D^2(cX) = c^2 D^2X\)

\(D^2(X+c) = D^2X\)

\(D^2(X+Y) = D^2X + D^Y\), dla \(X, Y\) niezależnych.

\section{Przykłady - zmienna
losowa}\label{przykux142ady---zmienna-losowa}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 4.3.}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 4.4.}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 4.5.}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 4.6.}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\section{Zadania i pytania}\label{zadania-i-pytania-2}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={Zadania}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-warning-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-warning-color-frame, colback=white]

\end{tcolorbox}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
\item
\item
\item
\item
\end{enumerate}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={Pytania problemowe}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
\item
\item
\item
\item
\end{enumerate}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={Prawda czy fałsz?}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-caution-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-caution-color-frame, colback=white]

\end{tcolorbox}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
\item
\item
\item
\item
\end{enumerate}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={Pytania testowe}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-important-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-important-color-frame, colback=white]

\end{tcolorbox}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
\item
\item
\item
\item
\end{enumerate}

\bookmarksetup{startatroot}

\chapter{Wybrane rozkłady zmiennych losowych
skokowych}\label{wybrane-rozkux142ady-zmiennych-losowych-skokowych}

\href{https://home.agh.edu.pl/~zak/downloads/4-Elektronika-2015.pdf}{Zmienne
skokowe}

\href{https://e.kul.pl/files/12167/public/statystyka/wyklad23.pdf}{Zmienne
skokowe}

\href{http://statystyka.rezolwenta.eu.org/Materialy/PRS.pdf}{Zmienne
skokowe}

\href{http://www.statystyka.org/statys/rzs/rt/rtt.htm}{Zmienne skokowe}

\href{https://wyznacznik.pl/zmienne-losowe-skokowe-zadania}{Zadania}

W tym rozdziale przedstawiono najczęściej spotykane w praktyce rozkłady
zmiennych losowych skokowych. We wszystkich przypadkach podano funkcję
rozkładu prawdopodobieństwa, przedstawiono wzory na obliczanie wartości
oczekiwanej i wariancji. Na zakończenie rozdziału przedstawiono
przykłady związane z wykorzystaniem tych rozkładów.

\section{Rozkład dwupunktowy}\label{rozkux142ad-dwupunktowy}

Zmienna losowa \(X\) ma rozkład dwupunktowy, jeżeli jej funkcja rozkładu
prawdopodobieństwa ma następującą postać:

\begin{equation}\phantomsection\label{eq-dwup}{ 
P(X=k)= 
\begin{cases} 
1-p & \text{dla } k=x_1 \\
p & \text{dla } k=x_2
\end{cases}
}\end{equation}

Zmienna losowa o rozkładzie dwupunktowym może przyjmować dwie wartości
\(x_1\) lub \(x_2\) odpowiednio z prawdopodobieństwami \(1-p\) oraz
\(p\) (por. \ref{eq-dwup}). Jest to najprostszy rozkład zmiennej
losowej. Z rozkładem dwupunktowym mamy często do czynienia w
doświadczeniach, gdzie możliwe są dwa wyniki. Przyjmując np., że w
strzelec strzela do tarczy mając dwa możliwe rezultaty - ``trafił'',
``nie trafił'' - trafiając z prawdopodobieństwem 0,8, (trafienie to
wartość zmiennej losowej ``1'', a brak trafienia celu, to ``0'') można
powiedzieć, że została określona zmienna losowa.

Szczególnym przypadkiem zmiennej losowej o rozkładzie dwupunktowym jest
zmienna losowa o rozkładzie zero-jedynkowym. Zmienna losowa ma rozkład
zero-jedynkowy z parametrem \(p\), jeśli jej funkcja rozkładu
prawdopodobieństwa jest zadana wzorem:

\begin{equation}\phantomsection\label{eq-zero}{
P(X=k)= 
\begin{cases} 
1-p & \text{dla } k=0 \\
p & \text{dla } k=1
\end{cases} \label
}\end{equation}

Zgodnie ze wzorem \ref{eq-zero}, zmienna losowa o rozkładzie
zero-jedynkowym może przyjmować wyłącznie wartosci 1 i 0, odpowiednio z
prawdopodobieństwami \(p\) i \(1-p\).

Wartość oczekiwana i wariancja zmiennej losowej \(X\) o rozkładzie
zero-jedynkowym z parametrem \(p\) są następujące:

\[ EX=p, \ D^2X = p(1-p) \]

Rozkład prawdopodobieństwa zmiennej losowej \(X\) o rozkładzie
zero-jedynkowym z parametrem \(p=0,25\) został przedstawiony na
rys.~\ref{fig-zero}.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{r05_files/figure-pdf/fig-zero-1.pdf}}

}

\caption{\label{fig-zero}Rozkład prawdopodobieństwa zmiennej losowej o
rozkładzie zero-jedynkowym (\(p=0,25\))}

\end{figure}%

\section{Rozkład dwumianowy}\label{rozkux142ad-dwumianowy}

Zmienna losowa \(X\) ma rozkład dwumianowy (rozkład Bernoulliego), jeśli
jej funkcja rozkładu prawdopodobieństwa ma postać:

\begin{equation}\phantomsection\label{eq-dwum}{P(X=k) = \binom{n}{k} p^k (1-p)^{n-k} }\end{equation}

gdzie:

\(n\) - liczba identycznych niezależnych doświadczeń, z których każde
kończy się sukcesem (1) albo porażką (0),

\(p\) - prawdopodobieństwo sukcesu w pojedynczej próbie,

\(k\) - liczba sukcesów, dla \(k = 0, 1, \ldots , n\).

Zmienna losowa o rozkładzie dwumianowym określa prawdopodobieństwo
wystapienia \(k\) sukcesów w serii \(n\) niezaleznych doswiadczeń, z
których każde kończy się sukcesem z prawdopodobieństwem \(p\) lub
porażką z prawdopodobieństwem \(1-p\).

Wartość oczekiwana i wariancja zmiennej losowej \(X\) o rozkładzie
dwumianowym z parametrem \(p\) dla \(n\) doświadczeń są następujące:

\[ EX=np , \ D^2X = np(1-p)\]

Rozkład prawdopodobieństwa trzech zmiennych losowych o rozkładzie
dwumianowym dla \(n=10\) z parametrami \(p = 0,2; p=0,5; p=0,8\) został
przedstawiony na rys.~\ref{fig-dwum}.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{r05_files/figure-pdf/fig-dwum-1.pdf}}

}

\caption{\label{fig-dwum}Rozkład prawdopodobieństwa zmiennej losowej o
rozkładzie dwumianowym \(B(n, p)\) dla \(n = 10\) oraz
\(p = 0,2; 0,5 \ i \ 0,8\)}

\end{figure}%

\section{Rozkład Poissona}\label{rozkux142ad-poissona}

Zmienna losowa \(X\) ma rozkład Poissona z parametrem \(\lambda\), jeśli
jej funkcja rozkładu prawdopodobieństwa jest zadana następującym wzorem:

\begin{equation}\phantomsection\label{eq-pois}{P(X=k) = \frac{e^{-\lambda}\lambda^k}{k!} }\end{equation}

gdzie \(k = 0, 1, ....\)

Wartość oczekiwana i wariancja zmiennej losowej \(X\) o rozkładzie
Poissona z parametrem \(\lambda\) są następujące:

\[ EX=\lambda, \ D^2X = \lambda \]

Rozkład prawdopodobieństwa zmiennej losowej \(X\) o rozkładzie
dwumianowym z parametrem \(\lambda = 2\) został przedstawiony na
rys.~\ref{fig-pois}.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{r05_files/figure-pdf/fig-pois-1.pdf}}

}

\caption{\label{fig-pois}Rozkład prawdopoodobieństwa zmiennej losowej o
rozkładzie Poissona (\(\lambda=2\))}

\end{figure}%

\section{Rozkład hipergeometryczny}\label{rozkux142ad-hipergeometryczny}

Zmienna losowa \(X\) ma rozkład hipergeometryczny, jeżeli jej rozkład
prawdopodobieństwa ma postać:

\begin{equation}\phantomsection\label{eq-hip}{P(X=k)=\frac{\binom{K}{k}\binom{N-K}{n-k}}{\binom{N}{n}}}\end{equation}

gdzie \(max(0,n-(N-K)) \le k \le min(n, K).\)

Wartość oczekiwana i wariancja tej zmiennej losowej zadane są
następująco:

\[EX=n\frac{K}{N}, \  D^2X= n\frac{K(N-K)(N-n)}{N^2(N-1)}\]

Rozkład prawdopodobieństwa zmiennej losowej \(X\) o rozkładzie
hipergeometrycznym dla \(N=20, K=8, n=5\) został przedstawiony na
rys.~\ref{fig-hiper}.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{r05_files/figure-pdf/fig-hiper-1.pdf}}

}

\caption{\label{fig-hiper}Rozkład prawdopodobieństwa zmiennej losowej o
rozkładzie hipergeometrycznym}

\end{figure}%

Zmienna losowa o rozkładzie hipergeometrycznym podaje prawdopodobieństwa
liczby \(k\) wylosowanych wyróżnionych elementów w próbie o liczebnosci
\(n\) elementów pobranej bezzwrotnie z populacji liczacej \(N\)
elementów, wśród których znajduje się \(K\) wyróżnionych elementów.

Rozwąmy sytuację, gdy do kontroli dostarczono partię o liczebności \(N\)
elementów. Niech w tej partii znajduje się \(K (K < N)\) elementów
wadliwych. Z partii losowo pobierana jest próba o liczebności \(n\).
Prwdopodobieństwo, że w wylosowanej próbie znajduje się \(k\) elementów
wadliwych opisywane jest poprzez rozkład hipergeometryczny.

\section{Rozkład geometryczny}\label{rozkux142ad-geometryczny}

Zmienna losowa \(X\) ma rozkład geometryczny jeśli jej funkcja rozkładu
prawdopodobieństwa ma postać (\citeproc{ref-wawrzynek2007}{Wawrzynek,
2007}):

\begin{equation}\phantomsection\label{eq-geom}{P(X=k) = p(1-p)^{k-1}}\end{equation}
gdzie \(0 < p < 1\), a \(k\) jest dowolną liczbą naturalną.

Wartość oczekiwana i wariancja tej zmiennej losowej wynoszą:

\[ EX=\frac{1}{p}, \ D^2X=\frac{1-p}{p^2}\]

Rozkład prawdopodobieństwa zmiennej losowej \(X\) o rozkładzie
geometrycznym z parametrem \(p=0,3\) został przedstawiony na
rys.~\ref{fig-geom}.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{r05_files/figure-pdf/fig-geom-1.pdf}}

}

\caption{\label{fig-geom}Rozkład prawdopodobieństwa zmiennej losowej o
rozkładzie geometrycznym (p=0,3)}

\end{figure}%

Zmienna losowa o rozkładzie geometrycznym podaje prawdopodobieństwa
liczby potrzebnych doświadczeń realizowanych według schematu
Bernoulliego do momentu uzyskania pierwszego sukcesu.

\section{Przykłady - rozkłady
skokowe}\label{przykux142ady---rozkux142ady-skokowe}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 5.1.}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 5.2.}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 5.3.}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 5.4.}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\section{Zadania i pytania}\label{zadania-i-pytania-3}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={Zadania}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-warning-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-warning-color-frame, colback=white]

\end{tcolorbox}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
\item
\item
\item
\item
\end{enumerate}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={Pytania problemowe}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
\item
\item
\item
\item
\end{enumerate}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={Prawda czy fałsz?}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-caution-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-caution-color-frame, colback=white]

\end{tcolorbox}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
\item
\item
\item
\item
\end{enumerate}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={Pytania testowe}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-important-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-important-color-frame, colback=white]

\end{tcolorbox}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
\item
\item
\item
\item
\end{enumerate}

\bookmarksetup{startatroot}

\chapter{Wybrane rozkłady zmiennych losowych
ciągłych}\label{wybrane-rozkux142ady-zmiennych-losowych-ciux105gux142ych}

W tym rozdziale przedstawiono najczęściej spotykane w praktyce rozkłady
zmiennych losowych ciągłych. We wszystkich przypadkach podano gęstość
prawdopodobieństwa lub zasadę konstrukcji zmiennej losowej,
przedstawiono wzory na obliczanie wartości oczekiwanej i wariancji, a
także przedstawiono przykłady zastosowania tych rozkładów.

\href{https://home.agh.edu.pl/~adan/wyklady/siod3-2014.pdf}{Zmienne
ciągłe}

\href{https://wyznacznik.pl/zmienne-losowe-ciagle-zadania}{Zmienne
ciągłe}

\href{https://merlin.up.poznan.pl/~strabel/dydaktyka/statystyka/ciagla.pdf}{Zmienne\ldots{}}

\section{Rozkład jednostajny}\label{rozkux142ad-jednostajny}

Zmienna losowa ma rozkład jednostajny (prostokątny) na przedziale {[}a,
b{]}, gdzie a\textless b, jeśli jej funkcja gęstości ma postać:

\begin{equation}\phantomsection\label{eq-gest_jed}{
f(x) = 
\begin{cases} 
0 &  \text{dla }x <a \\
\frac{1}{b - a} & \text{dla } x \in [a, b], \\
0 &  \text{dla }x >b.
\end{cases} 
}\end{equation}

Wartość oczekiwana i wariancja zmiennej losowej o rozkładzie
jednostajnym zadanym \ref{eq-gest_jed} są następująco:

\[EX=\frac{a+b}{2}, \ D^2X=\frac{(b-a)^2}{12}\]

Postać funkcji gęstości zadanej wzorem wzór \ref{eq-gest_jed} została
przedstawiona na rys.~\ref{fig-gest_jed} Zmienna losowa przedstawiona na
tym wykresie może przyjmować dowolne wartości z przedziału {[}a,b{]}.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{r06_files/figure-pdf/fig-gest_jed-1.pdf}}

}

\caption{\label{fig-gest_jed}Gęstość rozkładu jednostajnego na
przedziale {[}a, b{]}}

\end{figure}%

.

Pole pod wykresem funkcji gęstości (rys.~\ref{fig-gest_jed}) wynosi 1.
Można obliczyć to wykorzystując rachunek całkowy, ale jednocześnie jest
to łatwo zauważalne zważywszy, że pole pod wykresem, to obszar
prostokąta o bokach \(b-a\) oraz \(\frac{1}{b-a}\).

\section{Rozkład trójkatny}\label{rozkux142ad-truxf3jkatny}

Zmienna losowa o rozkładzie trójkątnym ma następującą funkcję gęstości
(Snopkowski (\citeproc{ref-snopkowski2007}{2007})):

\begin{equation}\phantomsection\label{eq-gest_tr}{
f(x) = 
\begin{cases} 
0 &  \text{dla x < a} \\
\frac{2(x-a)}{(b-a)(c-a)} & \text{dla } a \le x \le b \\
\frac{s(c-x)}{(c - a)(c-b)} & \text{dla } b < x \le c \\
0 &  \text{dla x > c}
\end{cases}
}\end{equation}

Wartość oczekiwana i wariancja zmiennej losowej o rozkładzie trójkątnym
zadanym \ref{eq-gest_tr} są następujace:

\[EX=\frac{a+b+c}{3}, \ D^2X=\frac{a^2+b^2+c^2-ab-ac-bc}{18}\]

Na rys.~\ref{fig-gest_tr} przedstawiono funkcję gęstości zmiennej
losowej o rozkładzie trójkątnym zadanej wzorem \ref{eq-gest_tr}.
Widoczne jest, że tak określona zmienna losowa może przyjmować dowolne
wartości w przedziale \([a,c]\).

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{r06_files/figure-pdf/fig-gest_tr-1.pdf}}

}

\caption{\label{fig-gest_tr}Gęstość rozkładu trójkątnego na przedziale
{[}a, c{]}}

\end{figure}%

\section{Rozkład normalny}\label{rozkux142ad-normalny}

Zmienna losowa \(X\) ma rozkład normalny z parametrami
\(\mu \text{ oraz } \sigma^2\) jeśli jej funkcja gęstości ma następującą
postać:

\begin{equation}\phantomsection\label{eq-gest_nor}{f(x)=\frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}}\end{equation}

gdzie: \[ \mu \in \mathbb{R}, \  \sigma > 0.\]

Dla takiej zmiennej stosuje się zapis:

\[X \sim N(\mu, \sigma^2)\]

Wartość oczekiwana i wariancja zmiennej losowej X wynoszą:

\[EX=\mu \text{, } D^2X=\sigma^2\]

Na rys. rys.~\ref{fig-gest_nor2} przedstawiono gęstości
prawdopodobieństwa dwóch zmiennych losowych o rozkładach normalnych z
parametrami odpowiednio \(\mu_1, \sigma_1^2\) oraz
\(\mu_2, \sigma_2^2\).

Na rysunku łatwo dostrzec, że w danym przypadku prawdziwe są następujące
nierówności: \(\mu_1< \mu_2\) oraz \(\sigma_1 > \sigma_2\)

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{r06_files/figure-pdf/fig-gest_nor2-1.pdf}}

}

\caption{\label{fig-gest_nor2}Gęstości dwóch zmiennych losowych o
rozkładach normalnych z różnymi parametrami}

\end{figure}%

Szczególnym przypadkiem zmiennej losowej o rozkładzie normalnym jest
zmienna losowa o rozkładzie normalnym standardowym \(Z \sim N(0,1)\),
gdzie wartość oczekiwana wynosi 0, a wariancja 1. Zgodnie z wzorem
\ref{eq-gest_nor} postać funkcji gęstości zmiennej losowej o rozkładzie
normalnym standardowym jest następujaca:

\begin{equation}\phantomsection\label{eq-gest_nor_st}{f(x)=\frac{1}{\sqrt{2\pi}} e^{-\frac{x^2}{2}}}\end{equation}

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{r06_files/figure-pdf/fig-gest_nor_st-1.pdf}}

}

\caption{\label{fig-gest_nor_st}Gęstość rozkładu normalnego
standardowego}

\end{figure}%

Na rys. rys.~\ref{fig-gest_nor_st} przedstawiono wykres funkcji gęstości
zmiennej losowej o rozkładzie normalnym standardowym. Zmienna losowa o
rozkładzie normalnym standardowym może przyjmować dowolne wartości
rzeczywiste. Jednak jak to jest widoczne na tym wykresie w praktyce
przyjmuje wartości z przedziału od (-3, 3). Prawdopodobieństwo
zdarzenia, że zmienna losowa przyjmie wartość z tego przedziału wynosi
prawie 0,999.

\[P(-3<Z<3) \approx 0,9987 \text{, jeśli } Z \sim N(0,1)\]

Na rys. rys.~\ref{fig-dys_norm} przedstawiono wykres dystrybuanty
zmiennej losowej o rozkladzie normalnym standardowym. Funkcja ta
przyjmuje wartości od 0 do 1, jest to funkcja rosnąca, a granice w
\(-\infty\) i \(+\infty\) wynoszą odpowiednio 0 i 1.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{r06_files/figure-pdf/fig-dys_norm-1.pdf}}

}

\caption{\label{fig-dys_norm}Dystrybuanta rozkładu normalnego
standardowego}

\end{figure}%

Na rys. rys.~\ref{fig-gest_nor3} przedstawiono gęstości trzech zmiennych
losowych o rozkładach normalnych.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{r06_files/figure-pdf/fig-gest_nor3-1.pdf}}

}

\caption{\label{fig-gest_nor3}Gęstości trzech zmiennych losowych o
rozkładach normalnych z różnymi parametrami}

\end{figure}%

Każdą zmienną losową o rozkładzie normalnym z parametrami \(\mu\) oraz
\(\sigma^2\) można sprowadzić do zmiennej losowej o rozkładzie normalnym
standardowym. W tym celu należy przeprowadzić standaryzację.

Standaryzacja rozkładu normalnego polega na następującym
przekształceniu:

\begin{equation}\phantomsection\label{eq-standaryzacja}{X \sim N(\mu,\sigma^2) \Rightarrow Z=\frac{X-\mu}{\sigma}:N(0,1)}\end{equation}

Na rys. rys.~\ref{fig-nor_stand} graficznie przedstawiono procedurę
standaryzacji. Zaznaczone pola, a więc również odpowiednie
prawdopodobieństwa, pomimo że odpowiadają innym zmiennym losowym sa
równe. Formalnie można to zapisać następująco:

Jeżeli \(X \sim N(\mu, \sigma^2)\), to

\[P(a<X<b)=P\left( \frac{a-\mu}{\sigma}<\frac{X-\mu}{\sigma}<\frac{b-\mu}{\sigma} \right) = P \left (\frac{a-\mu}{\sigma}<Z<\frac{b-\mu}{\sigma} \right)\]

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{r06_files/figure-pdf/fig-nor_stand-1.pdf}}

}

\caption{\label{fig-nor_stand}Ilustracja idei standaryzacji rozkładu
normalnego}

\end{figure}%

\section{Rozkład chi-kwadrat}\label{rozkux142ad-chi-kwadrat}

Jeżeli \(X_1, X_2, \ldots,X_k\) są niezależnymi zmiennymi losowymi o
rozkładzie normalnym standardowym, to zmienna losowa

\begin{equation}\phantomsection\label{eq-chi2}{\chi^2=\sum_{i=1}^k X_i^2}\end{equation}

ma rozkład chi-kwadrat o \(k\) stopniach swobody.

Wartość oczekiwana i wariancja zmiennej losowej \(\chi^2\) o rozkładzie
chi-kwadrat o \(k\) stopniach swobody wynoszą:

\[ E \chi^2=k, D^2 \chi^2=2k\]

Na rys.~\ref{fig-gest_chi} przedstawiono gęstości trzech zmiennych
losowych o rozkładach chi-kwadrat z różnymi parametrami.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{r06_files/figure-pdf/fig-gest_chi-1.pdf}}

}

\caption{\label{fig-gest_chi}Gęstosci zmiennych losowych o rozkładzie
chi-kwadrat}

\end{figure}%

\section{Rozkład t-Studenta}\label{rozkux142ad-t-studenta}

Jeżeli zmienna losowa \(X\) ma rozkład normalny standardowy, a zmienna
losowa \(Y\) rozkład chi-kwadrat o \(k\) stopniach swobody, to zmienna
losowa

\begin{equation}\phantomsection\label{eq-t}{t=\frac{X}{\sqrt{\frac{Y}{k}}}}\end{equation}

ma rozkład \(t\) Studenta o \(k\) stopniach swobody.

Wartość oczekiwana i wariancja zmiennej losowej \(t\) o rozkładzie \(t\)
Studenta o \(k\) stopniach swobody są następujące:

\[Et=0 \text{, } D^2t=\frac{k}{k-2} \text{, dla } k > 2\] Dla liczby
stopni swobody \(k = 1, 2\) wariancja zmiennej losowej \(t\) nie
istnieje.

Na rys.~\ref{fig-gest_t} przedstawiono gęstości zmiennych losowych o
rozkładzie \(t\) Studenta dla 3, 5 i 30 stopni swobody, a także gęstość
zmiennej losowej o rozkładzie normalnym standardowym.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{r06_files/figure-pdf/fig-gest_t-1.pdf}}

}

\caption{\label{fig-gest_t}Gęstości zmiennych losowych o rozkładzie
\(t\) Studenta (\(k\) = 3, 5 i 30) oraz gęstość rozkładu normalnego
standardowego}

\end{figure}%

\section{Rozkład F}\label{rozkux142ad-f}

Jeżeli \(X_1\) i \(X_2\) są zmiennymi losowymi o rozkładach chi-kwadrat
odpowiednio z \(k\) i \(m\) stopniami swobody, to zmienna losowa
\begin{equation}\phantomsection\label{eq-F}{F=\frac{X_1}{X_2}}\end{equation}

ma rozkład \(F\) (\(F\)-Snedecora, Fishera-Snedecora) o \(k, m\)
stopniach swobody.

Wartość oczekiwana i wariancja zmiennej losowej \(F\) o rozkładzie \(F\)
Snedecora o \(k,m\) stopniach swobody są następujące:

\[EF=\frac{m}{m-2} \text{, dla } m>2\] oraz

\[D^2F=\frac{2k^2(k+m-2)}{k(m-2)^2(m-4)} \text{, dla } m>4\]

Na rys.~\ref{fig-gest_F} przedstawiono gęstości trzech zmiennych
losowych o rozkładzie F.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{r06_files/figure-pdf/fig-gest_F-1.pdf}}

}

\caption{\label{fig-gest_F}Gęstości trzech zmiennych losowych o
rozkładzie F}

\end{figure}%

\section{Rozkład wykładniczy}\label{rozkux142ad-wykux142adniczy}

Zmienna losowa X ma rozkład wykładniczy z parametrem \(\lambda\), jeśli
jej funkcja gęstości ma postać:

\begin{equation}\phantomsection\label{eq-ges_exp}{f(x)=
\begin{cases} 
\lambda e^{-\lambda x} & \text{dla } x \geq 0, \\
0 & \text{dla } x < 0.
\end{cases}
}\end{equation}

Wartość oczekiwana i wariancja zmiennej losowej \(X\) o rozkładzie
wykładniczym z parametrem \(\lambda\) są następujące:

\[ EX=\lambda \text{, } D^2X=\lambda^2\] Na rys. rys.~\ref{fig-gest_wyk}
przedstawiono wykresy trzech gęstości zmiennych losowych o rozkładzie
wykładniczym (1,2,5)

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{r06_files/figure-pdf/fig-gest_wyk-1.pdf}}

}

\caption{\label{fig-gest_wyk}Gęstosci trzech zmiennych losowych o
rozkładzie o rozkładzie wykładniczym}

\end{figure}%

\section{Rozkład gamma}\label{rozkux142ad-gamma}

Zmienna losowa \(X\) ma rozkład gamma z parametrem kształtu \(\alpha\)
oraz z parametrem skali \(\beta\), jeśli jej funkcja gęstości ma postać:

\begin{equation}\phantomsection\label{eq-gamma}{f(x)=\frac{\beta^\alpha}{\Gamma(\beta)} x^{\beta-1}e^{-\alpha x}  \text{, dla } x \geq 0}\end{equation}

gdzie funkcja \(\Gamma\) jest zadana następująco:

\[\Gamma(\alpha)=\int_0^\infty t^{\alpha-1}e^{-t}dt\]

Własnosci funkcji \(\Gamma\):

\[\Gamma(\alpha+1)=\alpha \Gamma(\alpha)\]

\[\Gamma(n+1)=n!\]

\[\Gamma \left( \frac{1}{2} \right)=\sqrt{\pi}\]

Na rys. rys.~\ref{fig-gest_gamma} przedstawiono wykresy trzech gęstości
zmiennych losowych o rozkładzie gamma.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{r06_files/figure-pdf/fig-gest_gamma-1.pdf}}

}

\caption{\label{fig-gest_gamma}Gęstosci trzech zmiennych losowych o
rozkładzie gamma}

\end{figure}%

\section{Rozkład beta}\label{rozkux142ad-beta}

Zmienna losowa \(X\) ma rozkład beta z parametrami a i b, jeśli jej
funcja gęstości ma postać:

\begin{equation}\phantomsection\label{eq-beta}{f(x)=B^{-1}(a,b)x^{a-1}(1-x)^{b-1}  \text{, dla } 0 \le x \le 1}\end{equation}

gdzie:

\[B(a,b)=\int_0^1 x^{a-1}(1-x)^{b-1}dx=\frac{\Gamma(a)\Gamma(b)}{\Gamma(a+b)}\]
jest tzw. funkcją beta.

Na rys. rys.~\ref{fig-gest_beta} przedstawiono wykresy trzech gęstości
zmiennych losowych o rozkladzie beta.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{r06_files/figure-pdf/fig-gest_beta-1.pdf}}

}

\caption{\label{fig-gest_beta}Gęstosci trzech zmiennych losowych o
rozkładzie beta}

\end{figure}%

\section{Rozkład Cauchy'ego}\label{rozkux142ad-cauchyego}

Jeżeli zmienne losowe \(X\) i \(Y\) są niezależnymi zmiennymi losowymi o
rozkładzie normalnym standardowym, to zmienna losowa

\begin{equation}\phantomsection\label{eq-Cauchy}{C=\frac{X}{Y}}\end{equation}

ma rozkład Cauchy'ego z parametrami 0 oraz 1.

Na rys. rys.~\ref{fig-gest_cauchy} przedstawiono wykresy trzech gęstości
zmiennych losowych o rozkladzie Cauchy'ego. Zmienna losowa o rozkładzie
Cauchy'ego nie posiada ani wartości oczekiwanej, ani wariancji.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{r06_files/figure-pdf/fig-gest_cauchy-1.pdf}}

}

\caption{\label{fig-gest_cauchy}Gęstości trzech zmiennych losowych o
rozkładzie Cauchy'ego}

\end{figure}%

\section{Przykłady - rozkłady
ciągłe}\label{przykux142ady---rozkux142ady-ciux105gux142e}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 6.1.}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 6.2.}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 6.3.}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 6.4.}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\section{Zadania i pytania}\label{zadania-i-pytania-4}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={Zadania}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-warning-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-warning-color-frame, colback=white]

\end{tcolorbox}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
\item
\item
\item
\item
\end{enumerate}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={Pytania problemowe}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
\item
\item
\item
\item
\end{enumerate}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={Prawda czy fałsz?}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-caution-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-caution-color-frame, colback=white]

\end{tcolorbox}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
\item
\item
\item
\item
\end{enumerate}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={Pytania testowe}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-important-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-important-color-frame, colback=white]

\end{tcolorbox}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
\item
\item
\item
\item
\end{enumerate}

\bookmarksetup{startatroot}

\chapter{Wielowymiarowe zmienne
losowe}\label{wielowymiarowe-zmienne-losowe}

W tym rozdziale przedstawiono uogólnienie pojęcia zmiennej losowej na
przypadek wielowymiarowy. Podano przykłady zmiennych losowych
wielowymiarowych skokowych i ciągłych. Szczególną uwagę zwrócono na
zmienne losowe dwuwymiarowe, a w szczególnosci na zmienną losową o
dwuwymiarowym rozkładzie normalnym.

\href{https://home.agh.edu.pl/~adan/wyklady/rpis4.pdf}{Wielowymiarowe}

\href{http://prac.im.pwr.wroc.pl/~wkosz/Probabilistyka7.pdf}{Wielowymiarowe}

\href{http://statystyka.rezolwenta.eu.org/Materialy/wielowymiarowe.pdf}{Wielowymiarowe}

\href{https://www.cs.put.poznan.pl/wkotlowski/mp/07_wielowymiarowe_zmienne_losowe.pdf}{Wielowymiarowe}

Zmienną losową n-wywymiarową nazywa się ciąg \((X_1, X_2, \ldots, X_n)\)
\(n\) funkcji rzeczywistych

\(X_1=X_1(\omega), X_2=X_2(\omega), \ldots. X_n(\omega)\)

określonych na przestrzeni zdarzeń elementarnych
\(\omega (\omega \in \Omega)\), takich, że dla dowolnego ciągu liczb
rzeczywistych

\(x_1, x_2, \ldots, x_n\)

odpowiadajacy mu podzbiór
\(A=\{ \omega: X_1(\omega) < x_1,X_2(\omega)  <x_2,\ldots, X_n(\omega)  <x_n \}\)
zdarzeń elemmentarnych jest zdarzeniem losowym
(\citeproc{ref-wawrzynek2007}{Wawrzynek, 2007}).

W dalszej części rozważane będą głównie dwuwymiarowe zmienne losowe.

\section{Dwuwymiarowa zmienna losowa
skokowa}\label{dwuwymiarowa-zmienna-losowa-skokowa}

Dwuwymiarowa zmienna losowa \((X, Y)\) jest zmienną skokową, jeśli każda
ze zmiennych losowych X i Y ma skończony lub przeliczalny zbiór
wartości.

Łączny rozkład prawdopodobieństwa dwuwymiarowej zmiennej losowej
\((X, Y)\) wyraża się następującym wzorem:

\begin{equation}\phantomsection\label{eq-roz_p2wym}{P(X=x_i, Y=y_j) =  p_{ij},}\end{equation}

\(\text{ przy czym } \sum_i\sum_jp_{ij}=1\)

Podobnie jak w przypadku zmiennej losowej jednowymiarowej (por. pkt 4.1)
rozkład dwuwymiarowej zmiennej losowej często będzie przedstawiany w
formie tablicy. W tabela~\ref{tbl-2wym} przedstawiono rozkład zmiennej
losowej dwuwymiarowej \((X,Y)\), gdzie zmienna losowa \(X\) może
przyjmować \(r\), a zmienna losowa \(Y\) \(s\) wartości,

\begin{longtable}[]{@{}lllll@{}}
\caption{Dwuwymiarowy rozkład skokowy}\label{tbl-2wym}\tabularnewline
\toprule\noalign{}
\endfirsthead
\endhead
\bottomrule\noalign{}
\endlastfoot
& \(y_1\) & \(y_2\) & \(\ldots\) & \(y_s\) \\
\(x_1\) & \(p_{11}\) & \(p_{12}\) & \(\ldots\) & \(p_{1s}\) \\
\(x_2\) & \(p_{21}\) & \(p_{22}\) & \(\ldots\) & \(p_{2s}\) \\
\(\ldots\) & \(\ldots\) & \(\ldots\) & \(\ldots\) & \(\ldots\) \\
\(x_r\) & \(p_{r1}\) & \(p_{r2}\) & \(\ldots\) & \(p_{rs}\) \\
\end{longtable}

Jak pokazano w Tabeli tabela~\ref{tbl-2wym1}, \ldots{}

\subsection{Momenty dwuwymiarowej zmiennej losowej
skokowej}\label{momenty-dwuwymiarowej-zmiennej-losowej-skokowej}

Jeżeli dana jest dwuwymiarowa zmienna losowa \((X,Y)\), to momentem
zwykłym rzędu \(r+s, r, s = 0, 1, \ldots\) jest:

\begin{equation}\phantomsection\label{eq-mom_zw_sk}{ m_{rs}=E(X^rY^s)=\sum_i \sum_j x_i^r y_j^s p_{ij}}\end{equation}

W szczególności:

\[ m_{10}=E(X), m_{01}=E(Y), m_{20}=E(X^2), m_{02}=E(Y^2), m_{11}=E(XY)\]

Ostatni z wymienionych momentów nazywany jest momentem mieszanym.

Momentem centralnym rzędu \(r+s\) zmiennej losowej dwuwymiarowej
\((X,Y)\) określa się:

\[ \mu_{rs}=E ( (X-EX)^r(Y-EY)^s ) =\sum_i \sum_j (x_i-EX)^r (y_j-EY)^s p_{ij}\]

Moment centralny \(\mu_{11} = E((X-EX)(Y-EY))=cov(X,Y)\)

nazywany jest kowariancją (\(cov\)) zmiennych losowych \(X\) i \(Y\).

\subsection{Rozkłady brzegowe}\label{rozkux142ady-brzegowe}

Jeżeli znany jest łączny rozkład prawdopodobieństwa dwuwymiarowej
zmiennej losowej \((X,Y)\), to można wyznaczyć rozkład
prawdopodobieństwa każdej z osobna skokowej zmiennej losowej \(X\) lub
\(Y\). Takie rozkłady nazywane są rozkładami brzegowymi odpowiedniej
zmiennej.

Prawdopodobieństwa w rozkładzie brzegowym wyznacza się następująco:

\begin{itemize}
\tightlist
\item
  rozkład brzegowy zmiennej \(X\)
\end{itemize}

\begin{equation}\phantomsection\label{eq-roz_war_sk1}{ P(X=x_i)=\sum_{j=1}^sp_{ij}}\end{equation}

gdzie \(i = 1, 2, \ldots, r\).

\begin{itemize}
\tightlist
\item
  rozkład brzegowy zmiennej \(Y\)
\end{itemize}

\begin{equation}\phantomsection\label{eq-roz_war_sk2}{ P(Y=y_j)=\sum_{i=1}^rp_{ij}}\end{equation}

gdzie \(j = 1, 2, \ldots, s\).

Rozkłady brzegowe zmiennych losowych zwykle przedstawia się rozbudowując
tabelę tabela~\ref{tbl-2wym} uzyskując rezultat jak w tabeli
tabela~\ref{tbl-2wym1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1667}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1667}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1667}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1667}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1667}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1667}}@{}}
\caption{Dwuwymiarowy rozkład skokowy z rozkładami
brzegowymi}\label{tbl-2wym1}\tabularnewline
\toprule\noalign{}
\endfirsthead
\endhead
\bottomrule\noalign{}
\endlastfoot
& \(y_1\) & \(y_2\) & \(\ldots\) & \(y_s\) & \(p_{i\cdot}\) \\
\(x_1\) & \(p_{11}\) & \(p_{12}\) & \(\ldots\) & \(p_{1s}\) &
\(p_{1\cdot}\) \\
\(x_2\) & \(p_{21}\) & \(p_{22}\) & \(\ldots\) & \(p_{2s}\) &
\(p_{2\cdot}\) \\
\(\ldots\) & \(\ldots\) & \(\ldots\) & \(\ldots\) & \(\ldots\) &
\(\ldots\) \\
\(x_r\) & \(p_{r1}\) & \(p_{r2}\) & \(\ldots\) & \(p_{rs}\) &
\(p_{r\cdot}\) \\
\(p_{\cdot j}\) & \(p_{\cdot 1}\) & \(p_{\cdot 2}\) & \(\ldots\) &
\(p_{\cdot s}\) & \(1\) \\
\end{longtable}

Dysponując danymi jak w tabela~\ref{tbl-2wym1} można obliczyć wartość
oczekiwaną i wariancję zmiennych losowych \(X\) i \(Y\).

\begin{itemize}
\tightlist
\item
  dla zmiennej losowej \(X\)
\end{itemize}

\begin{equation}\phantomsection\label{eq-EX}{ EX = \sum_{i=1}^rx_ip_{i\cdot}}\end{equation}
\begin{equation}\phantomsection\label{eq-D2X}{ D^2X = \sum_{i=1}^ry_i^2p_{i\cdot} - (EX)^2}\end{equation}

\begin{itemize}
\tightlist
\item
  dla zmiennej losowej \(Y\)
\end{itemize}

\begin{equation}\phantomsection\label{eq-EY}{ EY = \sum_{j=1}^sx_jp_{\cdot j}}\end{equation}

\begin{equation}\phantomsection\label{eq-D2Y}{ D^2Y = \sum_{j=1}^sy_j^2p_{\cdot j} - (EY)^2}\end{equation}

\subsection{Rozkłady warunkowe}\label{rozkux142ady-warunkowe}

Prawdopodobieństwa realizacji zmiennej losowej w rozkładzie warunkowym
skokowej zmiennej losowej \(X\), pod warunkiem, że zmienna losowa \(Y\)
przyjęła wartość \(y_j\) wyznacza się następująco:

\begin{equation}\phantomsection\label{eq-roz_war_X}{ P(X=x_i/Y=y_j) = \frac{p_{ij}}{p_{\cdot j}}}\end{equation}
gdzie \(i = 1, 2, \ldots, r\).

Podobnie wyznacza się prawdopodobieństwa warunkowe zmiennej losowej
\(Y\), pod warunkiem, że zmienna losowa \(X\) przyjęła wartość \(x_i\)

\begin{equation}\phantomsection\label{eq-roz_war_Y}{ P(Y=y_j/X=x_i) = \frac{p_{ij}}{p_{i \cdot}}}\end{equation}

gdzie \(j = 1, 2, \ldots, s\).

Dla zmiennych warunkowych można wyznaczyć wartość oczekiwaną i wariancję
następująco:

\begin{equation}\phantomsection\label{eq-war_EX}{E(X/Y=y_j)=\sum_{i=1}^rx_i\frac{p_{ij}}{p_{i \cdot}}}\end{equation}

\begin{equation}\phantomsection\label{eq-war_EY}{E(Y/X=x_i)=\sum_{j=1}^sy_j\frac{p_{ij}}{p_{\cdot j}}}\end{equation}

\section{Dwuwymiarowa zmienna losowa
ciągła}\label{dwuwymiarowa-zmienna-losowa-ciux105gux142a}

Dwuwymiarowa zmienna losowa ciągła \((X,Y)\) to zmienna losowa, która
może przyjmować nieprzeliczalną liczbę par wartości
\((x,y) \in \mathbb{R}^2\).

Gęstością prawdopodobieństwa zmiennej losowej ciągłej \((X,Y)\) jest
funkcja \(f_{X,Y}(x,y)\) o następujacych własnościach
(\citeproc{ref-snopkowski2007}{Snopkowski, 2007}):

\[f_{X,Y}(x,y) \ge 0 \text{, dla } (x,y) \in \mathbb{R}^2.\]

\[ \int_{-\infty}^\infty f_{X,Y}(x,y)dxdy=1\]

Dystrybuanta dwuwymiarowej zmiennej losowej ciągłej \((X,Y)\) jest
funkcja \(F_{X,Y}(x,y)\) określona następująco:

\begin{equation}\phantomsection\label{eq-dys_2wcg}{ F_{X,Y}(x,y)=P(X < x, Y <y)=\int_{-\infty}^\infty \int_{-\infty}^\infty f_{X,Y}(s,t)dsdt=1}\end{equation}

\subsection{Momenty dwuwymiarowej zmiennej losowej
ciągłej}\label{momenty-dwuwymiarowej-zmiennej-losowej-ciux105gux142ej}

Jeżeli dana jest dwuwymiarowa zmienna losowa \((X,Y)\) ciągła, to
momentem zwykłym rzędu \(r+s, r, s = 0, 1, \ldots\) jest:

\begin{equation}\phantomsection\label{eq-mom_zw_cg}{ m_{rs}=E(X^rY^s)=\int_{-\infty}^{\infty}\int_{-\infty}^{\infty} x^r y^s dxdy}\end{equation}

W szczególności:

\[ m_{10}=E(X), m_{01}=E(Y), m_{20}=E(X^2), m_{02}=E(Y^2), m_{11}=E(XY)\]
Ostatni z momentów nazywany jest momentem mieszanym.

Momentem centralnym rzędu r+s zmiennej losowej dwuwymiarowej \((X,Y)\)
określa się:

\begin{equation}\phantomsection\label{eq-mom_cen_cg}{ \mu_{rs}=E((X-EX)^r(Y-EY)^s)=\int_{-\infty}^{\infty}\int_{-\infty}^{\infty} (x-EX)^r (y-EY)^s dxdy}\end{equation}

Moment centralny \[\mu_{11} = E((X-EX)(Y-EY))=cov(X,Y)\]

nazywany jest kowariancją zmiennych losowych \(X\) i \(Y\).

W szczególności należy zauważyć, że

\[cov(X,X)=D^2X=\mu_{20}\] oraz \[cov(Y,Y)=D^2Y=\mu_{02}.\]

Brzegowa funkcja gęstości \(f_X(x)\) zmiennej losowej \(X\) wyraża się
następującym wzorem:

\begin{equation}\phantomsection\label{eq-brz_cgX}{ f_X(x)=\int_{-\infty}^{\infty}f_{X,Y}(x,y)dy}\end{equation}

Brzegowa funkcja gęstości \(f_X(x)\) zmiennej losowej \(Y\) wyraża się
następującym wzorem:

\begin{equation}\phantomsection\label{eq-brz_cgY}{ f_Y(y)=\int_{-\infty}^{\infty}f_{X,Y}(x,y)dx}\end{equation}

Gęstość prawdopodobieństwa zmiennej losowej \(X\), przy ustalonej
wartości zmiennej losowej \(Y\), określa się mianem warunkowej gęstości
prawdopodobieństwa

\begin{equation}\phantomsection\label{eq-war_cgX}{ f_{X/Y}(x,y) = \frac{f_{X,Y}(x,y)}{f_Y(y)}}\end{equation}
Gęstość prawdopodobieństwa zmiennej losowej \(Y\), przy ustalonej
wartości zmiennej losowej \(X\), określa się mianem warunkowej gęstości
prawdopodobieństwa

\begin{equation}\phantomsection\label{eq-war_cgY}{ f_{Y/X}(x,y) = \frac{f_{X,Y}(x,y)}{f_X(x)}}\end{equation}

Jeżeli zmienne losowe \(X\) i \(Y\) są niezależne, to:

\[f_{X/Y}(x,y)=f_X(x,y)f_Y(x,y)\]

\[F(x,y)=F_X(x)F_Y(y)\]

\subsection{Rozkłady brzegowe}\label{rozkux142ady-brzegowe-1}

Brzegowa funkcja gęstości (rozkład brzegowy) dla zmiennej losowej \(X\)
ma postać:

\[f_X(x)=\int_{-\infty}^{\infty}f(x,y)dy\] a dla zmiennej \(Y\) ma
postać: \[f_Y(y)=\int_{-\infty}^{\infty}f(x,y)dx\]

\subsection{Rozkłady warunkowe}\label{rozkux142ady-warunkowe-1}

Rozkład warunkowy zmiennej losowej \(X\) pod warunkiem, że \(Y=y_0\),
to:

\[f_{X/Y=y_0}=\frac{f(x,y_0)}{f_Y(y_0)} \text{, dla dowolnych } (x,y_0) \in \mathbb{R}^2 \text{ takich, że } f_Y(y_0)>0\]

Analogicznie rozkład warunkowy zmiennej losowej \(Y\) pod warunkiem, że
\(X=x_0\), to:

\[f_{Y/X=x_0}=\frac{f(x_0,y)}{f_X(x_0)} \text{, dla dowolnych } (x_0,y) \in \mathbb{R}^2 \text{ takich, że } f_X(x_0)>0\]

Warunkowe wartości oczekiwane dla zmiennych losowych dwuwymiarowych
ciągłych wyrażają się następującymi wzorami

\[ E(X/Y=y_0) = \frac{ \int_{-\infty}^{\infty} x f(x,y_0)dx  }{\int_{-\infty}^{\infty} f(x,y_0)dx},\]

\[ E(Y/X=x_0) = \frac{ \int_{-\infty}^{\infty} y f(x_0,y)dy  }{\int_{-\infty}^{\infty} f(x_0,y)dy}.\]

\section{Dwu- i wielowymiarowy rozkład
normalny}\label{dwu--i-wielowymiarowy-rozkux142ad-normalny}

Wielowymiarowy rozkład normalny, często nazywany rozkładem
wielowymiarowym Gaussa, ma kluczowe znaczenie w statystyce,
probabilistyce i wielu dziedzinach nauki. Rozszerza ideę
jednowymiarowego rozkładu normalnego na przestrzenie wielowymiarowe.
Wielowymiarowy rozkład normalny pozwala na modelowanie zjawisk, w
których występuje wiele powiązanych ze sobą zmiennych. Jest to
szczególnie przydatne w badaniach naukowych, gdzie często mamy do
czynienia z wieloma współzależnymi czynnikami. Informacji o
zależnościach między zmiennymi dostarcza macierz wariancji-kowariancji
\(\boldsymbol{\Sigma}\).

\subsection{Dwuwymiarowy rozkład
normalny}\label{dwuwymiarowy-rozkux142ad-normalny}

Zmienna losowa \((X,Y)\) ma dwuwymiarowy rozkład normalny jeśli jej
funkcja gęstości zadana jest następującym wzorem:

\begin{equation}\phantomsection\label{eq-2wym_nor}{f_{XY}(x,y)= \frac{1}{2\pi \sigma_X \sigma_Y} e^{- \frac{1}{2(1-\rho^2)}q(x,y)}}\end{equation}
gdzie:

\(q(x,y) = \frac{(x-\mu_X)^2}{\sigma_X^2} - 2\rho \frac{(x-\mu_X)(y-\mu_Y)}{\sigma_X \sigma_Y} + \frac{(y-\mu_Y)^2}{\sigma_Y^2}\)

\(x, y \in (-\infty, \infty)\) , \(\sigma_X, \sigma_Y \ge 0\),
\(\mu_X, \mu_Y \in \mathbb{R}\)

\(-1 \le \rho \le 1 \text{ jest współczynnikiem korelacji pomiędzy zmiennymi losowymi X i Y}\)

Na rys.~\ref{fig-nor2wym} przedstawiono ilustrację trójwymiarową tej
gęstości (po lewej) oraz warstwice gęstości rozkładu normalnego
dwuwymiarowego (po prawej).

\begin{verbatim}
pdf 
  2 
\end{verbatim}

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{r07_files/figure-pdf/fig-nor2wym-1.pdf}}

}

\caption{\label{fig-nor2wym}Dwuwymiarowy rozkład normalny qęstość w
widoku 3D (po lewej) oraz warstwice gęstości (po prawej)}

\end{figure}%

\subsection{Wielowymiarowy rozkład
normalny}\label{wielowymiarowy-rozkux142ad-normalny}

Zmienna losowa \(\mathbf{X} = (X_1,X_2,\ldots,X_k)\) ma \(k\)-wymiarowy
rozkład normalny jeśli jej funkcja gęstości ma postać
(\citeproc{ref-aczel2000}{Aczel, 2000};
\citeproc{ref-wywial2004}{Wywiał, 2004}):

\[f(\boldsymbol{x})=\frac{1}{(2\pi)^{k/2}|\boldsymbol{\Sigma}|^{1/2}} e^{-\frac{1}{2}(\boldsymbol{x}-\boldsymbol{\mu})^T \boldsymbol{\Sigma}^{-1}(\boldsymbol{x}-\boldsymbol{\mu})}\]

gdzie \(\boldsymbol{x}=(x_1,x_2,\ldots,x_k) \in \mathbb{R}^k\),

\(\boldsymbol{\mu}=(\mu_1,\mu_2,\ldots,\mu_k),\)

\(\mathbf{\Sigma} \text{ jest nieosobliwą macierzą kowariancji, zadaną następująco:}\)

\[
\boldsymbol{\Sigma} =
\begin{bmatrix}
\sigma_{11} & \sigma_{12} & \cdots & \sigma_{1k} \\
\sigma_{21} & \sigma_{22} & \cdots & \sigma_{2k} \\
\vdots & \vdots & \ddots & \vdots \\
\sigma_{k1} & \sigma_{k2} & \cdots & \sigma_{kk}
\end{bmatrix}
\]

gdzie:

\[\sigma_{ii} =D^2 X_i \text{, dla } i = 1, 2, \ldots, k.\]

\[\sigma_{ij}=Cov(X_i,X_j) \text{, dla } i \neq j; \  i,j = 1, 2, \ldots, k.\]

Dla \(k\)-wymiarowej zmiennej losowej \(\mathbf{X}\) stosuje się
oznaczenie:

\[\boldsymbol{X} \sim N(\boldsymbol{\mu},\boldsymbol{\Sigma})\]

Własności

Niech \(X\) będzie \(k\) wymiarową zmienną losową o gęstości \(f_X\)

Dystrybuanta \(F_X\) \(k\)-wymiarowej zmiennej losowej zadana jest
wzorem:

\[F_X(x_1,x_2\ldots,x_k)=P(X_1<x_1, X_2<x_2,\ldots , X_k <x_k)\]

\(\boldsymbol{x}=(x_1,x_2,\ldots,x_k)\)

Dla \(k\) niezależnych zmiennych losowych:

Jeżeli zmienne losowe \(X_1, X_2, \dots, X_k\) sa niezależne, to

\[f_X(x_1,x_2\ldots,x_k)=f_1(x_1)f_2(x_2)\ldots f_k(x_k)\]

\[F(x_1,x_2\ldots,x_k)=F_1(x_1)F_2(x_2)\ldots F_k(x_k)\]

\section{Przykłady - rozkłady
wielowymiarowe}\label{przykux142ady---rozkux142ady-wielowymiarowe}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 6.1.}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 6.2.}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 6.3.}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 6.4.}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\section{Zadania i pytania}\label{zadania-i-pytania-5}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={Zadania}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-warning-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-warning-color-frame, colback=white]

\end{tcolorbox}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
\item
\item
\item
\item
\end{enumerate}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={Pytania problemowe}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
\item
\item
\item
\item
\end{enumerate}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={Prawda czy fałsz?}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-caution-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-caution-color-frame, colback=white]

\end{tcolorbox}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
\item
\item
\item
\item
\end{enumerate}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={Pytania testowe}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-important-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-important-color-frame, colback=white]

\end{tcolorbox}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
\item
\item
\item
\item
\end{enumerate}

\bookmarksetup{startatroot}

\chapter{Wybrane zagadnienia
teoretyczne}\label{wybrane-zagadnienia-teoretyczne}

\hyperref[funkcje-zmiennych-losowych]{Funkcje zmiennych losowych}

\href{https://pl.wikipedia.org/wiki/Funkcja_tworz\%C4\%85ca_momenty}{Funkcje
tworzące}

\href{https://ksiegarnia.iknt.pl/uploads/files/Rachunek_prawdopodobienstwa_fragment.pdf}{Funkcje
charakterystyczne}

\href{https://pl.wikipedia.org/wiki/Funkcja_charakterystyczna_(teoria_prawdopodobie\%C5\%84stwa)}{Funkcje
charakterystyczne}

\href{https://www2.im.uj.edu.pl/LeszekPieniazek/DU/PR/test-25.html}{Nierówność
Czebyszewa}

\href{https://pl.wikipedia.org/wiki/Nier\%C3\%B3wno\%C5\%9B\%C4\%87_Czebyszewa-Bienayme}{Nierówność
Czebyszewa}

\href{http://kryba.home.amu.edu.pl/2019zimaRAP/W060.pdf}{Nierówność
Czebyszewa}

\href{http://kryba.home.amu.edu.pl/2019zimaRAP/W060.pdf}{Twierdzenia
graniczne}

\href{https://www2.im.uj.edu.pl/LeszekPieniazek/DU/PR/test-37.html}{Twierdzenia
graniczne}

\href{https://mgr-mimuw.fandom.com/wiki/Twierdzenia_graniczne_w_rachunku_prawdopodobie\%C5\%84stwa}{Twierdzenia
graniczne}

\href{http://kryba.home.amu.edu.pl/2019zimaRAP/W063.pdf}{Twierdzenia
graniczne}

\href{https://pl.wikipedia.org/wiki/Proces_stochastyczny}{Procesy
stochastyczne}

https://www2.im.uj.edu.pl/MarcinPitera/files/SP.pdf

https://home.agh.edu.pl/\textasciitilde agorzkow/EiT\_NKwR2122/wyk\%C5\%82ad1.pdf

http://statystyka.rezolwenta.eu.org/Materialy/procesy-2005.pdf

Zagadnienia dodatkowe

W tym rozdziale w zwięzły sposób przedstawiono następujące zagadnienia:

\begin{itemize}
\item
  funkcje zmiennych losowych
\item
  funkcje tworzące
\item
  funkcje charakterystyczne
\item
  nierówność Czebyszewa
\item
  twierdzenia graniczne
\item
  procesy stochastyczne
\end{itemize}

Każdy z tych tematów jest obszerny i szeroko omawiany w literaturze.
Przy wprowadzeniu w tematykę podano przykładowe pozycje literatury
uzupełniającej do samodzielnego pogłębienia wiedzy przez Czytelnika. W
poniższych rozważaniach przytoczono jedynie podstawowe informacje,
zwracając uwagę na wybrane wnioski, które są przydatne we wnioskowaniu
statystycznym.

\section{Funkcje zmiennych losowych}\label{funkcje-zmiennych-losowych}

Jeśli \(X\) jest zmienną losową, a \(g\) jest pewną funkcją, to
\(Y = g(X)\) również jest zmienną losową. Rozkład prawdopodobieństwa
zmiennej losowej \(Y\) zależy od rozkładu zmiennej losowej \(X\) oraz od
postaci funkcji \(g\). Funkcje zmiennych losowych są kluczowym
narzędziem w analizie probabilistycznej i statystycznej, pozwalającym na
modelowanie i badanie złożonych zjawisk losowych. W tym punkcie
przedstawiono przykłady wyznaczania funkcji zmiennych losowych skokowych
i zmiennych losowych ciągłych.

Dodatkowe przykłady wyznaczania funkcji zmiennych losowych przedstawiają
np.: Snopkowski (\citeproc{ref-snopkowski2007}{2007}) {[}127-153{]},
Wieczorkowski \& Zieliński (\citeproc{ref-wieczorkowski1997}{1997, pp.
92--97}), Bratijczuk \& Chydziński (\citeproc{ref-bratijczuk2000}{2000,
pp. 147--149}).

\subsection{Funkcje zmiennych losowych
skokowych}\label{funkcje-zmiennych-losowych-skokowych}

W tym punkcie przedstawiono przykład wyznaczania funkcji zadanej
zmiennej losowej dyskretnej \(X\).

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 8.1}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

Niech zmienna losowa \(X\) ma następujący rozkład prawdopodobieństwa:

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
\(x_i\) & 1 & 2 & 5 \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(p_i\) & 0,1 & 0,3 & 0,6 \\
\end{longtable}

Wyznaczyć rozkład prawdopodobieństwa zmiennej losowej \(Y\), jeśli:

\(\text{a) } Y = 2X+1\)

\(\text{b) } Y = X^2-1\)

\(\text{c) } Y=(X-3)^2\)

\(\text{d) } Y = X_1+X_2+1\), gdzie \(X_1\) i \(X_2\) są niezależnymi
zmiennymi losowymi o rozkładzie jak zmienna losowa \(X\)

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={Rozwiązanie}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\(a)\)

Jeżeli zmienna losowa \(X\) przyjmuje kolejno wartości 1, 2 oraz 5, to
zmienna losowa \(Y\) odpowiednio: 3, 5 i 11. Wobec tego rozkład
prawdopodobeństwa zmiennej losowej \(Y\) jest następujący:

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
\(y_i\) & 3 & 5 & 11 \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(p_i\) & 0,1 & 0,3 & 0,6 \\
\end{longtable}

\(b)\)

Jeżeli zmienna losowa \(X\) przyjmuje kolejno wartości 1, 2 oraz 5, to
zmienna losowa \(Y\) odpowiednio: 0, 3 i 24. Wobec tego rozkład
prawdopodobeństwa zmiennej losowej \(Y\) jest następujący:

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
\(y_i\) & 0 & 3 & 24 \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(p_i\) & 0,1 & 0,3 & 0,6 \\
\end{longtable}

\(c)\)

Jeżeli zmienna losowa \(X\) przyjmuje kolejno wartości 1, 2 oraz 5, to
zmienna losowa \(Y\) odpowiednio: 4, 1 i ponownie 4. Wobec tego rozkład
prawdopodobeństwa zmiennej losowej \(Y\) jest następujący:

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\(y_i\) & 1 & 4 \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(p_i\) & 0,3 & 0,7 \\
\end{longtable}

\(d)\)

Jeżeli zmienne losowe \(X_1\) i \(X_2\) przyjmują wartości 1, 2 oraz 5,
to zmienna losowa \(Y\) może przyjmować wartości: 2 (1+1), 3 (1+2 lub
2+1), 4 (2+2), 6 (1+5 lub 5+1) , 7 (2+5 lub 5+2) oraz 10 (5+5). Wobec
tego rozkład prawdopodobeństwa zmiennej losowej \(Y\) jest następujący:

\begin{longtable}[]{@{}lllllll@{}}
\toprule\noalign{}
\(y_i\) & 2 & 3 & 4 & 6 & 7 & 10 \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(p_i\) & 0,01 & 0,06 & 0,09 & 0,12 & 0,36 & 0,36 \\
\end{longtable}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={***}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

\subsection{Funkcje zmiennych losowych
ciągłych}\label{funkcje-zmiennych-losowych-ciux105gux142ych}

W tym punkcie przedstawiono przykład wyznaczania funkcji zmiennych
losowych ciągłych \(X\) i \(Y\).

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Przykład 8.2}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

Rozważmy dwie zmienne losowe \(X\) i \(Y\), które są niezależne i mają
rozkład jednostajny na przedziale \([0, 1]\), co może być zapisane
następująco:

\(X, Y  \sim  U[0, 1]\).

Wyznaczyć rozkład zmiennej losowej \(Z\), gdzie

\[Z = X + Y\]

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={Rozwiązanie}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

Funkcja gęstości prawdopodobieństwa dla zmiennych losowych \(X\) i \(Y\)
jest następującej postaci:

\[
f(x) = 
\begin{cases} 
0 &  \text{dla }x <0 \\
\frac{1}{b - a} & \text{dla } x \in [0, 1], \\
0 &  \text{dla }x >1.
\end{cases} 
\]

Z określenia postaci zmiennej losowej \(Z\) wynika, że może przyjąć
dowolne wartości z przedziału \([0, 2].\) Stąd otrzymuje się:

dla \(z \notin [0,2] \ f(z) = 0\).

Wyznaczamy splot funkcji \(f_X\) i \(f_Y\), co oznaczamy:

\(f_Z(z) = f_X(x)*f_Y(y)\)

Rozważmy dwa przypadki \(z \in [0;1] \text{ oraz } z \in (1;2]\).

\(\text{a) } z \in [0;1]\)

\[f(z) =\int_{-\infty}^{\infty} f_X(x) f_Y(z-x) \, dx = \int_{0}^{1} f_X(x) f_Y(z-x) \, dx =\]

\[=  \int_{0}^{1} 1 f_Y(z-x) \, dx = \int_{0}^{z} f_Y(z-x) \, dx + \int_{z}^{1} f_Y(z-x) \, dx =\]

\[ = \int_{0}^{z} 1 \, dx + \int_{z}^{1} 0 \, dx = \left[ x \right]_0^z + 0 = z - 0 = z\]

\(\text{b) } z \in (1;2]\)

\[ f(z) = \int_{-\infty}^{\infty} f_X(x) f_Y(z-x) \, dx = \int_{0}^{1} f_X(x) f_Y(z-x) \, dx =\]

\[ =  \int_{0}^{1} 1 f_Y(z-x) \, dx =\int_{0}^{z-1} f_Y(z-x) \, dx + \int_{z-1}^{1} f_Y(z-x) \, dx =\]

\[ = \int_{0}^{z-1} 0 \, dx + \int_{z-1}^{1} 1 \, dx = 0+ \left[ x \right]_{z-1}^1  = 1-(z-1) = 2-z\]

Zatem, funkcja gęstości prawdopodobieństwa dla \(Z = X + Y\) przyjmuje
następującą postać:

\[f_Z(z) = 
\begin{cases} 
0 & \text{dla } z < 0 \\
z & \text{dla } 0 \le z < 1 \\
2 - z & \text{dla } 1 \le z < 2 \\
0 & \text{dla } z \ge 2
\end{cases}\]

Wykres funkcji gęstości sumy dwóch zmiennych losowych o rozkładach
jednostajnych na przedziale {[}0, 1{]} przedstawia
rys.~\ref{fig-gest_sum2}

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{r08_files/figure-pdf/fig-gest_sum2-1.pdf}}

}

\caption{\label{fig-gest_sum2}Gęstość sumy zmiennych losowych X i Y}

\end{figure}%

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title={***}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

\end{tcolorbox}

Podobnie można wykazać, że suma trzech niezależnych zmiennych losowych
\(X, Y\) i \(W\) o rozkładach jednostajnych \(U[0, 1]\) jest dana wzorem
(por.
\href{https://math.stackexchange.com/questions/2631501/finding-the-distribution-of-the-sum-of-three-independent-uniform-random-variable}{Trzy}
).

\[
f_Z(z) = 
\begin{cases} 
0 & \text{dla } x <0 \\
\frac{z^2}{2} & \text{dla } 0 \leq z < 1 \\
-z^2+3z-\frac{3}{2} & \text{dla } 1 \leq z < 2 \\
\frac{(z - 3)^2}{2} & \text{dla } 2 \leq z < 3 \\
0 & \text{dla } x \ge 3
\end{cases}
\]

Wykres funkcji gęstości sumy trzech niezależnych zmiennych losowych o
rozkładzie jednostajnym \(U[0,1]\) przedstawia rys.~\ref{fig-gest_sum3}.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{r08_files/figure-pdf/fig-gest_sum3-1.pdf}}

}

\caption{\label{fig-gest_sum3}Gęstość sumy zmiennych losowych X, Y i W}

\end{figure}%

Warto zauważyć, że gęstość sumy trzech niezaleznych zmiennych losowych o
rozkładach jednostajnych na przedziale \([0, 1]\) kształtem nieco
przypomina gęstość zmiennej losowej o rozkładzie normalnym. W miarę
zwiększania liczby składników \(n\) gęstość sumy zmiennych losowych
(także średniej) będzie coraz bardziej zbliżać się do gęstości zmiennej
losowej o rozkładzie normalnym. Spostrzeżenie to zostanie przybliżone w
dalszej części rozdziału w punkcie ``Twierdzenia graniczne''
???????????.

\subsection{Wybrane związki pomiędzy zmiennymi
losowymi}\label{wybrane-zwiux105zki-pomiux119dzy-zmiennymi-losowymi}

Wieczorkowski \& Zieliński (\citeproc{ref-wieczorkowski1997}{1997, pp.
92--97}) podają kilkadziesiąt związków pomiędzy zmiennymi losowymi, z
których poniżej podajemy jedynie kilka wybranych, jako przykłady funkcji
zmiennych losowych, które znajdują szerokie zastosowania praktyczne.

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Rozkład normalny i rozkład chi-kwadrat}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

Jeżeli \(X_1,X_2, \ldots, X_k\) są zmiennymi losowymi o rozkładzie
normalnym standardowym, to zmienna losowa \(Y=\sum_{i=1}^kX_i^2\) ma
rozkład chi-kwadrat o \(k\) stopniach swobody.

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Rozkład normalny, rozkład chi-kwadrat i rozkład \emph{t} Studenta}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

Jeżeli \(X\) ma rozkład normalny standardowy, a \(Y\) ma rozklad
chi-kwadrat o \(k\) stopniach swobody, to zmienna losowa
\(t=\frac{X}{\sqrt\frac{Y}{k}}\) ma rozkład t Studenta o \(k\) stopniach
swobody.

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Rozkład chi-kwadrat i rozkład \emph{F}}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

Jeżeli \(X,Y\) są zmiennymi losowymi o rozkładzie chi-kwadrat
odpowiednio o \(m\) i \(n\) stopniach swobody, to zmienna losowa
\(F=\frac{X}{Y}\) ma rozkład F o \(m\) i \(n\) stopniach swobody.

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Rozkład beta i rozkład beta}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

Jeżeli zmienna losowa \(X\) ma rozkład beta z parametrami \(s_1\) oraz
\(s_2\), to zmienna losowa \(Y = 1-X\) ma rozkład beta z parametrami
\(s_2\) oraz \(s_1\).

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Rozkład normalny i rozkład logarytmiczno-normalny}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

Jeżeli zmienna losowa \(X\) ma rozkład normalny z parametrami \(\mu\)
oraz \(\sigma\), to zmienna losowa \(Y = e^X\) ma rozkład
logarytmiczno-normalny z parametrami \(\mu\) oraz \(\sigma\).

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Rozkład normalny i rozkład Cauchy'ego}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

Iloraz dwóch zmiennych losowych o rozkładach normalnych standardowych ma
rozkład Cauchy'ego \(C(0,1)\)

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Rozkład Cauchy'go i rozkład Cauchy'ego}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, colback=white]

Jeżeli zmienna losowa \(X\) ma rozkład Cauchy'ego \(C(0,1)\), to zmienna
losowa \(\frac{1}{X}\) ma rozkład Cauchy'ego \(C(0,1)\)

\end{tcolorbox}

\section{Funkcja tworząca zmiennej
losowej}\label{funkcja-tworzux105ca-zmiennej-losowej}

Funkcje tworzące momenty (\emph{MGF - Moment Generating Functions}) są
narzędziami używanymi w teorii prawdopodobieństwa i statystyce do
analizy rozkładów zmiennych losowych. Pozwalają na łatwe obliczanie
momentów, analizę rozkładów oraz przekształcenia zmiennych losowych. Po
wprowadzeniu podstawowych określeń i wniosków zostanie pokazana
możliwość wyznaczania momentów zwykłych zmiennej losowej o rozkładzie
normalnym i rozkładzie wykładniczym. Przykłady dotyczace funkcji
tworzących przedstawiają np. Jakubowski \& Sztencel
(\citeproc{ref-jakubowski2004}{2004}) {[}330-335{]} i Bratijczuk \&
Chydziński (\citeproc{ref-bratijczuk2000}{2000, pp. 243--247}).

\textbf{Definicja}

Niech będzie dana zmienna losowa \(X: \Omega \to \mathbb{R}\). Funkcją
tworzacą momenty zmiennej losowej \(X\) określa się funkcję
\(M_X: \mathbb{R} \to \mathbb{R}\) zadaną następująco:

\begin{equation}\phantomsection\label{eq-fun_tw}{ M_X(t) = E(e^{tX})}\end{equation}

Dla zmiennej losowej skokowej wzór \ref{eq-fun_tw} przyjmuje postać:

\begin{equation}\phantomsection\label{eq-fun_tw_sk}{M_X(t)  = \sum_i e^{tx_i}p_i}\end{equation}

Dla zmiennej losowej ciagłej wzór \ref{eq-fun_tw} przyjmuje postać:

\begin{equation}\phantomsection\label{eq-fun_cg}{M_X(t)  = \int_{-\infty}^{\infty}e^{tx}f(x) dx}\end{equation}

Funkcja tworząca momenty zmiennej losowej jednoznacznie określa zmienną
losową (\citeproc{ref-jakubowski2004}{Jakubowski \& Sztencel, 2004, p.
{[}331{]}}). Podstawowe własności funkcji tworzącej momenty zmiennej
losowej są następujące:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(M_{cX}(t)= M_X(ct)\)
\item
  \(M_{aX+b}(t)= e^{bt}M_X(at)\)
\item
  \(M_{\sum_{i=1}^{n} X_i} (t)= \prod_{i=1}^{n} M_{X_i}(t)\)
\item
  \(\left. \frac{d^k M_X(t)}{dt^k} \right|_{t=0} = m_k\)
\end{enumerate}

Ostatnia z własności wyjaśnia określenie ``funkcja tworząca (momenty)''.
W oparciu o tę wwłasność można wyznaczyć momenty zwykłe dla danej
zmiennej losowej. W tym celu wystarczy obliczyć \(k\)-tą pochodną
funkcji \(M_X(t)\), a następnie jej wartość dla \(t=0\).

\subsection{Funkcja tworząca i momenty zwykłe zmiennej losowej o
rozkładzie normalnym
standardowym}\label{funkcja-tworzux105ca-i-momenty-zwykux142e-zmiennej-losowej-o-rozkux142adzie-normalnym-standardowym}

Niech \(Z\) będzie zmienną losową o rozkładzie normalnym standardowym.
Gęstość tej zmiennej losowej ma postać:

\[f(x)= \frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}, \text{ dla } x \in (-\infty, \infty)\]

Wówczas zgodnie z \ref{eq-fun_tw_nor} jej funkcja tworząca ma
następującą postać:

\[M_Z(t) = \int_{-\infty}^{\infty}\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}e^{tx}dx=\int_{-\infty}^{\infty}\frac{1}{\sqrt{2\pi}}e^{tx-\frac{x^2}{2}}dx=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}e^{tx-\frac{x^2}{2}}dx=\]

\[=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}e^{-(\frac{x}{\sqrt{2}}-\frac{t}{\sqrt{2}})^2+\frac{t^2}{2}}dx=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty} e^{-(\frac{x}{\sqrt{2}}-\frac{t}{\sqrt{2}})^2 } e^{\frac{t^2}{2}}dx=\]

\[=\frac{1}{\sqrt{2\pi}} e^{\frac{t^2}{2}} \int_{-\infty}^{\infty} e^{-(\frac{x}{\sqrt{2}}-\frac{t}{\sqrt{2}})^2 } dx=\frac{1}{\sqrt{2\pi}} e^{\frac{t^2}{2}} \sqrt{2\pi}= e^\frac{t^2}{2} \]

Wobec tego otrzymujemy, że funkcja tworząca zmiennej losowej \(Z\) o
rozkładzie normalnym standardowym ma postać:

\begin{equation}\phantomsection\label{eq-fun_tw_nor_s}{M_Z(t) = e^\frac{t^2}{2}}\end{equation}

Wyznaczając pierwszą pochodną funkcji \(M_Z(t)\) otrzymuje się:

\[ \frac{dM_Z(t)}{dt} = (e^\frac{t^2}{2})_t^{'}=e^\frac{t^2}{2}t\]

Podstawiając wartość w tym wyniku \(t = 0\) otrzymuje się wzór na
pierwszy moment zwykły (wartość oczekiwana) zmiennej losowej o
rozkładzie normalnym standardowym:

\[
m_1 = EZ = \left.\frac{dM_Z(t)}{dt}\right|_{t=0} = e^{\frac{0^2}{2}} \cdot 0 = 0
\]

Dla wyznaczenia drugiego momentu zwykłego należy wyznaczyć drugą
pochodną i następnie obliczyć jej wartość dla \(t = 0\).

\[ \frac{d^2M_Z(t)}{dt^2} = \left( e^\frac{t^2}{2} \right)_t^{''}= \left( e^\frac{t^2}{2}t \right) _t^{'}=e^\frac{t^2}{2}t\cdot t+e^\frac{t^2}{2}1 = e^\frac{t^2}{2} (t^2+1)\]

\[
m_2 = EZ^2 = \left.\frac{d^2 M_Z(t)}{dt^2}\right|_{t=0} = e^{\frac{0^2}{2}} (0^2 + 1) = 1
\]

Przeprowadzając podobne obliczenia uzyskuje się kolejne momenty zwykłe
zmiennej losowej \(Z\) o rozkładzie normalnym standardowym:

\begin{itemize}
\tightlist
\item
  momenty zwykłe rzędów nieparzystych:
\end{itemize}

\(m_1 = EZ=0\)

\(m_3 = EZ^3=0\)

\(m_5 = EZ^5=0\)

\(\ldots\)

\(m_{2k+1} = 0\), dla \(k = 1, 2, \ldots\).

\begin{itemize}
\tightlist
\item
  momenty zwykłe rzędów parzystych:
\end{itemize}

\(m_2 = 1\)

\(m_4 = EZ^4=1\cdot 3\)

\(m_6 = EZ^6=1\cdot 3 \cdot 5\)

\(\ldots\)

\(m_{2k} = EZ^{2k}=1\cdot 3 \ldots (2k-1)=(2k-1)!!\), dla
\(k = 1, 2, \ldots\).

\subsection{\texorpdfstring{Funkcja tworząca zmiennej losowej o
rozkładzie normalnym z parametrami \(\mu\) i
\(\sigma^2\)}{Funkcja tworząca zmiennej losowej o rozkładzie normalnym z parametrami \textbackslash mu i \textbackslash sigma\^{}2}}\label{funkcja-tworzux105ca-zmiennej-losowej-o-rozkux142adzie-normalnym-z-parametrami-mu-i-sigma2}

Jeżeli zmienna losowa \(X \sim N(\mu,\sigma^2)\), to zmienną losową
\(X\) można przedstawić następująco \(X = \sigma Z + \mu\),

gdzie \(Z \sim N(0,1)\).

Biorąc pod uwagę własność (2) funkcji tworzących przedstawione w tym
punkcie oraz wzór na funkcję tworzącą zmiennej losowej o rozkładzie
normalnym standardowym \ref{eq-fun_tw_nor_s}.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \(M_{aX+b}(t)= e^{bt}M_X(at)\)
\end{enumerate}

Funkcja tworząca zmiennej losowej \(X\) ma astępująca postać:

\(M_X(t)=e^{\mu t} M_Z(\sigma t) = e^{\mu t} e^{\frac{\mu^2 t^2}{2}} = e^{\mu t +\frac{1}{2} \mu^2 t^2}\)

\subsection{\texorpdfstring{Funkcja tworząca średniej arytmetycznej
zmiennych losowych
\(X_1, X_2, \ldots, X_n\)}{Funkcja tworząca średniej arytmetycznej zmiennych losowych X\_1, X\_2, \textbackslash ldots, X\_n}}\label{funkcja-tworzux105ca-ux15bredniej-arytmetycznej-zmiennych-losowych-x_1-x_2-ldots-x_n}

Niech \(X_i {\text \ dla \ i = 1, 2,\ldots n}\) będą niezależnymi
zmiennymi losowymi o rozkładzie normalnym z parametrami \(\mu\) oraz
\(\sigma^2\). Wyznaczyć funkcję tworzącą zmiennej losowej
\(Y = \sum_{i=1}^n a_iX_i\)

Funkcja tworząca zmiennej losowej \(Y\) ma postać:

\begin{equation}\phantomsection\label{eq-fun_tw_nor}{M_Y(t) = M_{\sum_{i=1}^n a_iX_i}(t)=\prod_{i=1}^n M_{a_iX_i} (t) = e^{\mu t \sum_{i=1}^n a_i+\frac{1}{2}\sigma^2t^2\sum_{i=1}^n a_i^2 }}\end{equation}

\textbf{Wniosek}

Funkcja tworząca zmiennej losowej \(Y\) jest funkcją tworzącą zmiennej
losowej o rozkładzie normalnym z parametrami
\(\mu_Y=\mu \sum_{i=1}^{n} a_i\) oraz
\(\sigma_Y=\sigma \sqrt{\sum_{i=1}^na_i^2}.\)

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{Wniosek}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-important-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-important-color-frame, colback=white]

Funkcja tworząca zmiennej losowej \(Y\) jest funkcją tworzącą zmiennej
losowej o rozkładzie normalnym z parametrami
\(\mu_Y=\mu \sum_{i=1}^{n} a_i\) oraz
\(\sigma_Y=\sigma \sqrt{\sum_{i=1}^na_i^2}.\)

\end{tcolorbox}

\textbf{Wniosek}

Jeśli \(\overline{X}=\frac{1}{n}\sum_{i=1}^{n}X_i\), gdzie
\(X_i \sim N(\mu,\sigma^2)\), dla \(i = 1, 2, \ldots, n\), to
\(\overline{X} \sim N(\mu,\frac{\sigma^2}{n}).\)

\begin{tcolorbox}[enhanced jigsaw, toprule=.15mm, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{Wniosek}, breakable, coltitle=black, titlerule=0mm, colbacktitle=quarto-callout-important-color!10!white, opacitybacktitle=0.6, opacityback=0, bottomtitle=1mm, left=2mm, arc=.35mm, leftrule=.75mm, bottomrule=.15mm, rightrule=.15mm, toptitle=1mm, colframe=quarto-callout-important-color-frame, colback=white]

Jeśli \(\overline{X}=\frac{1}{n}\sum_{i=1}^{n}X_i\), gdzie
\(X_i \sim N(\mu,\sigma^2)\), dla \(i = 1, 2, \ldots, n\), to
\(\overline{X} \sim N(\mu,\frac{\sigma^2}{n}).\)

\end{tcolorbox}

Dla uzasadnienia powyższego wystarczy w poprzednim wniosku przyjąć
\(a_i=\frac{1}{n}\), dla \(i = 1, 2, \ldots, n.\) Powyższy wniosek ma
bardzo duże znaczenie w zagadnieniach wnioskowania statystycznego.

\subsection{\texorpdfstring{Momenty zmiennej losowej \(X\) o rozkładzie
wykładniczym z parametrem
\(\lambda\).}{Momenty zmiennej losowej X o rozkładzie wykładniczym z parametrem \textbackslash lambda.}}\label{momenty-zmiennej-losowej-x-o-rozkux142adzie-wykux142adniczym-z-parametrem-lambda.}

Z wykorzystaniem funkcji tworzących momenty można wyznaczyć momenty
zwykłe rzędu \(k\) zmiennej losowej o rozkładzie wykładniczym z
parametrem \(\lambda\). Gęstość zmiennej losowej ma postać (por
\ref{eq-ges_exp})

\[
f(x) = \begin{cases} 
\lambda e^{-\lambda x} & \text{dla } x \ge 0 \\
0 & \text{dla } x <0 
\end{cases}
\]

Funkcja tworząca przyjmuje postać:

\[M_X(t) = E(e^{tX})=\int_{-\infty}^{\infty}e^{tx}f(x)dx=\int_0^{\infty}e^{tx}f(x)dx=\lambda \int_0^{\infty}e^{tx-\lambda x}dx = \lambda \int_0^{\infty}e^{(t-\lambda)} xdx=\]

\[=\frac{ \lambda}{\lambda-t}= \sum_{k=0}^{\infty} \frac{t^k}{\lambda ^k}\]

Wobec powyższego otrzymuje się wzór na moment zwykły rzędu \(k\):

\(EX^k=\left.\sum_{k=0}^{\infty} \frac{t^k}{\lambda^k} \right|_{t=0}^{(k)} = \frac{k!}{\lambda^k}\),
dla \(k = 1, 2, \ldots\).

W związku z powyższym otrzymuje się kolejne momenty zwykłe zmiennej
losowej \(X\) o rozkładzie wykładniczym z parametrem \(\lambda\):

\(m_1 = EX =  \frac{1}{\lambda}\)

\(m_2 = EX^2 =  \frac{2}{\lambda^2}\)

\(m_3 = EX^3 =  \frac{6}{\lambda^3}\)

Ogólnie, moment zwykły rzędu \(k\) zmiennej losowej o rozkładzie
wykładniczym z parametrem \(\lambda\) ma postać

\(m_k = EX^k =  \frac{k!}{\lambda^k}\), dla \(k = 1, 2, \ldots\).

\section{Funkcja charakterystyczna zmiennej
losowej}\label{funkcja-charakterystyczna-zmiennej-losowej}

Funkcja charakterystyczna zmiennej losowej jest narzędziem matematycznym
używanym w teorii prawdopodobieństwa i statystyce do opisania rozkładu
prawdopodobieństwa tej zmiennej. Dzięki zastosowaniu tych narzędzi
dowodzi się twierdzeń o rozkładach sumy zmiennych losowych, o postaci
transformacji zmiennych losowych i uzyskuje się oszacowania parametrów.
Po wprowadzeniu podstawowych określeń i własności zostanie pokazany
rozkład średniej z próby prostej.

Funkcje charakterystyczne zmiennych losowych są szeroko opisywane w
literaturze. Przykłady ich zastosowań przedstawiają np.: Jakubowski \&
Sztencel (\citeproc{ref-jakubowski2004}{2004}) {[}190-196{]}, Krzyśko
(\citeproc{ref-krzysko2000}{2000, pp. 213--231}), Krysicki
(\citeproc{ref-krysicki2003}{2003}) {[}146-153{]}, Hellwig
(\citeproc{ref-hellwig1998}{1998, pp. 118--124}) i Bratijczuk \&
Chydziński (\citeproc{ref-bratijczuk2000}{2000, pp. 237--242}).

\textbf{Definicja}

Funkcją charakterystyczną zmiennej losowej \(X: \Omega \to \mathbb{R}\)
określa się funkcję \(\varphi_X(t): \mathbb{R} \to \mathbb{C}\)

zadaną następująco (por. Krzyśko (\citeproc{ref-krzysko2000}{2000}),
Jakubowski \& Sztencel (\citeproc{ref-jakubowski2004}{2004})):

\begin{equation}\phantomsection\label{eq-fun_ch}{ \varphi_X(t) = E(e^{itX})}\end{equation}

Dla zmiennej skokowej wzór \ref{eq-fun_ch} przyjmuje postać:

\[\varphi_X(t) = \sum_ie^{itx_i}p_i\]

Dla zmiennej ciagłej wzór \ref{eq-fun_ch} przyjmuje postać:

\[\varphi_X(t) = \int_{-\infty}^{\infty}e^{itx}f(x)dx\]

Funkcja charakterystyczna istnieje dla każej zmiennej losowej \(X\) i
określa tę zmienną jednoznacznie, czyli dwie zmienne losowe mają
identyczne rozkłady wtedy i tylko wtedy, gdy ich funkcje
charakterystyczne są identyczne.

Własności funkcji charakterystycznych
(\citeproc{ref-jakubowski2004}{Jakubowski \& Sztencel, 2004};
\citeproc{ref-krysicki2003}{Krysicki, 2003};
\citeproc{ref-krzysko2000}{Krzyśko, 2000, p. {[}214{]}}):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(\varphi_X(0) = 1\)
\item
  \(|\varphi_X(t)| \le 1\), dla wszystkich \(t \in \mathbb{R}\)
\item
  \(\varphi_X(t) = \overline{\varphi_X(-t)}\)
\item
  \(\varphi_{aX}(t) = \varphi_X(at)\)
\item
  Jeżeli \(E|X^n| < \infty\), to \(\varphi_{X}^{(n)}(0) = i^nEX^n\)
\item
  Jeżeli \(X\) i \(Y\) są niezależnymi zmiennymi losowymi, to
  \(\varphi_{X+Y}(t) =\varphi_X(t)\varphi_Y(t)\)
\item
  Jeżeli \(Y=aX+b\), gdzie \(a\) i \(b\) są stałymi, to
  \(\varphi_{Y}(t) =e^{itb}\varphi_X(at)\)
\item
  \(\varphi\) jest funkcją rzeczywistą wtedy i tylko wtedy, gdy rozkład
  zmiennej losowej X jest symetryczny względem \(x = 0\).
\end{enumerate}

\subsection{Funkcja charakterystyczna zmiennej losowej o rozkładzie
normalnym
standardowym}\label{funkcja-charakterystyczna-zmiennej-losowej-o-rozkux142adzie-normalnym-standardowym}

Funkcja charakterystyczna zmiennej losowej \(Z\) o rozkładzie normalnym
standardowym \(N(0,1)\) zgodnie z \ref{eq-fun_ch} jest definiowana jako:

\[\varphi_Z(t) = E\left[e^{itZ}\right]\]

Dla zmiennej losowej \(Z\) o rozkładzie normalnym standardowym
\(N(0,1)\), jej gęstość prawdopodobieństwa zgodnie z
\ref{eq-gest_nor_st} jest dana następująco:

\[f_Z(x) = \frac{1}{\sqrt{2\pi}} e^{-\frac{x^2}{2}}\]

Dla wyprowadzenia wzoru na funkcję charakterystyczną zmiennej losowej
\(Z\), należy obliczyć wartość oczekiwaną zmiennej losowej \(e^{itZ}\):

\[\varphi_Z(t) = \int_{-\infty}^{\infty} e^{itx} f_Z(x) \, dx = \int_{-\infty}^{\infty} e^{itx} \frac{1}{\sqrt{2\pi}} e^{-\frac{x^2}{2}} \, dx = \frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}   e^{itx-\frac{x^2}{2}} \, dx\]

Wyrażenie w wykładniku potęgi można zapisać następująco:

\[ itx-\frac{x^2}{2}  = -\frac{1}{2}\left(x^2 - 2itx\right) = -\frac{1}{2}\left(x^2 - 2itx - t^2 + t^2\right) = -\frac{1}{2}\left((x - it)^2 + t^2\right)\]

Podstawiając to wyrażenie z powrotem do całki otrzymujemy:

\[
\varphi_Z(t) = \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{\infty} e^{-\frac{1}{2}\left((x - it)^2 + t^2\right)} \, dx = \frac{1}{\sqrt{2\pi}} e^{-\frac{t^2}{2}} \int_{-\infty}^{\infty} e^{-\frac{(x - it)^2}{2}} \, dx = 
e^{-\frac{t^2}{2}} \left( \frac{1}{\sqrt{2\pi}}  \int_{-\infty}^{\infty} e^{-\frac{(x - it)^2}{2}} \right) \, dx
\]

Wyrażenie w ostatnim nawiasie jest równe 1, ponieważ jest to całka
gęstości rozkładu normalnego. Ostatecznie otrzymuje się wzór na funkcję
charakterystyczną zmiennej losowej \(Z\) o rozkładzie normalnym
standardowym:

\begin{equation}\phantomsection\label{eq-fun_char_nor_s}{\varphi_Z(t) = e^{-\frac{t^2}{2}}}\end{equation}

\subsection{\texorpdfstring{Funkcja charakterystyczna zmiennej losowej
\(X\) o rozkładzie normalnym z parametrami \(\mu\) i
\(\sigma^2\)}{Funkcja charakterystyczna zmiennej losowej X o rozkładzie normalnym z parametrami \textbackslash mu i \textbackslash sigma\^{}2}}\label{funkcja-charakterystyczna-zmiennej-losowej-x-o-rozkux142adzie-normalnym-z-parametrami-mu-i-sigma2}

Niech \[Z \sim N(0,1)\]

Wówczas zmienna losowa \(X=Z\sigma+\mu\) ma rozkład
\(X \sim N( \mu,\sigma^2)\)

Wobec własności (4) funkcji charakterystycznych przedstawionych w tym
punkcie otrzymuje się

\[ \varphi_X(t)= E(e^{itX}) =E(e^{it(Z\sigma+\mu)}) = E(e^{it\mu} e^{it\sigma Z})=e^{it\mu}E( e^{it\sigma Z})=\]

\[=e^{it\mu} \varphi_Z(t\sigma)= e^{it\mu} e^{-\frac{t^2\sigma^2}{2}}\]

Wobec powyższego, funkcja charakterystyczna zmiennej losowej o
rozkładzie normalnym \(X \sim N(\mu,\sigma^2)\) ma postać:

\[ \varphi_X(t)=e^{it\mu-\frac{t^2\sigma^2}{2}} \]

\subsection{Rozkład średniej zmiennych losowych o identycznych,
niezależnych rozkładach
normalnych}\label{rozkux142ad-ux15bredniej-zmiennych-losowych-o-identycznych-niezaleux17cnych-rozkux142adach-normalnych}

Niech \(X_i, \text{ dla } i = 1, 2, \ldots n\) będą niezależnymi
zmiennymi losowymi o identycznych rozkładach normalnych z parametrami
\(\mu\) i \(\sigma^2\), czyli

\[X_i: N(\mu, \sigma^2), \text{ dla } i = 1, 2, \ldots n\].

Wyznaczyć funkcję charakterystyczną zmiennej losowej \(X\)

\[ \bar{X}=\frac{1}{n}\sum_{i=1}^nX_i\]

Ponieważ zmienna losowa \(X_i\) ma rozkład normalny z parametrami
\(\mu\) i \(\sigma\), to jej funkcja charakterystyczna ma postać:

\[\varphi_{X_i}(t)  = e^{mt-\frac{\sigma^2t^2}{2}}, \text{ dla } i = 1, 2, \ldots n\].

Na tej podstawie wyznacza się funkcję charakterystyczną zmiennej losowej
\(\bar{X}\):

\[\varphi_\bar{X}(t)  = \prod_{i=1}^ne^{\frac{1}{n}mt-\frac{\sigma^2t^2\frac{1}{n^2}}{2}}= e^{\sum_{i=1}^n{\frac{1}{n}mt-\frac{\sigma^2t^2\frac{1}{n^2}}{2}}}=e^{{tm}-\frac{\sigma^2t^2}{2n}}\].

Ostatnia postać, to funkcja charakterystyczna zmiennej losowej o
rozkladzie normalnym z parametrami \(\mu\) oraz \(\frac{\sigma^2}{n}\).
Wniosek ten można zapisać następująco:

\[\overline{X}: N\left(\mu,\frac{\sigma^2}{n} \right)\].

\section{Nierówność Czebyszewa}\label{nieruxf3wnoux15bux107-czebyszewa}

Nierówność Czebyszewa jest fundamentalnym narzędziem w teorii
prawdopodobieństwa, które pozwala oszacować prawdopodobieństwo, że
wartość zmiennej losowej odchyla się od jej wartości oczekiwanej o
więcej niż pewna ustalona liczba odchyleń standardowych. Formalnie,
nierówność Czebyszewa można zapisać w następujący sposób:

Niech \((\Omega,\mathcal{F},P)\) będzie przestrzenią probabilistyczną, a
\(X\) będzie nieujemną zmienną losową. Wówczas dla dowolnego
\(\varepsilon > 0\) prawdziwa jest nierówność:

\begin{equation}\phantomsection\label{eq-Czeb}{ P(X \ge \varepsilon) \le \frac{EX}{\varepsilon}}\end{equation}

\textbf{Dowód}

\begin{itemize}
\tightlist
\item
  zmienna losowa skokowa:
\end{itemize}

\[ P(X \ge \varepsilon) = \sum_{i:x_i \ge  \varepsilon} P(X=x_i) \le \sum_{i:x_i \ge  \varepsilon} \frac{x_i}{\varepsilon}P(X=x_i) = \frac{1}{\varepsilon}  \sum_{i:x_i \ge  \varepsilon} x_i P(X=x_i)  \le \frac{1}{\varepsilon}  \sum_i x_i P(X=x_i) = \frac{EX}{\varepsilon}\]

\begin{itemize}
\tightlist
\item
  zmienna losowa ciągła:
\end{itemize}

\[ P(X \ge \varepsilon) = \int_{\varepsilon}^{\infty} f(x) dx \le  \int_{\varepsilon}^{\infty} \frac{x}{\varepsilon} f(x) dx =         \frac{1}{\varepsilon}  \int_{\varepsilon}^{\infty} x f(x) dx  \le \frac{1}{\varepsilon}  \int_{-\infty}^{\infty} x f(x) dx     = \frac{EX}{\varepsilon}\]

Poniżej przedstawiamy wybrane uogólnienia nierównosci Czebyszewa wraz z
uzasadnieniami (por. Jakubowski \& Sztencel
(\citeproc{ref-jakubowski2004}{2004, pp. 92--93}))

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Jeżeli \(X \ge 0\) - zmienna losowa, \(k\) - liczba naturalna,
  \(\varepsilon>0\), to
\end{enumerate}

\begin{equation}\phantomsection\label{eq-Czeb_1}{ P(X \ge \varepsilon) \le \frac{EX^k}{\varepsilon^k}}\end{equation}

\textbf{Uzasadnienie}

\begin{itemize}
\tightlist
\item
  zmienna losowa skokowa
\end{itemize}

\[EX^k= \sum_i x_i^kp_i \ge \sum_{i:x_i \ge\varepsilon} x_i^kp_i \ge  \sum_{i:x_i \ge \varepsilon} \varepsilon^kp_i =  \varepsilon^k \sum_{i:x_i \ge \varepsilon} p_i   = \varepsilon^k P(X \ge \varepsilon)\]

\begin{itemize}
\tightlist
\item
  zmienna losowa ciagła
\end{itemize}

\[EX^k= \int_{-\infty}^{\infty}x^kf(x)dx \ge \int_{\varepsilon}^{\infty}x^kf(x)dx \ge \int_{\varepsilon}^{\infty} \varepsilon^kf(x)dx = \varepsilon^k \int_{\varepsilon}^{\infty}f(x)dx = \varepsilon^k P(X \ge \varepsilon)\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Jeżeli \(X \ge 0\) - zmienna losowa, \(k\) - liczba naturalna,
  \(\varepsilon >0\), to
\end{enumerate}

\begin{equation}\phantomsection\label{eq-Czeb_2}{ P(|X-EX| \ge \varepsilon) \le \frac{D^2X}{\varepsilon^2}}\end{equation}

\textbf{Uzasadnienie}

We wzorze \ref{eq-Czeb_1} w miejsce \(X\) podstawić \(|X-EX|\) i przyjąć
\(k = 2\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Jeżeli \(X \ge 0\) - zmienna losowa \(k\) - liczba naturalna
  \(\varepsilon > 0\), to
\end{enumerate}

\begin{equation}\phantomsection\label{eq-Czeb_3}{ P(|X-EX| \ge cDX) \le \frac{1}{c^2}}\end{equation}

\textbf{Uzasadnienie}

We wzorze \ref{eq-Czeb_2} przyjąć \(\varepsilon = cDX\).

\textbf{Wnioski}

Na podstawie \ref{eq-Czeb_3} otrzymuje się, że dla dowolnej zmiennej
losowej o wartości oczekiwanej \(\mu\) i odchyleniu standardowym
\(\sigma\) zawsze spełnione są następujące warunki:

\[ P(\mu-2\sigma < X <  \mu+2\sigma) \ge \frac{3}{4}\]

\[ P(\mu-3\sigma < X <  \mu+3\sigma) \ge \frac{8}{9}\]

\[ P(\mu-5\sigma < X <  \mu+5\sigma) \ge \frac{24}{25}\]

\section{Wybrane twierdzenia
graniczne}\label{wybrane-twierdzenia-graniczne}

Twierdzenia graniczne są fundamentalnymi wynikami w teorii
prawdopodobieństwa i statystyce, które opisują zachowanie sum dużej
liczby zmiennych losowych. Głównym celem tych twierdzeń jest określenie,
jak rozkład sumy (lub średniej) zmiennych losowych staje się coraz
bardziej przewidywalny w miarę zwiększania liczby zmiennych. Najbardziej
znane z tych twierdzeń to centralne twierdzenie graniczne, twierdzenie
Moivre'a-Laplace'a oraz prawa wielkich liczb.

\subsection{Centralne twierdzenie
graniczne}\label{centralne-twierdzenie-graniczne}

Centralne twierdzenie graniczne (CTG, twierdzenie Lindenberga-Levy'ego)
jest jednym z najważniejszych twierdzeń w statystyce i teorii
prawdopodobieństwa. Mówi ono o tym, że suma dużej liczby niezależnych
zmiennych losowych o jednakowym rozkładzie zbiega w rozkładzie do
rozkładu normalnego, niezależnie od rozkładu tych zmiennych.

Niech będzie dana zmienna losowa \(X=X_1+X_2+\ldots+X_n\), będąca sumą
\(n\) niezależnych zmiennych losowych o jednakowym rozkładzie ze
skończonymi wartościami oczekiwanymi \(\mu_i\) oraz wariancjami
\(\sigma_i^2 \text{, dla } i=1,2,\ldots,n\). Ponieważ zmienne losowe są
niezależne i mają identyczne rozkłady, to \(\mu_1=\mu_2=\ldots=\mu_n\)
oraz \(\sigma_1=\sigma_2=\ldots=\sigma_n\). Stąd otrzymuje się:

\[\mu=EX=n \mu_1\] \[\sigma^2=D^2X=n\sigma_1^2\]

Oznaczając przez \(S\) sumę standaryzowaną zmiennych losowych
\(X_1, X_2, \ldots, X_n\), tj:

\[S=\frac{X-\mu}{\sigma}=\frac{X-n \mu_1}{\sigma_1 \sqrt{n}}\] dla \(n\)
zmierzającego do nieskończoności spełniony jest warunek
(\citeproc{ref-hellwig1998}{Hellwig, 1998, p. {[}179{]}}):

\begin{equation}\phantomsection\label{eq-ctg1}{\lim_{n \to \infty} P(a < S < b) = \int_a^b f(x)dx}\end{equation}
gdzie \(f(x)\) jest gęstością rozkładu normalnego standardowego.

Warunek można zapisać równoważnie:

\begin{equation}\phantomsection\label{eq-ctg2}{\lim_{n \to \infty} P(a < S < b) = F(b) - F(a)}\end{equation}

gdzie \(F(x)\) jest dystrybuantą rozkładu normalnego standardowego.

Centralne twierdzenie graniczne (CTG) mówi, że suma dużej liczby
niezależnych o identycznych rozkładach zmiennych losowych o skończonej
wariancji zbiega w rozkładzie do rozkładu normalnego.

\subsection{Twierdzenie
Moivre'a-Laplace'a}\label{twierdzenie-moivrea-laplacea}

Twierdzenie de Moivre'a-Laplace'a jest szczególnym przypadkiem
centralnego twierdzenia granicznego i odnosi się do przybliżenia
rozkładu dwumianowego rozkładem normalnym. Jest to jedno z
fundamentalnych twierdzeń w teorii prawdopodobieństwa, które pozwala na
stosowanie rozkładu normalnego do modelowania wyników prób losowych o
dużych liczebnościach.

Niech \(S_n\) oznacza liczbę sukcesów w ciągu \(n\) prób wykonywanych
według schematu Bernoulliego, gdzie prawdopodobieństwo sukcesu w
pojedynczej próbie wynosi \(p\). Wówczas ciąg dystrybuant
(\citeproc{ref-kowgier2011}{Kowgier, 2011, p. {[}258{]}}):

\(F_1\left(\frac{S_1-p}{\sqrt{p(1-p)}}\right), F_2\left(\frac{S_2-p}{\sqrt{2p(1-p)}}\right), \ldots, F_n\left(\frac{S_n-p}{\sqrt{np(1-p)}}\right)\)

jest zbieżny do dystrybuanty rozkładu normalnego standardowego, to
znaczy:

\begin{equation}\phantomsection\label{eq-ML}{\lim_{n \to \infty}F_n(x) = \lim_{n \to \infty} \left( \frac{S_n-np}{\sqrt{np(1-p)}} <x \right) = F(x)}\end{equation}
gdzie \(F(x)\) jest dystrybuantą rozkładu normalnego standardowego.

\subsection{Słabe prawo wielkich
liczb}\label{sux142abe-prawo-wielkich-liczb}

Słabe prawo wielkich liczb jest fundamentalnym twierdzeniem w teorii
prawdopodobieństwa, które mówi o zbieżności średniej arytmetycznej próby
do wartości oczekiwanej populacji. Słabe prawo wielkich liczb, znane
również jako słabe prawo wielkich liczb Bernoulliego, można sformułować
następująco:

Niech \(X_1, X_2, ..., X_n\) będzie ciągiem niezależnych zmiennych
losowych o identycznych rozkładach o skończonej wartości oczekiwanej
\(\mu\). Wtedy dla dowolnego \(\varepsilon > 0\) zachodzi:

\begin{equation}\phantomsection\label{eq-pwl}{\lim_{n \to \infty} P\left( \left|\overline{X}_n-\mu\right| \le \varepsilon \right) =1}\end{equation}
gdzie: \(\overline{X}_n=\frac{X_1+X_2+\ldots +X_n}{n}\).

Oznacza to, że średnia arytmetyczna tych zmiennych losowych
\(\overline{X}_n = \frac{1}{n} \sum_{i=1}^{n} X_i\) zbiega w
prawdopodobieństwie do wartości oczekiwanej \(\mu\) w miarę jak liczba
prób \(n\) dąży do nieskończoności.

Prawo to można zastosować do zmiennych losowych o rozkładach
Bernoulliego (\citeproc{ref-kowgier2011}{Kowgier, 2011, p. {[}254{]}}),
wówczas przyjmuje ono postać:

Jeśli \(S_n\) oznacza liczbę sukcesów w schemacie \(n\) prób
Bernoulliego, z prawdopodobieństwem sukcesu w pojedynczej próbie \(p\),
to dla każdego \(\varepsilon > 0\) zachodzi relacja

\begin{equation}\phantomsection\label{eq-spwl_Ber}{\lim_{n \to \infty} P\left( \left|\frac{S_n}{n}-p\right| \le \varepsilon \right) =1}\end{equation}

Powyższa równość \ref{eq-spwl_Ber} wynika bezpośrednio z nierówności
Czebyszewa (Kowgier (\citeproc{ref-kowgier2011}{2011, p. 254})).
Prawdopodobieństwo, że częstość sukcesów \(\frac{S_n}{n}\) w serii \(n\)
doświadczeń dowolnie mało różni się od prawdopodobieństwa \(p\) zajścia
zdarzenia w pojedynczej próbie. Prawdopodobieństwo zapisane w
\ref{eq-spwl_Ber} jest bliskie 1 dla dostatecznie dużej liczby prób.

\subsection{Mocne prawo wielkich liczb
Bernoulliego}\label{mocne-prawo-wielkich-liczb-bernoulliego}

Mocne prawo wielkich liczb to kolejne z fundamentalnych twierdzeń w
teorii prawdopodobieństwa. Prawo to mówi, że średnia arytmetyczna dużej
liczby niezależnych obserwacji tej samej zmiennej losowej zbiega prawie
na pewno do wartości oczekiwanej tej zmiennej. Pozwala na szacowanie
prawdopodobieństwa zdarzeń na podstawie dużej liczby obserwacji.

Jeśli \(S_n\) oznacza liczbę sukcesów w schemacie \(n\) prób
Bernoulliego, z prawdopodobieństwem sukcesu w pojedynczej próbie \(p\),
to

\begin{equation}\phantomsection\label{eq-mpwl_Ber}{ P\left(\lim_{n \to \infty} \frac{S_n}{n}=p  \right) =1}\end{equation}

Mocne prawo wielkich liczb mówi o zbieżności prawie na pewno, co jest
silniejszym stwierdzeniem niż zbieżność w prawdopodobieństwie. Słabe
prawo wielkich liczb jest mniej rygorystyczne niż mocne prawo wielkich
liczb.

Mocne prawo wielkich liczb Bernoulliego (wzór \ref{eq-mpwl_Ber}) zostało
pierwotnie w nieco innej formie przedstawione w ``\emph{Ars
Conjectandi}'' (1713 rok). Prawo to oznacza, że przy bardzo dużej
liczbie prób \((n \to \infty)\), częstość względna sukcesów
\(\frac{S_n}{n}\) zbiega do rzeczywistego prawdopodobieństwa sukcesu
\(p\) z prawdopodobieństwem 1. Zbieżność ta zachodzi ``prawie na
pewno'', co jest silniejszym stwierdzeniem niż w słabym prawie wielkich
liczb, które mówi jedynie o zbieżności według prawdopodobieństwa. Prawo
to gwarantuje, że przy dostatecznie dużej liczbie powtórzeń
eksperymentu, empiryczna częstość wystąpienia zdarzenia będzie dowolnie
bliska jego teoretycznemu prawdopodobieństwu. Jest to fundamentalne
twierdzenie w teorii prawdopodobieństwa i statystyce, stanowiące
podstawę dla wielu metod wnioskowania statystycznego a w szczególności
dla metod symulacji komputerowej.

\bookmarksetup{startatroot}

\chapter*{Zakończenie}\label{zakoux144czenie}
\addcontentsline{toc}{chapter}{Zakończenie}

\markboth{Zakończenie}{Zakończenie}

Krótkie zakończenie

\bookmarksetup{startatroot}

\chapter*{Odpowiedzi do wybranych
zadań}\label{odpowiedzi-do-wybranych-zadaux144}
\addcontentsline{toc}{chapter}{Odpowiedzi do wybranych zadań}

\markboth{Odpowiedzi do wybranych zadań}{Odpowiedzi do wybranych zadań}

\subsection*{Rozdział 2}\label{rozdziaux142-2}
\addcontentsline{toc}{subsection}{Rozdział 2}

Zadanie 2.1.

Zadanie 2.2.

Zadanie 2.3.

\ldots{}

\subsection*{Rozdział 3}\label{rozdziaux142-3}
\addcontentsline{toc}{subsection}{Rozdział 3}

Zadanie 3.1.

Zadanie 3.2.

Zadanie 3.3.

\ldots{}

\subsection*{Rozdział 4}\label{rozdziaux142-4}
\addcontentsline{toc}{subsection}{Rozdział 4}

Zadanie 4.1.

Zadanie 4.2.

Zadanie 4.3.

\ldots{}

\subsection*{Rozdział 5}\label{rozdziaux142-5}
\addcontentsline{toc}{subsection}{Rozdział 5}

Zadanie 5.1.

Zadanie 5.2.

Zadanie 5.3.

\ldots{}

\subsection*{Rozdział 6}\label{rozdziaux142-6}
\addcontentsline{toc}{subsection}{Rozdział 6}

Zadanie 6.1.

Zadanie 6.2.

Zadanie 6.3.

\ldots{}

\subsection*{Rozdział 7}\label{rozdziaux142-7}
\addcontentsline{toc}{subsection}{Rozdział 7}

Zadanie 7.1.

Zadanie 7.2.

Zadanie 7.3.

\ldots{}

\bookmarksetup{startatroot}

\chapter*{References}\label{references}
\addcontentsline{toc}{chapter}{References}

\markboth{References}{References}

\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-aczel2000}
Aczel, A. D. (2000). \emph{Statystyka w zarz{ą}dzaniu}. Wydawnictwo
Naukowe PWN.

\bibitem[\citeproctext]{ref-bernstein1998}
Bernstein, P. L. (1998). \emph{Against the gods: the remarkable story of
risk} (Nachdr). Wiley.

\bibitem[\citeproctext]{ref-bernstein1997}
Bernstein, P. L., Baszniak, T., \& Borzęcki, P. (1997). \emph{Przeciw
bogom: niewyk{ł}e dzieje ryzyka}. WIG-Press.

\bibitem[\citeproctext]{ref-bertsekas2008}
Bertsekas, D. P., \& Tsitsiklis, J. N. (2008). \emph{Introduction to
probability} (2nd ed). Athena scientific.

\bibitem[\citeproctext]{ref-biblia2002}
\emph{Biblia Tysiąclecia}. (2002). Wydawnictwo Pallotinum.

\bibitem[\citeproctext]{ref-billingsley1995}
Billingsley, P. (1995). \emph{Probability and measure} (3rd ed). Wiley.

\bibitem[\citeproctext]{ref-bratijczuk2000}
Bratijczuk, M., \& Chydziński, A. (2000). \emph{Rachunek
prawdopodobie{ń}stwa}. Wydawnictwo Politechniki {Ś}l{ą}skiej.

\bibitem[\citeproctext]{ref-capinski2001}
Capiński, M., \& Zastawniak, T. (2001). \emph{Probability through
problems}. Springer.

\bibitem[\citeproctext]{ref-covington2020}
Covington, D. (2020). \emph{Probability}. LULU COM.

\bibitem[\citeproctext]{ref-cwiek2018}
Ćwiek, M., Podolec, B., Ulman, P., \& Walega, A. (2018).
\emph{Statystyka z elementami statystycznych metod sterowania
jako{ś}ci{ą}}. Wydawnictwo Akademii Ekonomicznej.

\bibitem[\citeproctext]{ref-czaplicki2011}
Czaplicki, J. M. (2011). \emph{Elementy statystyki matematycznej i ich
zastosowania w in{ż}ynierii górniczej i robót ziemnych}. Wydawnictwo
Politechniki {Ś}l{ą}skiej.

\bibitem[\citeproctext]{ref-feller1971}
Feller, W. (1971). \emph{An introduction to probability theory and its
applications. 2} (2. ed). Wiley.

\bibitem[\citeproctext]{ref-ganczarek-gamrot2013}
Ganczarek-Gamrot, A. (2013). \emph{Metody stochastyczne w badaniach
porównawczych wybranych rynków energii elektrycznej}. Wydawnictwo
Uniwersytetu Ekonomicznego.

\bibitem[\citeproctext]{ref-good1959}
Good, I. J. (1959). Kinds of Probability: Although there are at least
five kinds of probability, we can get along with just one kind.
\emph{Science}, \emph{129}(3347), 443--447.
\url{https://doi.org/10.1126/science.129.3347.443}

\bibitem[\citeproctext]{ref-hellwig1995}
Hellwig, Z. (1995). \emph{Elementy rachunku prawdopodobie{ń}stwa i
statystyki matematycznej} (Wyd. 12). Wydawnictwo Naukowe PWN.

\bibitem[\citeproctext]{ref-hellwig1998}
Hellwig, Z. (1998). \emph{Elementy rachunku prawdopodobie{ń}stwa i
statystyki matematycznej}. Wydawnictwo Naukowe PWN.

\bibitem[\citeproctext]{ref-iwasiewicz2000}
Iwasiewicz, A., \& Paszek, Z. (2000). \emph{Statystyka z elementami
statystycznych metod sterowania jako{ś}ci{ą}} (Wyd. 3 popr. i uzup).
Wydawnictwo Akademii Ekonomicznej.

\bibitem[\citeproctext]{ref-jakubowski2004}
Jakubowski, J., \& Sztencel, R. (2004). \emph{Wst{ę}p do teorii
prawdopodobie{ń}stwa} (Wyd. 3). Script.

\bibitem[\citeproctext]{ref-jasiulewicz2010}
Jasiulewicz, H., \& Kordecki, W. (2010). \emph{Rachunek
prawdopodobie{ń}stwa i statystyka matematyczna: przyk{ł}ady i zadania}
(Wyd. 3 popr., {[}dodr.{]}). Oficyna Wydawnicza GiS.

\bibitem[\citeproctext]{ref-jedrzejczak2020}
Jędrzejczak, A., \& Pekasiewicz, D. (2020). \emph{Teoretyczne rozkłady
dochodów gospodarstw domowych i ich estymacja}. Wydawnictwo Uniwersytetu
{Ł}ódzkiego.

\bibitem[\citeproctext]{ref-kaluszka1999}
Kałuszka, M. (1999). \emph{Rachunek prawdopodobie{ń}stwa i statystyka
dla licealistów} (Wyd. 2 zm). Wydawnictwa Naukowo-Techniczne.

\bibitem[\citeproctext]{ref-kinney2015}
Kinney, J. J. (2015). \emph{Probability: An introduction with
statistical applications} (Second edition). Wiley.

\bibitem[\citeproctext]{ref-konczak2000}
Kończak, G. (2000). \emph{Wykorzystanie kart kontrolnych w sterowaniu
jako{ś}ci{ą} w toku produkcji}. Wydawnictwo Akademii Ekonomicznej im.
Karola Adamieckiego.

\bibitem[\citeproctext]{ref-konczak2012}
Kończak, G. (2012). \emph{Wstęp do symulacji komputerowych}. Wydawnictwo
Uniwersytetu Ekonomicznego w Katowicach.

\bibitem[\citeproctext]{ref-konczak2014}
Kończak, G. (2014). Rola graficznych prezentacji danych w popularyzacji
statystyki. \emph{Wiadomo{ś}ci Statystyczne}, \emph{LIX}(7), 49--61.

\bibitem[\citeproctext]{ref-konczak2016}
Kończak, G. (2016). Teoretyczne podstawy zastosowania testów
permutacyjnych. \emph{Prace Komisji Naukowych}, \emph{39-40}, 88--91.

\bibitem[\citeproctext]{ref-konczak2020}
Kończak, G. (2020). A Multivariate Extension of McNemar{'}s Test Based
on Permutations. \emph{Acta Universitatis Lodziensis. Folia Oeconomica},
\emph{4 (349)}, 93--105. \url{https://doi.org/10.18778/0208-6018.349.06}

\bibitem[\citeproctext]{ref-kordecki2003}
Kordecki, W. (2003). \emph{Rachunek prawdopodobie{ń}stwa i statystyka
matematyczna: definicje, twierdzenia, wzory} (Wyd. 4 popr). {"}GiS{"}.

\bibitem[\citeproctext]{ref-kowgier2011}
Kowgier, H. (2011). \emph{Elementy rachunku prawdopodobie{ń}stwa i
statystyki na przyk{ł}adach z ekonomii}. Wydawnictwa Naukowo-Techniczne.

\bibitem[\citeproctext]{ref-krysicki2003}
Krysicki, W. (2003). \emph{Rachunek prawdopodobie{ń}stwa} (Wyd. 9,
dodr). Wydawnictwo Naukowe PWN.

\bibitem[\citeproctext]{ref-krzysko2000}
Krzyśko, M. (2000). \emph{Wyk{ł}ady z teorii prawdopodobie{ń}stwa}.
Wydawnictwa Naukowo-Techniczne.

\bibitem[\citeproctext]{ref-kucharski2013}
Kucharski, A. (2013). \emph{Prognozowanie szeregów czasowych metodami
ewolucyjnymi}. Wydawnictwo Uniwersytetu {Ł}ódzkiego.

\bibitem[\citeproctext]{ref-lange1970}
Lange, O., \& Banasiński, A. (1970). \emph{Teoria statystyki}.
Pa{ń}stwowe Wydawnictwo Ekonomiczne.

\bibitem[\citeproctext]{ref-malecka2016}
Małecka, M. (2016). \emph{Weryfikacja hipotez w ocenie ryzyka
rynkowego}. Wydawnictwo Uniwersytetu {Ł}ódzkiego.

\bibitem[\citeproctext]{ref-piasecki2013}
Piasecki, K., \& Tomasik, E. (2013). \emph{Rozk{ł}ady stóp zwrotu z
instrumentów polskiego rynku kapita{ł}owego}. Wydawnictwo Edu-Libri.

\bibitem[\citeproctext]{ref-plucinska1983}
Plucińska, A., \& Pluciński, E. (1983). \emph{Zadania z probabilistyki}.
Pa{ń}stwowe Wydawnictwo Naukowe.

\bibitem[\citeproctext]{ref-plucinska2006}
Plucińska, A., \& Pluciński, E. (2006). \emph{Probabilistyka: Rachunek
prawdopodobie{ń}stwa, statystyka matematyczna, procesy stochastyczne}
(Wyd. 1, 3 dodr). Wydawnictwa Naukowo-Techniczne.

\bibitem[\citeproctext]{ref-polko-zajac2021}
Polko-Zając, D. (2021). \emph{Metody porównywania populacji w badaniach
ekonomicznych}. Wydawnictwo Uniwersytetu Ekonomicznego.

\bibitem[\citeproctext]{ref-rao1997}
Rao, C. R. (1997). \emph{Statistics and truth: putting chance to work}
(2nd ed). World Scientific.

\bibitem[\citeproctext]{ref-simons2017}
Simons, K. (2017). \emph{Paradoksy prawdopodobie{ń}stwa}. Wydawnictwo
Naukowe PWN.

\bibitem[\citeproctext]{ref-snopkowski2007}
Snopkowski, R. (2007). \emph{Symulacja stochastyczna}. AGH. Uczelniane
Wydawnictwa Naukowo-Dydaktyczne.

\bibitem[\citeproctext]{ref-sobczyk2001}
Sobczyk, M. (2001). \emph{Statystyka} (Wyd. 3 zm., dodr). Wydaw. Naukowe
PWN.

\bibitem[\citeproctext]{ref-steinhaus2010}
Steinhaus, H., \& Kobyliński, S. (2010). \emph{Orze{ł} czy reszka?}
(Wyd. 3). Wydawnictwo Naukowe PWN.

\bibitem[\citeproctext]{ref-suhov2005}
Suhov, Y. M., \& Kelbert, M. (2005). \emph{Probability and statistics by
example. Volume I, Basic probability and statistics}. Cambridge
University Press.

\bibitem[\citeproctext]{ref-szymanska2017}
Szymańska, A. (2017). \emph{Ubezpieczenia i finanse: rozwój i
perspektywy}. Wydawnictwo Uniwersytetu {Ł}ódzkiego.

\bibitem[\citeproctext]{ref-thas2010}
Thas, O. (2010). \emph{Comparing Distributions}. Springer New York.
\url{https://doi.org/10.1007/978-0-387-92710-7}

\bibitem[\citeproctext]{ref-trzpiot2011}
Trzpiot, G. (2008). \emph{Wybrane modele oceny ryzyka: Podejście
nieklasyczne}.

\bibitem[\citeproctext]{ref-trzpiot2008b}
Trzpiot, G. (2011). \emph{Statystyczna analiza decyzji}. Wydawnictwo
Uniwersytetu Ekonomicznego.

\bibitem[\citeproctext]{ref-trzpiot2002}
Trzpiot, G., \& Kończak, G. (2002). \emph{Statystyka dla studentów
ekonomii}. Górno{ś}l{ą}ska Wy{ż}sza Szko{ł}a Handlowa.

\bibitem[\citeproctext]{ref-trzpiot2008}
Trzpiot, G., \& Kończak, G. (2008). \emph{Statystyka matematyczna w
przyk{ł}adach i zadaniach}. Górno{ś}l{ą}ska Wy{ż}sza Szko{ł}a Handlowa.

\bibitem[\citeproctext]{ref-ulman2021}
Ulman, P., \& Ćwiek, M. (2021). Measuring housing poverty in Poland: a
multidimensional analysis. \emph{Housing Studies}, \emph{36}(8),
1212--1230. \url{https://doi.org/10.1080/02673037.2020.1759515}

\bibitem[\citeproctext]{ref-wawrzynek2007}
Wawrzynek, J. (2007). \emph{Metody opisu i wnioskowania statystycznego}.
Wydawnictwo Akademii Ekonomicznej im. Oskara Langego.

\bibitem[\citeproctext]{ref-wieczorkowski1997}
Wieczorkowski, R., \& Zieliński, R. (1997). \emph{Komputerowe generatory
liczb losowych}. Wydawnictwa Naukowo-Techniczne.

\bibitem[\citeproctext]{ref-wywial2004}
Wywiał, J. (2004). \emph{Wprowadzenie do wnioskowania statystycznego}.
Wydawnictwo Akademii Ekonomicznej im. Karola Adamieckiego.

\bibitem[\citeproctext]{ref-zelias2002}
Zeliaś, A., Pawełek, B., \& Wanat, S. (2002). \emph{Metody statystyczne:
zadania i sprawdziany}. Polskie Wydawnictwo Ekonomiczne.

\end{CSLReferences}




\end{document}
